<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>CHAI JEHYUNG</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="CHAI JEHYUNG"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="CHAI JEHYUNG"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="CHAI JEHYUNG"><meta property="og:url" content="https://westar99.github.io/"><meta property="og:site_name" content="CHAI JEHYUNG"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://westar99.github.io/img/og_image.png"><meta property="article:author" content="John Doe"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://westar99.github.io"},"headline":"CHAI JEHYUNG","image":["https://westar99.github.io/img/og_image.png"],"author":{"@type":"Person","name":"John Doe"},"publisher":{"@type":"Organization","name":"CHAI JEHYUNG","logo":{"@type":"ImageObject","url":"https://westar99.github.io/img/logo.svg"}},"description":""}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 6.2.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="CHAI JEHYUNG" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-07T08:05:34.000Z" title="2022. 7. 7. 오후 5:05:34">2022-07-07</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-07T08:14:07.421Z" title="2022. 7. 7. 오후 5:14:07">2022-07-07</time></span><span class="level-item">31 minutes read (About 4695 words)</span></div></div><div class="content"><hr>
<h1 id="title-‘데이터분석-하우스’"><a href="#title-‘데이터분석-하우스’" class="headerlink" title="title: ‘데이터분석-하우스’"></a><strong>title: ‘데이터분석-하우스’</strong></h1><h1 id="date-‘2022-07-07-09-00’"><a href="#date-‘2022-07-07-09-00’" class="headerlink" title="date: ‘2022-07-07 09:00’"></a><strong>date: ‘2022-07-07 09:00’</strong></h1><hr>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 구글 드라이브 연동</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> drive </span><br><span class="line">drive.mount(<span class="string">&quot;/content/drive&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&quot;/content/drive&quot;, force_remount=True).
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This Python 3 environment comes with many helpful analytics libraries installed</span></span><br><span class="line"><span class="comment"># It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python</span></span><br><span class="line"><span class="comment"># For example, here&#x27;s several helpful packages to load</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># linear algebra</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd <span class="comment"># data processing, CSV file I/O (e.g. pd.read_csv)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Input data files are available in the read-only &quot;../input/&quot; directory</span></span><br><span class="line"><span class="comment"># For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">for</span> dirname, _, filenames <span class="keyword">in</span> os.walk(<span class="string">&#x27;/kaggle/input&#x27;</span>):</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> filenames:</span><br><span class="line">        <span class="built_in">print</span>(os.path.join(dirname, filename))</span><br><span class="line"></span><br><span class="line"><span class="comment"># You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using &quot;Save &amp; Run All&quot; </span></span><br><span class="line"><span class="comment"># You can also write temporary files to /kaggle/temp/, but they won&#x27;t be saved outside of the current session</span></span><br></pre></td></tr></table></figure>

<h2 id="라이브러리-불러오기"><a href="#라이브러리-불러오기" class="headerlink" title="라이브러리 불러오기"></a>라이브러리 불러오기</h2><ul>
<li>주요 라이브러리 버전을 확인한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl </span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns </span><br><span class="line"><span class="keyword">import</span> sklearn</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb </span><br><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;pandas version :&quot;</span>, pd.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;numpy version :&quot;</span>, np.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;matplotlib version :&quot;</span>, mpl.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;seaborn version :&quot;</span>, sns.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;scikit-learn version :&quot;</span>, sklearn.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;xgboost version :&quot;</span>, xgb.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;lightgbm version :&quot;</span>, lgb.__version__)</span><br></pre></td></tr></table></figure>

<pre><code>pandas version : 1.3.5
numpy version : 1.21.6
matplotlib version : 3.2.2
seaborn version : 0.11.2
scikit-learn version : 1.0.2
xgboost version : 0.90
lightgbm version : 2.2.3
</code></pre>
<h2 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h2><ul>
<li>pandas 활용</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DATA_PATH = <span class="string">&#x27;/content/drive/MyDrive/Colab Notebooks/Human_ai/lecture/house/&#x27;</span></span><br><span class="line">train = pd.read_csv(DATA_PATH + <span class="string">&quot;train.csv&quot;</span>)</span><br><span class="line">test = pd.read_csv(DATA_PATH + <span class="string">&quot;test.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;데이터 불러오기 완료!&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>데이터 불러오기 완료!
</code></pre>
<h2 id="데이터-둘러보기"><a href="#데이터-둘러보기" class="headerlink" title="데이터 둘러보기"></a>데이터 둘러보기</h2><ul>
<li>데이터를 둘러봅니다. </li>
<li>train : 행 갯수 1460 열 갯수 81 (SalePrice 존재)</li>
<li>test : 행 갯수 1459, 열 갯수 80 (SalePrice 컬럼 미 존재)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.shape, test.shape</span><br></pre></td></tr></table></figure>




<pre><code>((1460, 81), (1459, 80))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 1460 entries, 0 to 1459
Data columns (total 81 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   Id             1460 non-null   int64  
 1   MSSubClass     1460 non-null   int64  
 2   MSZoning       1460 non-null   object 
 3   LotFrontage    1201 non-null   float64
 4   LotArea        1460 non-null   int64  
 5   Street         1460 non-null   object 
 6   Alley          91 non-null     object 
 7   LotShape       1460 non-null   object 
 8   LandContour    1460 non-null   object 
 9   Utilities      1460 non-null   object 
 10  LotConfig      1460 non-null   object 
 11  LandSlope      1460 non-null   object 
 12  Neighborhood   1460 non-null   object 
 13  Condition1     1460 non-null   object 
 14  Condition2     1460 non-null   object 
 15  BldgType       1460 non-null   object 
 16  HouseStyle     1460 non-null   object 
 17  OverallQual    1460 non-null   int64  
 18  OverallCond    1460 non-null   int64  
 19  YearBuilt      1460 non-null   int64  
 20  YearRemodAdd   1460 non-null   int64  
 21  RoofStyle      1460 non-null   object 
 22  RoofMatl       1460 non-null   object 
 23  Exterior1st    1460 non-null   object 
 24  Exterior2nd    1460 non-null   object 
 25  MasVnrType     1452 non-null   object 
 26  MasVnrArea     1452 non-null   float64
 27  ExterQual      1460 non-null   object 
 28  ExterCond      1460 non-null   object 
 29  Foundation     1460 non-null   object 
 30  BsmtQual       1423 non-null   object 
 31  BsmtCond       1423 non-null   object 
 32  BsmtExposure   1422 non-null   object 
 33  BsmtFinType1   1423 non-null   object 
 34  BsmtFinSF1     1460 non-null   int64  
 35  BsmtFinType2   1422 non-null   object 
 36  BsmtFinSF2     1460 non-null   int64  
 37  BsmtUnfSF      1460 non-null   int64  
 38  TotalBsmtSF    1460 non-null   int64  
 39  Heating        1460 non-null   object 
 40  HeatingQC      1460 non-null   object 
 41  CentralAir     1460 non-null   object 
 42  Electrical     1459 non-null   object 
 43  1stFlrSF       1460 non-null   int64  
 44  2ndFlrSF       1460 non-null   int64  
 45  LowQualFinSF   1460 non-null   int64  
 46  GrLivArea      1460 non-null   int64  
 47  BsmtFullBath   1460 non-null   int64  
 48  BsmtHalfBath   1460 non-null   int64  
 49  FullBath       1460 non-null   int64  
 50  HalfBath       1460 non-null   int64  
 51  BedroomAbvGr   1460 non-null   int64  
 52  KitchenAbvGr   1460 non-null   int64  
 53  KitchenQual    1460 non-null   object 
 54  TotRmsAbvGrd   1460 non-null   int64  
 55  Functional     1460 non-null   object 
 56  Fireplaces     1460 non-null   int64  
 57  FireplaceQu    770 non-null    object 
 58  GarageType     1379 non-null   object 
 59  GarageYrBlt    1379 non-null   float64
 60  GarageFinish   1379 non-null   object 
 61  GarageCars     1460 non-null   int64  
 62  GarageArea     1460 non-null   int64  
 63  GarageQual     1379 non-null   object 
 64  GarageCond     1379 non-null   object 
 65  PavedDrive     1460 non-null   object 
 66  WoodDeckSF     1460 non-null   int64  
 67  OpenPorchSF    1460 non-null   int64  
 68  EnclosedPorch  1460 non-null   int64  
 69  3SsnPorch      1460 non-null   int64  
 70  ScreenPorch    1460 non-null   int64  
 71  PoolArea       1460 non-null   int64  
 72  PoolQC         7 non-null      object 
 73  Fence          281 non-null    object 
 74  MiscFeature    54 non-null     object 
 75  MiscVal        1460 non-null   int64  
 76  MoSold         1460 non-null   int64  
 77  YrSold         1460 non-null   int64  
 78  SaleType       1460 non-null   object 
 79  SaleCondition  1460 non-null   object 
 80  SalePrice      1460 non-null   int64  
dtypes: float64(3), int64(35), object(43)
memory usage: 924.0+ KB
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 1459 entries, 0 to 1458
Data columns (total 80 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   Id             1459 non-null   int64  
 1   MSSubClass     1459 non-null   int64  
 2   MSZoning       1455 non-null   object 
 3   LotFrontage    1232 non-null   float64
 4   LotArea        1459 non-null   int64  
 5   Street         1459 non-null   object 
 6   Alley          107 non-null    object 
 7   LotShape       1459 non-null   object 
 8   LandContour    1459 non-null   object 
 9   Utilities      1457 non-null   object 
 10  LotConfig      1459 non-null   object 
 11  LandSlope      1459 non-null   object 
 12  Neighborhood   1459 non-null   object 
 13  Condition1     1459 non-null   object 
 14  Condition2     1459 non-null   object 
 15  BldgType       1459 non-null   object 
 16  HouseStyle     1459 non-null   object 
 17  OverallQual    1459 non-null   int64  
 18  OverallCond    1459 non-null   int64  
 19  YearBuilt      1459 non-null   int64  
 20  YearRemodAdd   1459 non-null   int64  
 21  RoofStyle      1459 non-null   object 
 22  RoofMatl       1459 non-null   object 
 23  Exterior1st    1458 non-null   object 
 24  Exterior2nd    1458 non-null   object 
 25  MasVnrType     1443 non-null   object 
 26  MasVnrArea     1444 non-null   float64
 27  ExterQual      1459 non-null   object 
 28  ExterCond      1459 non-null   object 
 29  Foundation     1459 non-null   object 
 30  BsmtQual       1415 non-null   object 
 31  BsmtCond       1414 non-null   object 
 32  BsmtExposure   1415 non-null   object 
 33  BsmtFinType1   1417 non-null   object 
 34  BsmtFinSF1     1458 non-null   float64
 35  BsmtFinType2   1417 non-null   object 
 36  BsmtFinSF2     1458 non-null   float64
 37  BsmtUnfSF      1458 non-null   float64
 38  TotalBsmtSF    1458 non-null   float64
 39  Heating        1459 non-null   object 
 40  HeatingQC      1459 non-null   object 
 41  CentralAir     1459 non-null   object 
 42  Electrical     1459 non-null   object 
 43  1stFlrSF       1459 non-null   int64  
 44  2ndFlrSF       1459 non-null   int64  
 45  LowQualFinSF   1459 non-null   int64  
 46  GrLivArea      1459 non-null   int64  
 47  BsmtFullBath   1457 non-null   float64
 48  BsmtHalfBath   1457 non-null   float64
 49  FullBath       1459 non-null   int64  
 50  HalfBath       1459 non-null   int64  
 51  BedroomAbvGr   1459 non-null   int64  
 52  KitchenAbvGr   1459 non-null   int64  
 53  KitchenQual    1458 non-null   object 
 54  TotRmsAbvGrd   1459 non-null   int64  
 55  Functional     1457 non-null   object 
 56  Fireplaces     1459 non-null   int64  
 57  FireplaceQu    729 non-null    object 
 58  GarageType     1383 non-null   object 
 59  GarageYrBlt    1381 non-null   float64
 60  GarageFinish   1381 non-null   object 
 61  GarageCars     1458 non-null   float64
 62  GarageArea     1458 non-null   float64
 63  GarageQual     1381 non-null   object 
 64  GarageCond     1381 non-null   object 
 65  PavedDrive     1459 non-null   object 
 66  WoodDeckSF     1459 non-null   int64  
 67  OpenPorchSF    1459 non-null   int64  
 68  EnclosedPorch  1459 non-null   int64  
 69  3SsnPorch      1459 non-null   int64  
 70  ScreenPorch    1459 non-null   int64  
 71  PoolArea       1459 non-null   int64  
 72  PoolQC         3 non-null      object 
 73  Fence          290 non-null    object 
 74  MiscFeature    51 non-null     object 
 75  MiscVal        1459 non-null   int64  
 76  MoSold         1459 non-null   int64  
 77  YrSold         1459 non-null   int64  
 78  SaleType       1458 non-null   object 
 79  SaleCondition  1459 non-null   object 
dtypes: float64(11), int64(26), object(43)
memory usage: 912.0+ KB
</code></pre>
<h2 id="데이터-시각화"><a href="#데이터-시각화" class="headerlink" title="데이터 시각화"></a>데이터 시각화</h2><ul>
<li><p>여기에서는 생략</p>
</li>
<li><p>종속변수 분포 확인</p>
</li>
<li><p>샤피로 검정</p>
</li>
<li><p>정규분포인가요? </p>
<ul>
<li>정규분포가 아님! –&gt; 로그변환, 박스콕스 변환 등등</li>
<li>정규분포로 만들어 줘야 함.</li>
</ul>
</li>
<li><p>선형모델의 성능을 올리기 위해서는</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm </span><br><span class="line">(mu, sigma) = norm.fit(train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;평균:&quot;</span>, mu)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;표준편차:&quot;</span>, sigma)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">sns.histplot(train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line">ax.<span class="built_in">set</span>(title=<span class="string">&quot;SalePrice Distribution&quot;</span>)</span><br><span class="line">ax.axvline(mu, color = <span class="string">&#x27;r&#x27;</span>, linestyle = <span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">ax.text(mu + <span class="number">10000</span>, <span class="number">160</span>, <span class="string">&#x27;Mean of SalePrice&#x27;</span>, color = <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>평균: 180921.19589041095
표준편차: 79415.29188606751
</code></pre>
<p><img src="/images/day0707/output_14_1.png" alt="png"></p>
<ul>
<li>로그변환을 해서 정규분포로 변환해준다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 로그변환을 함. </span></span><br><span class="line">train[<span class="string">&#x27;SalePrice&#x27;</span>] = np.log1p(train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line"></span><br><span class="line">(mu, sigma) = norm.fit(train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;평균:&quot;</span>, mu)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;표준편차:&quot;</span>, sigma)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">sns.histplot(train[<span class="string">&#x27;SalePrice&#x27;</span>])</span><br><span class="line">ax.<span class="built_in">set</span>(title=<span class="string">&quot;SalePrice Distribution&quot;</span>)</span><br><span class="line">ax.axvline(mu, color = <span class="string">&#x27;r&#x27;</span>, linestyle = <span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">ax.text(mu + <span class="number">0.0001</span>, <span class="number">160</span>, <span class="string">&#x27;Mean of SalePrice&#x27;</span>, color = <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">ax.set_ylim(<span class="number">0</span>, <span class="number">170</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>평균: 12.024057394918406
표준편차: 0.39931245219387496
</code></pre>
<p><img src="/images/day0707/output_14_1.png" alt="png"></p>
<h2 id="데이터-전처리"><a href="#데이터-전처리" class="headerlink" title="데이터 전처리"></a>데이터 전처리</h2><ul>
<li>컬럼 갯수가 많다?, 어떤 컬럼을 없앨 것인가? </li>
<li>머신러닝 연산 속도부터 높여야 함.</li>
</ul>
<h3 id="데이터-ID값-제거"><a href="#데이터-ID값-제거" class="headerlink" title="데이터 ID값 제거"></a>데이터 ID값 제거</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_ID = train[<span class="string">&#x27;Id&#x27;</span>]</span><br><span class="line">test_ID = test[<span class="string">&#x27;Id&#x27;</span>]</span><br><span class="line"></span><br><span class="line">train = train.drop([<span class="string">&#x27;Id&#x27;</span>], axis = <span class="number">1</span>)</span><br><span class="line">train.shape</span><br></pre></td></tr></table></figure>




<pre><code>(1460, 80)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test = test.drop([<span class="string">&#x27;Id&#x27;</span>], axis = <span class="number">1</span>)</span><br><span class="line">test.shape </span><br></pre></td></tr></table></figure>




<pre><code>(1459, 79)
</code></pre>
<h3 id="Y값-추출"><a href="#Y값-추출" class="headerlink" title="Y값 추출"></a>Y값 추출</h3><ul>
<li>train데이터에 SalePrice만 따로 저장한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y = train[<span class="string">&#x27;SalePrice&#x27;</span>]</span><br><span class="line">train = train.drop(<span class="string">&#x27;SalePrice&#x27;</span>, axis = <span class="number">1</span>)</span><br><span class="line">train.shape</span><br></pre></td></tr></table></figure>




<pre><code>(1460, 79)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test.shape</span><br></pre></td></tr></table></figure>




<pre><code>(1459, 79)
</code></pre>
<h3 id="데이터-합치기"><a href="#데이터-합치기" class="headerlink" title="데이터 합치기"></a>데이터 합치기</h3><ul>
<li>강의 목적</li>
<li>원칙<ul>
<li>train, 따로 정리</li>
<li>test, 따로 정리</li>
</ul>
</li>
<li>Data Leakage 오류를 범할 가능성이 높음.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_df = pd.concat([train, test]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">all_df.shape</span><br></pre></td></tr></table></figure>




<pre><code>(2919, 79)
</code></pre>
<h2 id="결측치-확인"><a href="#결측치-확인" class="headerlink" title="결측치 확인"></a>결측치 확인</h2><ul>
<li>결측치의 비율 확인하는 사용자 정의 함수 작성</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 1460 entries, 0 to 1459
Data columns (total 79 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   MSSubClass     1460 non-null   int64  
 1   MSZoning       1460 non-null   object 
 2   LotFrontage    1201 non-null   float64
 3   LotArea        1460 non-null   int64  
 4   Street         1460 non-null   object 
 5   Alley          91 non-null     object 
 6   LotShape       1460 non-null   object 
 7   LandContour    1460 non-null   object 
 8   Utilities      1460 non-null   object 
 9   LotConfig      1460 non-null   object 
 10  LandSlope      1460 non-null   object 
 11  Neighborhood   1460 non-null   object 
 12  Condition1     1460 non-null   object 
 13  Condition2     1460 non-null   object 
 14  BldgType       1460 non-null   object 
 15  HouseStyle     1460 non-null   object 
 16  OverallQual    1460 non-null   int64  
 17  OverallCond    1460 non-null   int64  
 18  YearBuilt      1460 non-null   int64  
 19  YearRemodAdd   1460 non-null   int64  
 20  RoofStyle      1460 non-null   object 
 21  RoofMatl       1460 non-null   object 
 22  Exterior1st    1460 non-null   object 
 23  Exterior2nd    1460 non-null   object 
 24  MasVnrType     1452 non-null   object 
 25  MasVnrArea     1452 non-null   float64
 26  ExterQual      1460 non-null   object 
 27  ExterCond      1460 non-null   object 
 28  Foundation     1460 non-null   object 
 29  BsmtQual       1423 non-null   object 
 30  BsmtCond       1423 non-null   object 
 31  BsmtExposure   1422 non-null   object 
 32  BsmtFinType1   1423 non-null   object 
 33  BsmtFinSF1     1460 non-null   int64  
 34  BsmtFinType2   1422 non-null   object 
 35  BsmtFinSF2     1460 non-null   int64  
 36  BsmtUnfSF      1460 non-null   int64  
 37  TotalBsmtSF    1460 non-null   int64  
 38  Heating        1460 non-null   object 
 39  HeatingQC      1460 non-null   object 
 40  CentralAir     1460 non-null   object 
 41  Electrical     1459 non-null   object 
 42  1stFlrSF       1460 non-null   int64  
 43  2ndFlrSF       1460 non-null   int64  
 44  LowQualFinSF   1460 non-null   int64  
 45  GrLivArea      1460 non-null   int64  
 46  BsmtFullBath   1460 non-null   int64  
 47  BsmtHalfBath   1460 non-null   int64  
 48  FullBath       1460 non-null   int64  
 49  HalfBath       1460 non-null   int64  
 50  BedroomAbvGr   1460 non-null   int64  
 51  KitchenAbvGr   1460 non-null   int64  
 52  KitchenQual    1460 non-null   object 
 53  TotRmsAbvGrd   1460 non-null   int64  
 54  Functional     1460 non-null   object 
 55  Fireplaces     1460 non-null   int64  
 56  FireplaceQu    770 non-null    object 
 57  GarageType     1379 non-null   object 
 58  GarageYrBlt    1379 non-null   float64
 59  GarageFinish   1379 non-null   object 
 60  GarageCars     1460 non-null   int64  
 61  GarageArea     1460 non-null   int64  
 62  GarageQual     1379 non-null   object 
 63  GarageCond     1379 non-null   object 
 64  PavedDrive     1460 non-null   object 
 65  WoodDeckSF     1460 non-null   int64  
 66  OpenPorchSF    1460 non-null   int64  
 67  EnclosedPorch  1460 non-null   int64  
 68  3SsnPorch      1460 non-null   int64  
 69  ScreenPorch    1460 non-null   int64  
 70  PoolArea       1460 non-null   int64  
 71  PoolQC         7 non-null      object 
 72  Fence          281 non-null    object 
 73  MiscFeature    54 non-null     object 
 74  MiscVal        1460 non-null   int64  
 75  MoSold         1460 non-null   int64  
 76  YrSold         1460 non-null   int64  
 77  SaleType       1460 non-null   object 
 78  SaleCondition  1460 non-null   object 
dtypes: float64(3), int64(33), object(43)
memory usage: 901.2+ KB
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">check_na</span>(<span class="params">data, head_num = <span class="number">6</span></span>):</span><br><span class="line">  isnull_na = (data.isnull().<span class="built_in">sum</span>() / <span class="built_in">len</span>(data)) * <span class="number">100</span></span><br><span class="line">  data_na = isnull_na.drop(isnull_na[isnull_na == <span class="number">0</span>].index).sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line">  missing_data = pd.DataFrame(&#123;<span class="string">&#x27;Missing Ratio&#x27;</span> :data_na, </span><br><span class="line">                               <span class="string">&#x27;Data Type&#x27;</span>: data.dtypes[data_na.index]&#125;)</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">&quot;결측치 데이터 컬럼과 건수:\n&quot;</span>, missing_data.head(head_num))</span><br><span class="line"></span><br><span class="line">check_na(all_df, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<pre><code>결측치 데이터 컬럼과 건수:
               Missing Ratio Data Type
PoolQC            99.657417    object
MiscFeature       96.402878    object
Alley             93.216855    object
Fence             80.438506    object
FireplaceQu       48.646797    object
LotFrontage       16.649538   float64
GarageFinish       5.447071    object
GarageQual         5.447071    object
GarageCond         5.447071    object
GarageYrBlt        5.447071   float64
GarageType         5.378554    object
BsmtExposure       2.809181    object
BsmtCond           2.809181    object
BsmtQual           2.774923    object
BsmtFinType2       2.740665    object
BsmtFinType1       2.706406    object
MasVnrType         0.822199    object
MasVnrArea         0.787941   float64
MSZoning           0.137033    object
BsmtFullBath       0.068517   float64
</code></pre>
<ul>
<li>결측치 제거</li>
<li>결측치 비율이 높은 변수들을 모두 제거하기로 했다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_df = all_df.drop([<span class="string">&#x27;PoolQC&#x27;</span>, <span class="string">&#x27;MiscFeature&#x27;</span>, <span class="string">&#x27;Alley&#x27;</span>, <span class="string">&#x27;Fence&#x27;</span>, <span class="string">&#x27;FireplaceQu&#x27;</span>, <span class="string">&#x27;LotFrontage&#x27;</span>], axis = <span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(all_df.shape)</span><br><span class="line">check_na(all_df, <span class="number">40</span>)</span><br></pre></td></tr></table></figure>

<pre><code>(2919, 73)
결측치 데이터 컬럼과 건수:
               Missing Ratio Data Type
GarageCond         5.447071    object
GarageQual         5.447071    object
GarageYrBlt        5.447071   float64
GarageFinish       5.447071    object
GarageType         5.378554    object
BsmtCond           2.809181    object
BsmtExposure       2.809181    object
BsmtQual           2.774923    object
BsmtFinType2       2.740665    object
BsmtFinType1       2.706406    object
MasVnrType         0.822199    object
MasVnrArea         0.787941   float64
MSZoning           0.137033    object
Functional         0.068517    object
Utilities          0.068517    object
BsmtFullBath       0.068517   float64
BsmtHalfBath       0.068517   float64
GarageArea         0.034258   float64
GarageCars         0.034258   float64
TotalBsmtSF        0.034258   float64
KitchenQual        0.034258    object
Electrical         0.034258    object
BsmtUnfSF          0.034258   float64
BsmtFinSF2         0.034258   float64
BsmtFinSF1         0.034258   float64
Exterior2nd        0.034258    object
Exterior1st        0.034258    object
SaleType           0.034258    object
</code></pre>
<h2 id="결측치-채우기"><a href="#결측치-채우기" class="headerlink" title="결측치 채우기"></a>결측치 채우기</h2><ul>
<li>train 데이터와 test 데이터가 섞이면 안됨. </li>
<li>train &#x2F; test 분리해서 진행해야 함. </li>
<li>문자데이터 : 자주 등장하는 빈도 값으로 채움</li>
<li>숫자데이터 : 평균이 아니라, 중간값으로 채울 예정</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># all_df[&#x27;SaleType&#x27;].value_counts()</span></span><br><span class="line">all_df[<span class="string">&#x27;SaleType&#x27;</span>].mode()[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>




<pre><code>&#39;WD&#39;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">check_na(all_df, <span class="number">40</span>)</span><br></pre></td></tr></table></figure>

<pre><code>결측치 데이터 컬럼과 건수:
               Missing Ratio Data Type
GarageCond         5.447071    object
GarageQual         5.447071    object
GarageYrBlt        5.447071   float64
GarageFinish       5.447071    object
GarageType         5.378554    object
BsmtCond           2.809181    object
BsmtExposure       2.809181    object
BsmtQual           2.774923    object
BsmtFinType2       2.740665    object
BsmtFinType1       2.706406    object
MasVnrType         0.822199    object
MasVnrArea         0.787941   float64
MSZoning           0.137033    object
Functional         0.068517    object
Utilities          0.068517    object
BsmtFullBath       0.068517   float64
BsmtHalfBath       0.068517   float64
GarageArea         0.034258   float64
GarageCars         0.034258   float64
TotalBsmtSF        0.034258   float64
KitchenQual        0.034258    object
Electrical         0.034258    object
BsmtUnfSF          0.034258   float64
BsmtFinSF2         0.034258   float64
BsmtFinSF1         0.034258   float64
Exterior2nd        0.034258    object
Exterior1st        0.034258    object
SaleType           0.034258    object
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 문자열 데이터만 추출</span></span><br><span class="line">cat_all_vars = train.select_dtypes(exclude=[np.number])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The whole number of all_vars&quot;</span>, <span class="built_in">len</span>(<span class="built_in">list</span>(cat_all_vars)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 문자열 데이터 중에서 이미 기 삭제했던 Feature들이 있었기 때문에, </span></span><br><span class="line"><span class="comment"># 한번 더 Feature를 정리하는 코드를 작성한다. </span></span><br><span class="line"><span class="comment"># 따라서 38개의 Feature만 추출했다. </span></span><br><span class="line">final_cat_vars = []</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> cat_all_vars:</span><br><span class="line">    <span class="keyword">if</span> v <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;PoolQC&#x27;</span>, <span class="string">&#x27;MiscFeature&#x27;</span>, <span class="string">&#x27;Alley&#x27;</span>, <span class="string">&#x27;Fence&#x27;</span>, <span class="string">&#x27;FireplaceQu&#x27;</span>]:</span><br><span class="line">        final_cat_vars.append(v)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The whole number of final_cat_vars&quot;</span>, <span class="built_in">len</span>(final_cat_vars))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이제 각 Feature 마다 빈도수가 가장 많이 나타나는 값을 추가하는 코드를 작성한다. </span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> final_cat_vars:</span><br><span class="line">  all_df[i] = all_df[i].fillna(all_df[i].mode()[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이제 수치형 데이터만 남은 것을 확인한다. </span></span><br><span class="line">check_na(all_df, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<pre><code>The whole number of all_vars 43
The whole number of final_cat_vars 38
결측치 데이터 컬럼과 건수:
               Missing Ratio Data Type
GarageYrBlt        5.447071   float64
MasVnrArea         0.787941   float64
BsmtFullBath       0.068517   float64
BsmtHalfBath       0.068517   float64
BsmtFinSF1         0.034258   float64
BsmtFinSF2         0.034258   float64
BsmtUnfSF          0.034258   float64
TotalBsmtSF        0.034258   float64
GarageCars         0.034258   float64
GarageArea         0.034258   float64
</code></pre>
<ul>
<li>수치형 데이터의 결측치를 추가할 수 있다. </li>
<li>평균이 아닌 중간값으로 진행한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 방법은 기존과 동일하다. </span></span><br><span class="line"><span class="comment"># 이번에는 수치형 데이터만 추출한다. </span></span><br><span class="line">num_all_vars = <span class="built_in">list</span>(train.select_dtypes(include=[np.number]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The whole number of all_vars&quot;</span>, <span class="built_in">len</span>(num_all_vars))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 수치형 데이터 중, 결측치가 많았던 `LotFrontage`만 처리한다. </span></span><br><span class="line">num_all_vars.remove(<span class="string">&#x27;LotFrontage&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;The whole number of final_cat_vars&quot;</span>, <span class="built_in">len</span>(num_all_vars))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 이번에는 수치형 데이터의 평균이 아닌 중간값을 지정했다. </span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> num_all_vars:</span><br><span class="line">  all_df[i].fillna(value=all_df[i].median(), inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">check_na(all_df, <span class="number">20</span>)</span><br></pre></td></tr></table></figure>

<pre><code>The whole number of all_vars 36
The whole number of final_cat_vars 35
결측치 데이터 컬럼과 건수:
 Empty DataFrame
Columns: [Missing Ratio, Data Type]
Index: []
</code></pre>
<h2 id="도출-변수"><a href="#도출-변수" class="headerlink" title="도출 변수"></a>도출 변수</h2><ul>
<li><p>새로운 도출 변수를 작성 (기존 변수 활용)</p>
</li>
<li><p>기존 변수 제거 </p>
</li>
<li><p>각 층의 면적으로 모두 더해 전체 면적으로 계산한 새로운 변수를 작성한다.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;TotalSF&#x27;</span>] = all_df[<span class="string">&#x27;TotalBsmtSF&#x27;</span>] + all_df[<span class="string">&#x27;1stFlrSF&#x27;</span>] + all_df[<span class="string">&#x27;2ndFlrSF&#x27;</span>]</span><br><span class="line">all_df = all_df.drop([<span class="string">&#x27;TotalBsmtSF&#x27;</span>, <span class="string">&#x27;1stFlrSF&#x27;</span>, <span class="string">&#x27;2ndFlrSF&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(all_df.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(2919, 71)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;Total_Bathrooms&#x27;</span>] = (all_df[<span class="string">&#x27;FullBath&#x27;</span>] + (<span class="number">0.5</span> * all_df[<span class="string">&#x27;HalfBath&#x27;</span>]) + all_df[<span class="string">&#x27;BsmtFullBath&#x27;</span>] + (<span class="number">0.5</span> * all_df[<span class="string">&#x27;BsmtHalfBath&#x27;</span>]))</span><br><span class="line">all_df[<span class="string">&#x27;Total_porch_sf&#x27;</span>] = (all_df[<span class="string">&#x27;OpenPorchSF&#x27;</span>] + all_df[<span class="string">&#x27;3SsnPorch&#x27;</span>] + all_df[<span class="string">&#x27;EnclosedPorch&#x27;</span>] + all_df[<span class="string">&#x27;ScreenPorch&#x27;</span>])</span><br><span class="line">all_df = all_df.drop([<span class="string">&#x27;FullBath&#x27;</span>, <span class="string">&#x27;HalfBath&#x27;</span>, <span class="string">&#x27;BsmtFullBath&#x27;</span>, <span class="string">&#x27;BsmtHalfBath&#x27;</span>, <span class="string">&#x27;OpenPorchSF&#x27;</span>, <span class="string">&#x27;3SsnPorch&#x27;</span>, <span class="string">&#x27;EnclosedPorch&#x27;</span>, <span class="string">&#x27;ScreenPorch&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(all_df.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(2919, 65)
</code></pre>
<ul>
<li>연도와 관련된 변수를 추출하는 코드 작성.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">num_all_vars = <span class="built_in">list</span>(train.select_dtypes(include=[np.number]))</span><br><span class="line">year_feature = []</span><br><span class="line"><span class="keyword">for</span> var <span class="keyword">in</span> num_all_vars:</span><br><span class="line">  <span class="keyword">if</span> <span class="string">&#x27;Yr&#x27;</span> <span class="keyword">in</span> var:</span><br><span class="line">    year_feature.append(var)</span><br><span class="line">  <span class="keyword">elif</span> <span class="string">&#x27;Year&#x27;</span> <span class="keyword">in</span> var:</span><br><span class="line">    year_feature.append(var)</span><br><span class="line">  <span class="keyword">else</span>:  </span><br><span class="line">    <span class="built_in">print</span>(var, <span class="string">&quot;is not related with Year&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(year_feature)</span><br></pre></td></tr></table></figure>

<pre><code>MSSubClass is not related with Year
LotFrontage is not related with Year
LotArea is not related with Year
OverallQual is not related with Year
OverallCond is not related with Year
MasVnrArea is not related with Year
BsmtFinSF1 is not related with Year
BsmtFinSF2 is not related with Year
BsmtUnfSF is not related with Year
TotalBsmtSF is not related with Year
1stFlrSF is not related with Year
2ndFlrSF is not related with Year
LowQualFinSF is not related with Year
GrLivArea is not related with Year
BsmtFullBath is not related with Year
BsmtHalfBath is not related with Year
FullBath is not related with Year
HalfBath is not related with Year
BedroomAbvGr is not related with Year
KitchenAbvGr is not related with Year
TotRmsAbvGrd is not related with Year
Fireplaces is not related with Year
GarageCars is not related with Year
GarageArea is not related with Year
WoodDeckSF is not related with Year
OpenPorchSF is not related with Year
EnclosedPorch is not related with Year
3SsnPorch is not related with Year
ScreenPorch is not related with Year
PoolArea is not related with Year
MiscVal is not related with Year
MoSold is not related with Year
[&#39;YearBuilt&#39;, &#39;YearRemodAdd&#39;, &#39;GarageYrBlt&#39;, &#39;YrSold&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots(<span class="number">3</span>, <span class="number">1</span>, figsize=(<span class="number">10</span>, <span class="number">6</span>), sharex=<span class="literal">True</span>, sharey=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> i, var <span class="keyword">in</span> <span class="built_in">enumerate</span>(year_feature):</span><br><span class="line">  <span class="keyword">if</span> var != <span class="string">&#x27;YrSold&#x27;</span>:</span><br><span class="line">    ax[i].scatter(train[var], y, alpha=<span class="number">0.3</span>)</span><br><span class="line">    ax[i].set_title(<span class="string">&#x27;&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(var), size=<span class="number">15</span>)</span><br><span class="line">    ax[i].set_ylabel(<span class="string">&#x27;SalePrice&#x27;</span>, size=<span class="number">15</span>, labelpad=<span class="number">12.5</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0707/output_43_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_df = all_df.drop([<span class="string">&#x27;YearBuilt&#x27;</span>, <span class="string">&#x27;GarageYrBlt&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(all_df.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(2919, 63)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">YearsSinceRemodel = train[<span class="string">&#x27;YrSold&#x27;</span>].astype(<span class="built_in">int</span>) - train[<span class="string">&#x27;YearRemodAdd&#x27;</span>].astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line">ax.scatter(YearsSinceRemodel, y, alpha=<span class="number">0.3</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0707/output_45_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;YearsSinceRemodel&#x27;</span>] = all_df[<span class="string">&#x27;YrSold&#x27;</span>].astype(<span class="built_in">int</span>) - all_df[<span class="string">&#x27;YearRemodAdd&#x27;</span>].astype(<span class="built_in">int</span>)</span><br><span class="line">all_df = all_df.drop([<span class="string">&#x27;YrSold&#x27;</span>, <span class="string">&#x27;YearRemodAdd&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(all_df.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(2919, 62)
</code></pre>
<h2 id="더미변수"><a href="#더미변수" class="headerlink" title="더미변수"></a>더미변수</h2><ul>
<li>더미변수란 원 데이터 독립변수를 0과 1로 변환하는 변수를 말함.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;PoolArea&#x27;</span>].value_counts() </span><br></pre></td></tr></table></figure>




<pre><code>0      2906
512       1
648       1
576       1
555       1
480       1
519       1
738       1
144       1
368       1
444       1
228       1
561       1
800       1
Name: PoolArea, dtype: int64
</code></pre>
<ul>
<li>사용자 정의 함수 만들기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">count_dummy</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">if</span> x &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;PoolArea&#x27;</span>] = all_df[<span class="string">&#x27;PoolArea&#x27;</span>].apply(count_dummy) </span><br><span class="line">all_df[<span class="string">&#x27;PoolArea&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>




<pre><code>0    2906
1      13
Name: PoolArea, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;GarageArea&#x27;</span>] = all_df[<span class="string">&#x27;GarageArea&#x27;</span>].apply(count_dummy)</span><br><span class="line">all_df[<span class="string">&#x27;GarageArea&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>




<pre><code>1    2762
0     157
Name: GarageArea, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_df[<span class="string">&#x27;Fireplaces&#x27;</span>] = all_df[<span class="string">&#x27;Fireplaces&#x27;</span>].apply(count_dummy)</span><br><span class="line">all_df[<span class="string">&#x27;Fireplaces&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>




<pre><code>1    1499
0    1420
Name: Fireplaces, dtype: int64
</code></pre>
<h2 id="인코딩"><a href="#인코딩" class="headerlink" title="인코딩"></a>인코딩</h2><ul>
<li>문자를 숫자로 변환해주는 코드를 인코딩 변환</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(all_df.info())</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 2919 entries, 0 to 2918
Data columns (total 62 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   MSSubClass         2919 non-null   int64  
 1   MSZoning           2919 non-null   object 
 2   LotArea            2919 non-null   int64  
 3   Street             2919 non-null   object 
 4   LotShape           2919 non-null   object 
 5   LandContour        2919 non-null   object 
 6   Utilities          2919 non-null   object 
 7   LotConfig          2919 non-null   object 
 8   LandSlope          2919 non-null   object 
 9   Neighborhood       2919 non-null   object 
 10  Condition1         2919 non-null   object 
 11  Condition2         2919 non-null   object 
 12  BldgType           2919 non-null   object 
 13  HouseStyle         2919 non-null   object 
 14  OverallQual        2919 non-null   int64  
 15  OverallCond        2919 non-null   int64  
 16  RoofStyle          2919 non-null   object 
 17  RoofMatl           2919 non-null   object 
 18  Exterior1st        2919 non-null   object 
 19  Exterior2nd        2919 non-null   object 
 20  MasVnrType         2919 non-null   object 
 21  MasVnrArea         2919 non-null   float64
 22  ExterQual          2919 non-null   object 
 23  ExterCond          2919 non-null   object 
 24  Foundation         2919 non-null   object 
 25  BsmtQual           2919 non-null   object 
 26  BsmtCond           2919 non-null   object 
 27  BsmtExposure       2919 non-null   object 
 28  BsmtFinType1       2919 non-null   object 
 29  BsmtFinSF1         2919 non-null   float64
 30  BsmtFinType2       2919 non-null   object 
 31  BsmtFinSF2         2919 non-null   float64
 32  BsmtUnfSF          2919 non-null   float64
 33  Heating            2919 non-null   object 
 34  HeatingQC          2919 non-null   object 
 35  CentralAir         2919 non-null   object 
 36  Electrical         2919 non-null   object 
 37  LowQualFinSF       2919 non-null   int64  
 38  GrLivArea          2919 non-null   int64  
 39  BedroomAbvGr       2919 non-null   int64  
 40  KitchenAbvGr       2919 non-null   int64  
 41  KitchenQual        2919 non-null   object 
 42  TotRmsAbvGrd       2919 non-null   int64  
 43  Functional         2919 non-null   object 
 44  Fireplaces         2919 non-null   int64  
 45  GarageType         2919 non-null   object 
 46  GarageFinish       2919 non-null   object 
 47  GarageCars         2919 non-null   float64
 48  GarageArea         2919 non-null   int64  
 49  GarageQual         2919 non-null   object 
 50  GarageCond         2919 non-null   object 
 51  PavedDrive         2919 non-null   object 
 52  WoodDeckSF         2919 non-null   int64  
 53  PoolArea           2919 non-null   int64  
 54  MiscVal            2919 non-null   int64  
 55  MoSold             2919 non-null   int64  
 56  SaleType           2919 non-null   object 
 57  SaleCondition      2919 non-null   object 
 58  TotalSF            2919 non-null   float64
 59  Total_Bathrooms    2919 non-null   float64
 60  Total_porch_sf     2919 non-null   int64  
 61  YearsSinceRemodel  2919 non-null   int64  
dtypes: float64(7), int64(17), object(38)
memory usage: 1.4+ MB
None
</code></pre>
<h2 id="Label-Encoding-Ordinal-Encoding-One-Hot-Encoding"><a href="#Label-Encoding-Ordinal-Encoding-One-Hot-Encoding" class="headerlink" title="Label Encoding ,Ordinal Encoding,One-Hot Encoding"></a>Label Encoding ,Ordinal Encoding,One-Hot Encoding</h2><ul>
<li>인코딩은 문자 데이터를 수치로 변환하는 방법론 중의 하나이다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 분류모형</span></span><br><span class="line"><span class="comment"># 종속변수(양성,음성)</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">temp = pd.DataFrame(&#123;<span class="string">&#x27;Food_Name&#x27;</span>: [<span class="string">&#x27;Apple&#x27;</span>, <span class="string">&#x27;Chicken&#x27;</span>, <span class="string">&#x27;Broccoli&#x27;</span>], </span><br><span class="line">                     <span class="string">&#x27;Calories&#x27;</span>: [<span class="number">95</span>, <span class="number">231</span>, <span class="number">50</span>]&#125;)</span><br><span class="line"></span><br><span class="line">encoder = LabelEncoder()</span><br><span class="line">encoder.fit(temp[<span class="string">&#x27;Food_Name&#x27;</span>])</span><br><span class="line">labels = encoder.transform(temp[<span class="string">&#x27;Food_Name&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(temp[<span class="string">&#x27;Food_Name&#x27;</span>]), <span class="string">&quot;==&gt;&quot;</span>, labels)</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Apple&#39;, &#39;Chicken&#39;, &#39;Broccoli&#39;] ==&gt; [0 2 1]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Ordinal Encoding은 독립변수로만 사용</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OrdinalEncoder</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">temp = pd.DataFrame(&#123;<span class="string">&#x27;Food_Name&#x27;</span>: [<span class="string">&#x27;Apple&#x27;</span>, <span class="string">&#x27;Chicken&#x27;</span>, <span class="string">&#x27;Broccoli&#x27;</span>], </span><br><span class="line">                     <span class="string">&#x27;Calories&#x27;</span>: [<span class="number">95</span>, <span class="number">231</span>, <span class="number">50</span>]&#125;)</span><br><span class="line"></span><br><span class="line">encoder = OrdinalEncoder()</span><br><span class="line">labels = encoder.fit_transform(temp[[<span class="string">&#x27;Food_Name&#x27;</span>]])</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(temp[<span class="string">&#x27;Food_Name&#x27;</span>]), <span class="string">&quot;==&gt;&quot;</span>, labels.tolist())</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Apple&#39;, &#39;Chicken&#39;, &#39;Broccoli&#39;] ==&gt; [[0.0], [2.0], [1.0]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">temp = pd.DataFrame(&#123;<span class="string">&#x27;Food_Name&#x27;</span>: [<span class="string">&#x27;Apple&#x27;</span>, <span class="string">&#x27;Chicken&#x27;</span>, <span class="string">&#x27;Broccoli&#x27;</span>],</span><br><span class="line">                     <span class="string">&#x27;Calories&#x27;</span>: [<span class="number">95</span>, <span class="number">231</span>, <span class="number">50</span>]&#125;)</span><br><span class="line"></span><br><span class="line">temp[<span class="string">&#x27;Food_No&#x27;</span>] = temp.Food_Name.replace(to_replace = [<span class="string">&#x27;Apple&#x27;</span>, <span class="string">&#x27;Chicken&#x27;</span>, <span class="string">&#x27;Broccoli&#x27;</span>], value = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(temp[[<span class="string">&#x27;Food_Name&#x27;</span>, <span class="string">&#x27;Food_No&#x27;</span>]])</span><br></pre></td></tr></table></figure>

<pre><code>  Food_Name  Food_No
0     Apple        1
1   Chicken        2
2  Broccoli        3
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#One-Hot Encoding</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelBinarizer</span><br><span class="line"></span><br><span class="line">temp = pd.DataFrame(&#123;<span class="string">&#x27;Food_Name&#x27;</span>: [<span class="string">&#x27;Apple&#x27;</span>, <span class="string">&#x27;Chicken&#x27;</span>, <span class="string">&#x27;Broccoli&#x27;</span>], </span><br><span class="line">                     <span class="string">&#x27;Calories&#x27;</span>: [<span class="number">95</span>, <span class="number">231</span>, <span class="number">50</span>]&#125;)</span><br><span class="line"></span><br><span class="line">encoder = LabelBinarizer()</span><br><span class="line">encoder.fit(temp[<span class="string">&#x27;Food_Name&#x27;</span>])</span><br><span class="line">transformed = encoder.transform(temp[<span class="string">&#x27;Food_Name&#x27;</span>])</span><br><span class="line">ohe_df = pd.DataFrame(transformed)</span><br><span class="line">temp = pd.concat([temp, ohe_df], axis=<span class="number">1</span>).drop([<span class="string">&#x27;Food_Name&#x27;</span>], axis=<span class="number">1</span>)</span><br><span class="line">temp.columns = [<span class="string">&#x27;Calories&#x27;</span>, <span class="string">&#x27;Food_Name_Apple&#x27;</span>, <span class="string">&#x27;Food_Name_Broccoli&#x27;</span>, <span class="string">&#x27;Food_Name_Chicken&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(temp)</span><br><span class="line"><span class="built_in">print</span>(temp.shape)</span><br></pre></td></tr></table></figure>

<pre><code>   Calories  Food_Name_Apple  Food_Name_Broccoli  Food_Name_Chicken
0        95                1                   0                  0
1       231                0                   0                  1
2        50                0                   1                  0
(3, 4)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">temp = pd.DataFrame(&#123;<span class="string">&#x27;Food_Name&#x27;</span>: [<span class="string">&#x27;Apple&#x27;</span>, <span class="string">&#x27;Chicken&#x27;</span>, <span class="string">&#x27;Broccoli&#x27;</span>], </span><br><span class="line">                     <span class="string">&#x27;Calories&#x27;</span>: [<span class="number">95</span>, <span class="number">231</span>, <span class="number">50</span>]&#125;)</span><br><span class="line"></span><br><span class="line">temp = pd.get_dummies(temp)</span><br><span class="line"><span class="built_in">print</span>(temp)</span><br><span class="line"><span class="built_in">print</span>(temp.shape)</span><br></pre></td></tr></table></figure>

<pre><code>   Calories  Food_Name_Apple  Food_Name_Broccoli  Food_Name_Chicken
0        95                1                   0                  0
1       231                0                   0                  1
2        50                0                   1                  0
(3, 4)
</code></pre>
<ul>
<li>본 데이터 적용<ul>
<li>여기서는 Ordinal Encoding적용 안함(실전에는 필요)</li>
</ul>
</li>
<li>원 핫 인코딩 적용</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">all_df = pd.get_dummies(all_df).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">all_df.shape</span><br></pre></td></tr></table></figure>




<pre><code>(2919, 258)
</code></pre>
<ul>
<li>train,test 데이터 합쳐서 진행</li>
<li>train,test 데이터 재분리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = all_df.iloc[:<span class="built_in">len</span>(y), :]</span><br><span class="line">test = all_df.iloc[<span class="built_in">len</span>(y):, :]</span><br><span class="line"></span><br><span class="line">X.shape, y.shape, test.shape</span><br></pre></td></tr></table></figure>




<pre><code>((1460, 258), (1460,), (1459, 258))
</code></pre>
<ul>
<li>머신러닝을 위한 데이터 전처리가 끝남</li>
</ul>
<h2 id="과제"><a href="#과제" class="headerlink" title="과제"></a>과제</h2><ul>
<li>남은 시간동안 교제를 모고 머신러닝 학습 및 RMSE 구하세요.</li>
<li>데이터셋 분리</li>
</ul>
<ul>
<li>X데이터를 X-train, X_test, y_train, y_test로 분리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(</span><br><span class="line">    <span class="comment">#독립변수, 종속변수</span></span><br><span class="line">    X, y, test_size = <span class="number">0.3</span>, random_state = <span class="number">0</span> </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">X_train.shape, X_test.shape, y_train.shape, y_test.shape</span><br></pre></td></tr></table></figure>




<pre><code>((1022, 258), (438, 258), (1022,), (438,))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span>  LinearRegression</span><br><span class="line">lr_model = LinearRegression()</span><br><span class="line">lr_model.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(lr_model.score(X_train,y_train))</span><br><span class="line"><span class="built_in">print</span>(lr_model.score(X_test,y_test))</span><br></pre></td></tr></table></figure>

<pre><code>0.9513387660720953
-52492042.95698945
</code></pre>
<p><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rmse</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="keyword">return</span> np.sqrt(mean_squared_error(y_true, y_pred))</span><br></pre></td></tr></table></figure>

<h3 id="머신러닝-모형-정의-검증평가"><a href="#머신러닝-모형-정의-검증평가" class="headerlink" title="머신러닝 모형 정의, 검증평가"></a>머신러닝 모형 정의, 검증평가</h3><ul>
<li>교차검증함수 만들기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#다양한 모형</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor </span><br><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMRegressor</span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 교차 검증</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, cross_val_score </span><br><span class="line"></span><br><span class="line"><span class="comment"># 모형 정의</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cv_rmse</span>(<span class="params">model, n_folds=<span class="number">5</span></span>):</span><br><span class="line">    cv = KFold(n_splits = n_folds, random_state=<span class="number">42</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line">    rmse_list = np.sqrt(-cross_val_score(model, X, y, scoring=<span class="string">&#x27;neg_mean_squared_error&#x27;</span>, cv=cv))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;CV RMSE Value List:&#x27;</span>, np.<span class="built_in">round</span>(rmse_list, <span class="number">4</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;CV RMSE mean List:&#x27;</span>, np.<span class="built_in">round</span>(np.mean(rmse_list), <span class="number">4</span>))</span><br><span class="line">    <span class="keyword">return</span> rmse_list</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rmse_scores = &#123;&#125; </span><br><span class="line">lr_model = LinearRegression()</span><br><span class="line"></span><br><span class="line">score = cv_rmse(lr_model, n_folds=<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;linear regression - mean : &#123;:.4f&#125; (std: &#123;:.4f&#125;)&#x27;</span>.<span class="built_in">format</span>(score.mean(), score.std()))</span><br><span class="line"></span><br><span class="line">rmse_scores[<span class="string">&#x27;Linear Regression&#x27;</span>] = (score.mean(), score.std())</span><br></pre></td></tr></table></figure>

<pre><code>CV RMSE Value List: [1.2790000e-01 1.2580000e-01 1.1136811e+03 1.5580000e-01 9.2491152e+03]
CV RMSE mean List: 2072.6412
linear regression - mean : 2072.6412 (std: 3614.0617)
</code></pre>
<h3 id="제출방법"><a href="#제출방법" class="headerlink" title="제출방법"></a>제출방법</h3><ul>
<li></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_predict</span><br><span class="line"></span><br><span class="line"><span class="comment"># X = all_df.iloc[:len(y), :]</span></span><br><span class="line"><span class="comment"># X_test = all_df.iloc[len(y):, :]</span></span><br><span class="line"><span class="comment"># X.shape, y.shape, X_test.shape</span></span><br><span class="line"></span><br><span class="line">lr_model_fit = lr_model.fit(X_train, y_train)</span><br><span class="line">final_preds = np.floor(np.expm1(lr_model_fit.predict(test)))</span><br><span class="line"><span class="built_in">print</span>(final_preds)</span><br></pre></td></tr></table></figure>

<pre><code>[109089. 160608. 181348. ... 167207. 109945. 204485.]


/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in expm1
  
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">submission = pd.read_csv(DATA_PATH + <span class="string">&quot;sample_submission.csv&quot;</span>)</span><br><span class="line">submission.iloc[:,<span class="number">1</span>] = final_preds</span><br><span class="line"><span class="built_in">print</span>(submission.head())</span><br><span class="line">submission.to_csv(<span class="string">&quot;submission.csv&quot;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<pre><code>     Id  SalePrice
0  1461   109089.0
1  1462   160608.0
2  1463   181348.0
3  1464   195114.0
4  1465   189188.0
</code></pre>
<h2 id="모형-만들기"><a href="#모형-만들기" class="headerlink" title="모형 만들기"></a>모형 만들기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr_model = LinearRegression()</span><br><span class="line">lr_model.fit(X_train, y_train) </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(lr_model.score(X_train, y_train))</span><br><span class="line"><span class="built_in">print</span>(lr_model.score(X_test, y_test))</span><br></pre></td></tr></table></figure>

<pre><code>0.9513387660720953
-52492042.95698945
</code></pre>
<h2 id="번외-평가지표"><a href="#번외-평가지표" class="headerlink" title="번외)평가지표"></a>번외)평가지표</h2><p>-MAE, MSE, RMSE</p>
<h3 id="MAE"><a href="#MAE" class="headerlink" title="MAE"></a>MAE</h3><ul>
<li>실제값과 예측값의 차이, 오차와 오차들의 절댓값 평균을 말함.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mean_absolute_error</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    error = <span class="number">0</span> </span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># yt : 실젯값</span></span><br><span class="line">        <span class="comment"># yp : 예측값</span></span><br><span class="line">        error = error + np.<span class="built_in">abs</span>(yt - yp)</span><br><span class="line">        <span class="comment"># 절댓값 오차의 평균</span></span><br><span class="line">    mae = error / <span class="built_in">len</span>(y_true)</span><br><span class="line">    <span class="keyword">return</span> mae</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mean_squared_error</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    error = <span class="number">0</span> </span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># yt : 실젯값</span></span><br><span class="line">        <span class="comment"># yp : 예측값</span></span><br><span class="line">        error = error + (yt - yp) ** <span class="number">2</span></span><br><span class="line">        <span class="comment"># 제곱값 오차의 평균</span></span><br><span class="line">    mse = error / <span class="built_in">len</span>(y_true)</span><br><span class="line">    <span class="keyword">return</span> mse</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">root_mean_squared_error</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    error = <span class="number">0</span> </span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># yt : 실젯값</span></span><br><span class="line">        <span class="comment"># yp : 예측값</span></span><br><span class="line">        error = error + (yt - yp) ** <span class="number">2</span></span><br><span class="line">        <span class="comment"># 제곱값 오차의 평균</span></span><br><span class="line">    mse = error / <span class="built_in">len</span>(y_true)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 제곱근 추가</span></span><br><span class="line">    rmse = np.<span class="built_in">round</span>(np.sqrt(mse), <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">return</span> rmse</span><br><span class="line"></span><br><span class="line">y_true = [<span class="number">400</span>, <span class="number">300</span>, <span class="number">800</span>]</span><br><span class="line">y_pred = [<span class="number">380</span>, <span class="number">320</span>, <span class="number">777</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MAE:&quot;</span>, mean_absolute_error(y_true, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MSE:&quot;</span>, mean_squared_error(y_true, y_pred))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;RMSE:&quot;</span>, root_mean_squared_error(y_true, y_pred))</span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-06T07:38:20.000Z" title="2022. 7. 6. 오후 4:38:20">2022-07-06</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-06T07:44:05.811Z" title="2022. 7. 6. 오후 4:44:05">2022-07-06</time></span><span class="level-item">an hour read (About 8039 words)</span></div></div><div class="content"><hr>
<h1 id="title-‘REVIEW-그래프와-머신러닝’"><a href="#title-‘REVIEW-그래프와-머신러닝’" class="headerlink" title="title: ‘REVIEW-그래프와 머신러닝’"></a><strong>title: ‘REVIEW-그래프와 머신러닝’</strong></h1><h1 id="date-‘2022-07-06-09-00’"><a href="#date-‘2022-07-06-09-00’" class="headerlink" title="date: ‘2022-07-06 09:00’"></a><strong>date: ‘2022-07-06 09:00’</strong></h1><hr>
<h2 id="데이터-분석-머신러닝-딥러닝-프로세스"><a href="#데이터-분석-머신러닝-딥러닝-프로세스" class="headerlink" title="데이터 분석(머신러닝, 딥러닝) 프로세스"></a>데이터 분석(머신러닝, 딥러닝) 프로세스</h2><ul>
<li>데이터 불러오기<ul>
<li>CSV, 오라클, MySQL, PostgreSQL, 클라우드 DB연동</li>
</ul>
</li>
<li>탐색적 자료 분석<ul>
<li>데이터 전처리 및 가공</li>
</ul>
</li>
<li>잠정적인 컬럼의 갯수를 지정</li>
<li>머신러닝 모델(&#x3D;통계 모델링, t.test, 분산분석, 교차분석)</li>
<li>머신러닝 모델의 경우 배포(지금은 다루지 않음)</li>
</ul>
<ul>
<li>JSP-스프링 웹개발 시 배우게 됨.</li>
</ul>
<ul>
<li><p>통계 모델링 경우 p-value값 기준으로 귀무가설 및 대립가설 검정</p>
</li>
<li><p>(공통) 결과보고서를 작성 필요.</p>
</li>
</ul>
<ul>
<li>.PPT준비</li>
</ul>
<h2 id="그래프-복습"><a href="#그래프-복습" class="headerlink" title="그래프 복습"></a>그래프 복습</h2><ul>
<li>수치형 데이터 시각화</li>
<li>범주형 데이터 시각화</li>
<li>데이터 관계 시각화</li>
</ul>
<ul>
<li>matplotlib 라이브러리 방법(복잡)</li>
<li>seaborn 라이브러리 방법(단순)</li>
</ul>
<h3 id="수치형-데이터-시각화"><a href="#수치형-데이터-시각화" class="headerlink" title="수치형 데이터 시각화"></a>수치형 데이터 시각화</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">titanic = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(titanic.head(<span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<pre><code>   survived  pclass     sex   age  sibsp  parch     fare embarked   class  \
0         0       3    male  22.0      1      0   7.2500        S   Third   
1         1       1  female  38.0      1      0  71.2833        C   First   
2         1       3  female  26.0      0      0   7.9250        S   Third   
3         1       1  female  35.0      1      0  53.1000        S   First   
4         0       3    male  35.0      0      0   8.0500        S   Third   
5         0       3    male   NaN      0      0   8.4583        Q   Third   
6         0       1    male  54.0      0      0  51.8625        S   First   
7         0       3    male   2.0      3      1  21.0750        S   Third   
8         1       3  female  27.0      0      2  11.1333        S   Third   
9         1       2  female  14.0      1      0  30.0708        C  Second   

     who  adult_male deck  embark_town alive  alone  
0    man        True  NaN  Southampton    no  False  
1  woman       False    C    Cherbourg   yes  False  
2  woman       False  NaN  Southampton   yes   True  
3  woman       False    C  Southampton   yes  False  
4    man        True  NaN  Southampton    no   True  
5    man        True  NaN   Queenstown    no   True  
6    man        True    E  Southampton    no   True  
7  child       False  NaN  Southampton    no  False  
8  woman       False  NaN  Southampton   yes  False  
9  child       False  NaN    Cherbourg   yes  False  
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 히스토그램</span></span><br><span class="line">sns.histplot(data= titanic, x = <span class="string">&#x27;age&#x27;</span>,bins=<span class="number">10</span>, hue= <span class="string">&#x27;alive&#x27;</span>,multiple=<span class="string">&#x27;stack&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf86744d10&gt;
</code></pre>
<p><img src="/images/day0706/output_5_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 확률밀도추정(KDE) 함수 그래프- 히스토그램을 부드러운 곡선 형태로 표현한다.</span></span><br><span class="line"><span class="comment"># 연속형 데이터 1개만 쓸 때 사용, y축은 수량의 비율</span></span><br><span class="line">sns.kdeplot(data =titanic, x =<span class="string">&#x27;age&#x27;</span>,hue= <span class="string">&#x27;alive&#x27;</span>,multiple=<span class="string">&#x27;stack&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf856ddf50&gt;
</code></pre>
<p><img src="/images/day0706/output_6_1.png" alt="png"></p>
<ul>
<li>분포도</li>
<li>수치형 데이터 한개 컬럼의 분포를 나타내는 그래프</li>
</ul>
<ul>
<li>정규분포인가?</li>
</ul>
<ul>
<li>ditstplot()히스토그램에 kdeplot와,rugplot을 한번에 그림</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.displot(data =titanic, x =<span class="string">&#x27;age&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.FacetGrid at 0x7faf85734850&gt;
</code></pre>
<p><img src="/images/day0706/output_8_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.displot(data =titanic, x =<span class="string">&#x27;age&#x27;</span>,kind=<span class="string">&#x27;kde&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.FacetGrid at 0x7faf85590050&gt;
</code></pre>
<p><img src="/images/day0706/output_9_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.displot(data =titanic, x =<span class="string">&#x27;age&#x27;</span>,kde =<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.FacetGrid at 0x7faf85621910&gt;
</code></pre>
<p><img src="/images/day0706/output_10_1.png" alt="png"></p>
<h2 id="범주형-데이터-시각화"><a href="#범주형-데이터-시각화" class="headerlink" title="범주형 데이터 시각화"></a>범주형 데이터 시각화</h2><ul>
<li>x축 범주형, y축 수치 데이터</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 막대 그래프-matplotlib은 개수를 세는 작업을 해줘야하지만 seaborn은 알아서 해준다.</span></span><br><span class="line">sns.barplot(x=<span class="string">&#x27;class&#x27;</span>,y=<span class="string">&#x27;fare&#x27;</span>,data= titanic)</span><br><span class="line"><span class="comment"># 클래스 별로 가격을 표시했지만 그 가격은 평균치를 나타내고 에러바(오차막대)를 만들어줌</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf8540f810&gt;
</code></pre>
<p><img src="/images/day0706/output_12_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 포인트 플롯</span></span><br><span class="line">sns.pointplot(x=<span class="string">&#x27;class&#x27;</span>,y=<span class="string">&#x27;fare&#x27;</span>,data=titanic)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf853f1890&gt;
</code></pre>
<p><img src="/images/day0706/output_13_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># boxplot(박스플롯)</span></span><br><span class="line">sns.boxplot(x=<span class="string">&#x27;class&#x27;</span>,y=<span class="string">&#x27;age&#x27;</span>,data=titanic)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf8535b1d0&gt;
</code></pre>
<p><img src="/images/day0706/output_14_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#바이올린 플롯</span></span><br><span class="line">sns.violinplot(x= <span class="string">&#x27;class&#x27;</span>, y=<span class="string">&#x27;age&#x27;</span>, hue=<span class="string">&#x27;sex&#x27;</span>,data=titanic,split =<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf8527f590&gt;
</code></pre>
<p><img src="/images/day0706/output_15_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 카운트 플롯</span></span><br><span class="line"><span class="comment"># - 범주형데이터의 갯수 확인할 때 사용</span></span><br><span class="line">sns.countplot(x = <span class="string">&#x27;alive&#x27;</span>, data= titanic)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf852701d0&gt;
</code></pre>
<p><img src="/images/day0706/output_16_1.png" alt="png"></p>
<h2 id="데이터-관계-시각화"><a href="#데이터-관계-시각화" class="headerlink" title="데이터 관계 시각화"></a>데이터 관계 시각화</h2><ul>
<li>여러 데이터 사이의 관계도 파악을 위한 그래</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 히트맵</span></span><br><span class="line">flights =sns.load_dataset(<span class="string">&#x27;flights&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(flights.head(<span class="number">7</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>   year month  passengers
0  1949   Jan         112
1  1949   Feb         118
2  1949   Mar         132
3  1949   Apr         129
4  1949   May         121
5  1949   Jun         135
6  1949   Jul         148
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  각 연도별 월별 승객수 구하기</span></span><br><span class="line"><span class="comment"># flights[&#x27;year&#x27;].value_count()</span></span><br><span class="line">flights_pivot = flights.pivot(index=<span class="string">&#x27;month&#x27;</span>, columns=<span class="string">&#x27;year&#x27;</span>, values=<span class="string">&#x27;passengers&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(flights_pivot)</span><br></pre></td></tr></table></figure>

<pre><code>year   1949  1950  1951  1952  1953  1954  1955  1956  1957  1958  1959  1960
month                                                                        
Jan     112   115   145   171   196   204   242   284   315   340   360   417
Feb     118   126   150   180   196   188   233   277   301   318   342   391
Mar     132   141   178   193   236   235   267   317   356   362   406   419
Apr     129   135   163   181   235   227   269   313   348   348   396   461
May     121   125   172   183   229   234   270   318   355   363   420   472
Jun     135   149   178   218   243   264   315   374   422   435   472   535
Jul     148   170   199   230   264   302   364   413   465   491   548   622
Aug     148   170   199   242   272   293   347   405   467   505   559   606
Sep     136   158   184   209   237   259   312   355   404   404   463   508
Oct     119   133   162   191   211   229   274   306   347   359   407   461
Nov     104   114   146   172   180   203   237   271   305   310   362   390
Dec     118   140   166   194   201   229   278   306   336   337   405   432
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.heatmap(data = flights_pivot)<span class="comment"># 시각화를 통해 1960년대 8월에 가장 사람들 수가 많았다.</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf851e8610&gt;
</code></pre>
<p><img src="/images/day0706/output_20_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 라인플롯</span></span><br><span class="line">sns.lineplot(x=<span class="string">&#x27;year&#x27;</span>,y=<span class="string">&#x27;passengers&#x27;</span>,data=flights)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf85117f10&gt;
</code></pre>
<p><img src="/images/day0706/output_21_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 산점도</span></span><br><span class="line">tips =sns.load_dataset(<span class="string">&#x27;tips&#x27;</span>)</span><br><span class="line">tips.head(<span class="number">8</span>)</span><br><span class="line"><span class="comment"># 영수증금액/ 팁/ 성별/ 담배/ 요일/ 시간/ 같이먹은 사람의 수(카운트데이터)</span></span><br></pre></td></tr></table></figure>





  <div id="df-98401926-69e1-464f-9f4f-ce6a7afd0680">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>total_bill</th>
      <th>tip</th>
      <th>sex</th>
      <th>smoker</th>
      <th>day</th>
      <th>time</th>
      <th>size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>16.99</td>
      <td>1.01</td>
      <td>Female</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.34</td>
      <td>1.66</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>21.01</td>
      <td>3.50</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>23.68</td>
      <td>3.31</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>24.59</td>
      <td>3.61</td>
      <td>Female</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>4</td>
    </tr>
    <tr>
      <th>5</th>
      <td>25.29</td>
      <td>4.71</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>4</td>
    </tr>
    <tr>
      <th>6</th>
      <td>8.77</td>
      <td>2.00</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>2</td>
    </tr>
    <tr>
      <th>7</th>
      <td>26.88</td>
      <td>3.12</td>
      <td>Male</td>
      <td>No</td>
      <td>Sun</td>
      <td>Dinner</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-98401926-69e1-464f-9f4f-ce6a7afd0680')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-98401926-69e1-464f-9f4f-ce6a7afd0680 button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-98401926-69e1-464f-9f4f-ce6a7afd0680&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;output_type&#39;] = &#39;display_data&#39;;
      await google.colab.output.renderOutput(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 두개의 연속형 데이터</span></span><br><span class="line">sns.scatterplot(x=<span class="string">&#x27;total_bill&#x27;</span>,y=<span class="string">&#x27;tip&#x27;</span>,data= tips)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf8564f0d0&gt;
</code></pre>
<p><img src="/images/day0706/output_23_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.scatterplot(x=<span class="string">&#x27;total_bill&#x27;</span>,y=<span class="string">&#x27;tip&#x27;</span>,hue =<span class="string">&#x27;time&#x27;</span>,data= tips)</span><br><span class="line"><span class="comment"># 저녁에 더 많은 팁을 준다.</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf854beed0&gt;
</code></pre>
<p><img src="/images/day0706/output_24_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.scatterplot(x=<span class="string">&#x27;total_bill&#x27;</span>,y=<span class="string">&#x27;tip&#x27;</span>,hue =<span class="string">&#x27;sex&#x27;</span>,data= tips)</span><br><span class="line"><span class="comment"># 남자들의 경우 영수증 금액이 클수록 팁의 양(+)에 상관관계가 있다.</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf863f4750&gt;
</code></pre>
<p><img src="/images/day0706/output_25_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 회귀선</span></span><br><span class="line"><span class="comment">#선형회귀 적합선(상관관계를 표현한 선)을 포함한 산점도를 그리자.</span></span><br><span class="line">sns.regplot(x= <span class="string">&#x27;total_bill&#x27;</span>,y= <span class="string">&#x27;tip&#x27;</span>, data =tips)</span><br><span class="line"><span class="comment"># 30달라를 냈을 때 4달러의 팁이 예상됨.</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf866085d0&gt;
</code></pre>
<p><img src="/images/day0706/output_26_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(x=<span class="string">&#x27;sex&#x27;</span>,data =tips)</span><br><span class="line"><span class="comment"># 남자와 여자를 비교할 때 남자들이 자주 팁을 준다.</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf867a81d0&gt;
</code></pre>
<p><img src="/images/day0706/output_27_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(x=<span class="string">&#x27;sex&#x27;</span>,hue=<span class="string">&#x27;time&#x27;</span>,data=tips)</span><br><span class="line"><span class="comment"># 남자가 여자보다 저녁시간에 팁주는 횟수가 많다.</span></span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf86796b10&gt;
</code></pre>
<p><img src="/images/day0706/output_28_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.relplot(x=<span class="string">&quot;total_bill&quot;</span>,y=<span class="string">&quot;tip&quot;</span>,hue=<span class="string">&#x27;size&#x27;</span>,data=tips)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.FacetGrid at 0x7faf8692f450&gt;
</code></pre>
<p><img src="/images/day0706/output_29_1.png" alt="png"></p>
<h2 id="머신러닝-리뷰"><a href="#머신러닝-리뷰" class="headerlink" title="머신러닝 리뷰"></a>머신러닝 리뷰</h2><ul>
<li>가장 인기 있는 모델</li>
</ul>
<ul>
<li>lightGBM, XGBoost</li>
</ul>
<h3 id="선형회귀"><a href="#선형회귀" class="headerlink" title="선형회귀"></a>선형회귀</h3><ul>
<li>선형회귀식을 찾는 것이 중요</li>
<li>$y &#x3D;3 x +4$ 에 근사한 데이터 50개 생성</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 시드값 고정- 랜덤한 내용이 다른 사람들과 같은 결과를 얻기 위해</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">intercept = <span class="number">4</span> <span class="comment"># 절편, 상수</span></span><br><span class="line">slope = <span class="number">3</span> <span class="comment"># 기울기</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 변동성 주기 위해 노이즈 생성</span></span><br><span class="line">noise = np.random.randn(<span class="number">50</span>, <span class="number">1</span>)</span><br><span class="line">x = <span class="number">5</span> * np.random.rand(<span class="number">50</span>, <span class="number">1</span>) <span class="comment"># 0과 5사이의 실숫값 50개 생성</span></span><br><span class="line">y = slope * x + intercept + noise</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 프레임 생성</span></span><br><span class="line">data = pd.DataFrame(&#123;<span class="string">&#x27;X&#x27;</span> : x[:, <span class="number">0</span>], <span class="string">&#x27;Y&#x27;</span> : y[:, <span class="number">0</span>]&#125;)</span><br><span class="line"><span class="built_in">print</span>(data)</span><br></pre></td></tr></table></figure>

<pre><code>           X          Y
0   0.794848   8.148596
1   0.551876   6.055784
2   3.281648  14.823682
3   0.690915   8.313637
4   0.982912   8.816293
5   1.843626   8.553600
6   4.104966  17.264987
7   0.485506   5.305162
8   4.189725  16.465955
9   0.480492   5.852075
10  4.882297  18.790936
11  2.343256  12.484042
12  4.883805  19.412454
13  3.024228  13.194358
14  3.696318  15.532817
15  0.195939   4.921491
16  1.414035   9.736184
17  0.600983   5.597790
18  1.480701   8.755171
19  0.593639   4.926820
20  1.589916   6.216758
21  2.071315  10.867564
22  0.320737   5.826649
23  3.462361  13.644917
24  2.833007  14.768776
25  1.326947   6.526477
26  2.616240  11.894479
27  0.469703   5.221924
28  2.879732  14.171977
29  4.646481  19.408802
30  1.592845   8.933482
31  3.337052  14.389318
32  0.658989   5.089182
33  3.581636  12.764112
34  1.447030   7.993179
35  0.915957   6.904219
36  2.932565  14.027985
37  0.100538   5.503993
38  4.144700  16.046774
39  0.023477   3.768129
40  3.389083  13.118695
41  1.350040   6.630102
42  3.675970  13.321640
43  4.810943  20.383604
44  1.243766   7.221645
45  2.880787  12.204286
46  2.960210  11.627834
47  2.861260  13.361269
48  1.115408   5.732327
49  4.763745  18.078495
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(data[<span class="string">&#x27;X&#x27;</span>], data[<span class="string">&#x27;Y&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0706/output_33_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns </span><br><span class="line">sns.scatterplot(x = <span class="string">&#x27;X&#x27;</span>, y = <span class="string">&#x27;Y&#x27;</span>, data = data)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faf85003c10&gt;
</code></pre>
<p><img src="/images/day0706/output_34_1.png" alt="png"></p>
<h4 id="선형회귀-모형-훈련"><a href="#선형회귀-모형-훈련" class="headerlink" title="선형회귀 모형 훈련"></a>선형회귀 모형 훈련</h4><ul>
<li>모형 생성 후, 회귀계수 3과 y절편 4에 근사한 값이 나와야 함</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line">lr_model = LinearRegression()<span class="comment">#,선형회귀 모델</span></span><br><span class="line">lr_model.fit(x,y)<span class="comment">##모델훈련</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;y절편:&#x27;</span>, lr_model.intercept_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;회귀계수:&#x27;</span>, lr_model.coef_)</span><br></pre></td></tr></table></figure>

<pre><code>y절편: [4.05757639]
회귀계수: [[3.03754061]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 예측값</span></span><br><span class="line">y_pred = lr_model.predict(x)</span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(x, y)</span><br><span class="line">ax.plot(x, y_pred, color=<span class="string">&#x27;green&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># slope, intercept </span></span><br><span class="line">label = <span class="string">&#x27;slope: &#123;&#125;\nintercept: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">round</span>(lr_model.coef_[<span class="number">0</span>][<span class="number">0</span>], <span class="number">2</span>), <span class="built_in">round</span>(lr_model.intercept_[<span class="number">0</span>], <span class="number">2</span>))</span><br><span class="line">ax.text(<span class="number">3.5</span>, <span class="number">4</span>, label, style =<span class="string">&#x27;italic&#x27;</span>, </span><br><span class="line">        fontsize = <span class="number">10</span>, color =<span class="string">&quot;green&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0706/output_37_0.png" alt="png"></p>
<h3 id="로지스틱-회귀"><a href="#로지스틱-회귀" class="headerlink" title="로지스틱 회귀"></a>로지스틱 회귀</h3><p>- </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">arr, scale=<span class="number">1</span></span>):</span><br><span class="line">    arr = np.asarray(arr)</span><br><span class="line">    result = <span class="number">1</span>/(<span class="number">1</span> + np.exp(-arr*scale))</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line">x = np.linspace(-<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line">y = sigmoid(x)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.plot(x, y)</span><br><span class="line">ax.grid(which=<span class="string">&#x27;major&#x27;</span>, axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>)</span><br><span class="line">ax.axvline(x=<span class="number">0</span>, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, linewidth=<span class="number">1</span>)</span><br><span class="line">ax.set_ylim(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">ax.set_yticks([<span class="number">0</span>, <span class="number">1</span>, <span class="number">0.5</span>])</span><br><span class="line">ax.text(<span class="number">0</span>-<span class="number">0.1</span>, <span class="number">0.5</span>, <span class="string">&#x27;0.5&#x27;</span>, ha=<span class="string">&#x27;right&#x27;</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;Sigmoid Graph&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src="/images/day0706/output_39_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 라이브러리 불러오기</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report, confusion_matrix</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 가져오기</span></span><br><span class="line">x = np.arange(<span class="number">10</span>).reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">y = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델 생성 및 학습</span></span><br><span class="line">model = LogisticRegression(solver=<span class="string">&#x27;liblinear&#x27;</span>, C=<span class="number">10.0</span>, random_state=<span class="number">0</span>)</span><br><span class="line">model.fit(x, y)</span><br></pre></td></tr></table></figure>




<pre><code>LogisticRegression(C=10.0, random_state=0, solver=&#39;liblinear&#39;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 모형 평가</span></span><br><span class="line">p_pred =model.predict_proba(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;p_pred&#x27;</span>,p_pred,sep =<span class="string">&#x27;\n&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>p_pred
[[0.97979027 0.02020973]
 [0.94958202 0.05041798]
 [0.87976149 0.12023851]
 [0.73975066 0.26024934]
 [0.52477284 0.47522716]
 [0.30020373 0.69979627]
 [0.1428487  0.8571513 ]
 [0.06080627 0.93919373]
 [0.02453462 0.97546538]
 [0.00967652 0.99032348]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">y_pred = model.predict(x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;y_pred&#x27;</span>,y_pred)</span><br></pre></td></tr></table></figure>

<pre><code>y_pred [0 0 0 0 0 1 1 1 1 1]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(x, y)</span><br><span class="line">ax.plot(x, p_pred[:, <span class="number">1</span>], color = <span class="string">&#x27;black&#x27;</span>,  marker=<span class="string">&#x27;o&#x27;</span>, markersize=<span class="number">6</span>)</span><br><span class="line">ax.plot()</span><br><span class="line"></span><br><span class="line">ax.set_xticks(x)</span><br><span class="line">ax.set_yticks(np.arange(<span class="number">0</span>, <span class="number">1.1</span>, <span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line">ax.grid(which=<span class="string">&#x27;major&#x27;</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0706/output_43_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conf_m = confusion_matrix(y,y_pred)</span><br><span class="line"><span class="built_in">print</span>(conf_m)</span><br></pre></td></tr></table></figure>

<pre><code>[[5 0]
 [0 5]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cm = confusion_matrix(y, y_pred)</span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots(figsize=(<span class="number">8</span>, <span class="number">8</span>))</span><br><span class="line">ax.imshow(cm, cmap = <span class="string">&#x27;Pastel1&#x27;</span>)<span class="comment"># pastel2는 색깔임 &#x27;GnBu&#x27;</span></span><br><span class="line">ax.grid(<span class="literal">False</span>)</span><br><span class="line">ax.xaxis.<span class="built_in">set</span>(ticks=(<span class="number">0</span>, <span class="number">1</span>), ticklabels=(<span class="string">&#x27;Predicted 0&#x27;</span>, <span class="string">&#x27;Predicted 1&#x27;</span>))</span><br><span class="line">ax.yaxis.<span class="built_in">set</span>(ticks=(<span class="number">0</span>, <span class="number">1</span>), ticklabels=(<span class="string">&#x27;Actual 0&#x27;</span>, <span class="string">&#x27;Actual 1&#x27;</span>))</span><br><span class="line">ax.set_ylim(<span class="number">1.5</span>, -<span class="number">0.5</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">        ax.text(j, i, cm[i, j], ha=<span class="string">&#x27;center&#x27;</span>, va=<span class="string">&#x27;center&#x27;</span>, color=<span class="string">&#x27;black&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0706/output_45_0.png" alt="png"></p>
<h3 id="결정-트리"><a href="#결정-트리" class="headerlink" title="결정 트리"></a>결정 트리</h3><ul>
<li>분류와 회귀 문제에 모두 사용가능</li>
</ul>
<h3 id="주요-개념"><a href="#주요-개념" class="headerlink" title="주요 개념"></a>주요 개념</h3><ul>
<li>작동 원리<ul>
<li>데이터를 가장 잘 구분하는 조건을 정함.</li>
<li>조건을 기준으로 데이터를 두 범주로 나눔</li>
<li>나뉜 각 범주의 데이터를 구분하는 조건을 정함</li>
<li>각 조건을 기준으로 데이터를 두 범주로 나눔</li>
<li>언제까지 계속 분할할지 정한 후, 최종 결정 값을 구함.</li>
</ul>
</li>
<li>불순도(Impurity)<ul>
<li>한 범주 안에 서로 다른 데이터가 얼마나 섞여 있는지 나타냄</li>
<li>흰색과 검은색이 50:50으로 섞여 있다. (불순도 최대)</li>
<li>흰색과 검은색으로 완전 분리 되었다. (불순도 최소)</li>
</ul>
</li>
<li>엔트로피(Entropy)<ul>
<li>불확실한 정도를 의미함. 0 ~ 1로 정함.</li>
<li>흰색과 검은색이 50:50으로 섞여 있다. 엔트로피 1</li>
<li>흰색과 검은색으로 완전 분리 되었다. 엔트로피 0</li>
</ul>
</li>
<li>정보이득(Information Gain)<ul>
<li>1에서 엔트로피를 뺀 수치</li>
<li>정보 이득을 최대화하는 방향(엔트로피를 최소화 하는 방향)으로 노드를 분할함</li>
</ul>
</li>
<li>지니 불순도(Gini Impurity)<ul>
<li>지니 불순도 값이 클수록 불순도도 높고, 작을수록 불순도도 낮음. 엔트로피와 마찬가지로 지니 불순도가 낮아지는 방향으로 노드 분할함.</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split </span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns </span><br><span class="line"></span><br><span class="line"><span class="comment"># tips 데이터셋 </span></span><br><span class="line">titanic = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line">titanic.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 15 columns):
 #   Column       Non-Null Count  Dtype   
---  ------       --------------  -----   
 0   survived     891 non-null    int64   
 1   pclass       891 non-null    int64   
 2   sex          891 non-null    object  
 3   age          714 non-null    float64 
 4   sibsp        891 non-null    int64   
 5   parch        891 non-null    int64   
 6   fare         891 non-null    float64 
 7   embarked     889 non-null    object  
 8   class        891 non-null    category
 9   who          891 non-null    object  
 10  adult_male   891 non-null    bool    
 11  deck         203 non-null    category
 12  embark_town  889 non-null    object  
 13  alive        891 non-null    object  
 14  alone        891 non-null    bool    
dtypes: bool(2), category(2), float64(2), int64(4), object(5)
memory usage: 80.7+ KB
</code></pre>
<ul>
<li>suvived의 비율을 구한다</li>
</ul>
<ul>
<li>0: 사망자</li>
<li>1: 생존</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">titanic[<span class="string">&#x27;survived&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>




<pre><code>0    549
1    342
Name: survived, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">X = titanic[[<span class="string">&#x27;pclass&#x27;</span>, <span class="string">&#x27;parch&#x27;</span>, <span class="string">&#x27;fare&#x27;</span>]]</span><br><span class="line">y = titanic[<span class="string">&#x27;survived&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련데이터, 테스트 데이터 분리</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = <span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line">X_train.shape, X_test.shape, y_train.shape, y_test.shape</span><br></pre></td></tr></table></figure>




<pre><code>((623, 3), (268, 3), (623,), (268,))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tree_model = DecisionTreeClassifier()</span><br><span class="line">tree_model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">acc = tree_model.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;모형 정확도 : <span class="subst">&#123;acc:<span class="number">.3</span>f&#125;</span>&#x27;</span>) <span class="comment"># 정확도 측정</span></span><br></pre></td></tr></table></figure>

<pre><code>모형 정확도 : 0.675
</code></pre>
<h2 id="랜덤-포레스"><a href="#랜덤-포레스" class="headerlink" title="랜덤 포레스"></a>랜덤 포레스</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split </span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns </span><br><span class="line"></span><br><span class="line"><span class="comment"># tips 데이터셋 </span></span><br><span class="line">titanic = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line"></span><br><span class="line">X = titanic[[<span class="string">&#x27;pclass&#x27;</span>, <span class="string">&#x27;parch&#x27;</span>, <span class="string">&#x27;fare&#x27;</span>]]</span><br><span class="line">y = titanic[<span class="string">&#x27;survived&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련데이터, 테스트 데이터 분리</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = <span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델 훈련</span></span><br><span class="line">rf_model = RandomForestClassifier(random_state=<span class="number">42</span>) <span class="comment"># 랜덤 포레스트 정의</span></span><br><span class="line">rf_model.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">acc = rf_model.score(X_test, y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;모형 정확도 : <span class="subst">&#123;acc:<span class="number">.3</span>f&#125;</span>&#x27;</span>) <span class="comment"># 정확도 측정</span></span><br></pre></td></tr></table></figure>

<pre><code>모형 정확도 : 0.675
</code></pre>
<h2 id="XGBoost-2016-amp-LightGBM"><a href="#XGBoost-2016-amp-LightGBM" class="headerlink" title="XGBoost(2016) &amp; LightGBM"></a>XGBoost(2016) &amp; LightGBM</h2><ul>
<li>전통적인 머신러닝 알고리즘의 융합<ul>
<li>선형회귀 릿지 라쏘, 과적합 방지를 위한 규제</li>
</ul>
<ul>
<li>결정트리의 핵심적인 알고리즘</li>
<li>경사 하강법</li>
<li>부스팅 기법</li>
</ul>
</li>
<li>문제점 : 파라미터의 개수가 매우 많음</li>
<li>왜 많이 사용할까?</li>
</ul>
<ul>
<li>모델 학습 속도</li>
<li>성능</li>
<li>가장 좋은 모델이란 학습속도는 빠르고 성능이 좋음.(기준: 지금까지 나온 알고리즘과 비교해서)</li>
</ul>
<ul>
<li>언어를 Python,Java에서 시작했어도 C,C++로 가야만 됨.</li>
<li>개발 초기: 자체 사용 용도로 개발 –&gt; Python Wrapper <ul>
<li>R, 머신러닝 프레임워크 종류가 다양.</li>
<li>파이썬 머신러닝 중 Scikit-Learn이 대세로 떠오름</li>
</ul>
</li>
<li>개발 중기: 파이썬 머신러닝 Scikit-Learn에서 API를 사용해 XGBoost을 사용</li>
</ul>
<h3 id="XGBoost-Python-Wrapper-방식"><a href="#XGBoost-Python-Wrapper-방식" class="headerlink" title="XGBoost-Python Wrapper 방식"></a>XGBoost-Python Wrapper 방식</h3><ul>
<li>X_train, Y_train</li>
<li>각 모듈에 맞도록 행렬을 재변환해야 함.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb <span class="comment"># 엑스지부스터를 사용-&gt;파이썬래퍼 방식</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 데이터 분리</span></span><br><span class="line">titanic = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line">titanic.info()</span><br><span class="line"></span><br><span class="line"><span class="comment">#x,독립변수 y종속변수</span></span><br><span class="line">X = titanic[[<span class="string">&#x27;pclass&#x27;</span>, <span class="string">&#x27;parch&#x27;</span>, <span class="string">&#x27;fare&#x27;</span>]]</span><br><span class="line">y = titanic[<span class="string">&#x27;survived&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련데이터, 테스트 데이터 분리</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, </span><br><span class="line">                                                    y, </span><br><span class="line">                                                    stratify = y, </span><br><span class="line">                                                    test_size = <span class="number">0.3</span>, </span><br><span class="line">                                                    random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">X_train.shape, X_test.shape, y_train.shape, y_test.shape</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 15 columns):
 #   Column       Non-Null Count  Dtype   
---  ------       --------------  -----   
 0   survived     891 non-null    int64   
 1   pclass       891 non-null    int64   
 2   sex          891 non-null    object  
 3   age          714 non-null    float64 
 4   sibsp        891 non-null    int64   
 5   parch        891 non-null    int64   
 6   fare         891 non-null    float64 
 7   embarked     889 non-null    object  
 8   class        891 non-null    category
 9   who          891 non-null    object  
 10  adult_male   891 non-null    bool    
 11  deck         203 non-null    category
 12  embark_town  889 non-null    object  
 13  alive        891 non-null    object  
 14  alone        891 non-null    bool    
dtypes: bool(2), category(2), float64(2), int64(4), object(5)
memory usage: 80.7+ KB





((623, 3), (268, 3), (623,), (268,))
</code></pre>
<ul>
<li><p><strong>여기가 핵심</strong></p>
<ul>
<li>다른 데이터로 변신</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dtrain = xgb.DMatrix(data = X_train, label = y_train)</span><br><span class="line">dtest = xgb.DMatrix(data= X_test, label= y_test)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(dtrain)</span><br></pre></td></tr></table></figure>

<pre><code>&lt;xgboost.core.DMatrix object at 0x7faf7bee2490&gt;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>:<span class="number">3</span>,<span class="comment">#트리 깊이는 3</span></span><br><span class="line">    <span class="string">&#x27;n_estimator&#x27;</span>:<span class="number">100</span>,<span class="comment">#100번 심기-&gt;결정트리갯수</span></span><br><span class="line">    <span class="string">&#x27;eta&#x27;</span>:<span class="number">0.1</span>,</span><br><span class="line">    <span class="string">&#x27;objectice&#x27;</span> : <span class="string">&#x27;binary:logistic&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">num_rounds = <span class="number">400</span></span><br><span class="line"></span><br><span class="line">w_list = [(dtrain, <span class="string">&#x27;train&#x27;</span>), (dtest, <span class="string">&#x27;test&#x27;</span>)]</span><br><span class="line">xgb_ml = xgb.train(params = params, </span><br><span class="line">                   dtrain = dtrain, </span><br><span class="line">                   num_boost_round = <span class="number">400</span>, <span class="comment">#경사하강법의 에포크(가중치를 계속 줌)</span></span><br><span class="line">                   early_stopping_rounds = <span class="number">100</span>, <span class="comment"># 100번하고 효과 없으면 멈춰라</span></span><br><span class="line">                   evals = w_list)</span><br></pre></td></tr></table></figure>

<pre><code>[0]	train-rmse:0.487916	test-rmse:0.490147
Multiple eval metrics have been passed: &#39;test-rmse&#39; will be used for early stopping.

Will train until test-rmse hasn&#39;t improved in 100 rounds.
[1]	train-rmse:0.477856	test-rmse:0.482183
[2]	train-rmse:0.470061	test-rmse:0.47532
[3]	train-rmse:0.462181	test-rmse:0.470924
[4]	train-rmse:0.455721	test-rmse:0.466351
[5]	train-rmse:0.450355	test-rmse:0.462927
[6]	train-rmse:0.445684	test-rmse:0.459554
[7]	train-rmse:0.441298	test-rmse:0.458577
[8]	train-rmse:0.437792	test-rmse:0.456831
[9]	train-rmse:0.434393	test-rmse:0.456526
[10]	train-rmse:0.431725	test-rmse:0.455362
[11]	train-rmse:0.428592	test-rmse:0.454746
[12]	train-rmse:0.426484	test-rmse:0.454121
[13]	train-rmse:0.423993	test-rmse:0.453891
[14]	train-rmse:0.421947	test-rmse:0.453115
[15]	train-rmse:0.42036	test-rmse:0.452995
[16]	train-rmse:0.418511	test-rmse:0.452991
[17]	train-rmse:0.417025	test-rmse:0.452558
[18]	train-rmse:0.415955	test-rmse:0.45293
[19]	train-rmse:0.41396	test-rmse:0.453367
[20]	train-rmse:0.413199	test-rmse:0.453852
[21]	train-rmse:0.412091	test-rmse:0.453547
[22]	train-rmse:0.410501	test-rmse:0.454099
[23]	train-rmse:0.409461	test-rmse:0.453524
[24]	train-rmse:0.408469	test-rmse:0.453724
[25]	train-rmse:0.407781	test-rmse:0.454117
[26]	train-rmse:0.406954	test-rmse:0.454325
[27]	train-rmse:0.405709	test-rmse:0.454997
[28]	train-rmse:0.405121	test-rmse:0.455544
[29]	train-rmse:0.40445	test-rmse:0.455746
[30]	train-rmse:0.403643	test-rmse:0.45576
[31]	train-rmse:0.403092	test-rmse:0.45603
[32]	train-rmse:0.40252	test-rmse:0.456502
[33]	train-rmse:0.401617	test-rmse:0.456903
[34]	train-rmse:0.401175	test-rmse:0.457341
[35]	train-rmse:0.400151	test-rmse:0.458455
[36]	train-rmse:0.399748	test-rmse:0.458725
[37]	train-rmse:0.398984	test-rmse:0.45933
[38]	train-rmse:0.3982	test-rmse:0.459086
[39]	train-rmse:0.397529	test-rmse:0.459736
[40]	train-rmse:0.39734	test-rmse:0.460037
[41]	train-rmse:0.396627	test-rmse:0.460473
[42]	train-rmse:0.396461	test-rmse:0.460603
[43]	train-rmse:0.395536	test-rmse:0.460408
[44]	train-rmse:0.395255	test-rmse:0.460791
[45]	train-rmse:0.394568	test-rmse:0.461165
[46]	train-rmse:0.39406	test-rmse:0.461553
[47]	train-rmse:0.39335	test-rmse:0.461595
[48]	train-rmse:0.393206	test-rmse:0.461718
[49]	train-rmse:0.392991	test-rmse:0.462002
[50]	train-rmse:0.392352	test-rmse:0.461921
[51]	train-rmse:0.391973	test-rmse:0.462235
[52]	train-rmse:0.391844	test-rmse:0.462413
[53]	train-rmse:0.391345	test-rmse:0.462504
[54]	train-rmse:0.391184	test-rmse:0.462824
[55]	train-rmse:0.391068	test-rmse:0.462939
[56]	train-rmse:0.390596	test-rmse:0.462162
[57]	train-rmse:0.390164	test-rmse:0.462743
[58]	train-rmse:0.389861	test-rmse:0.463045
[59]	train-rmse:0.389441	test-rmse:0.462628
[60]	train-rmse:0.389338	test-rmse:0.462737
[61]	train-rmse:0.388745	test-rmse:0.462943
[62]	train-rmse:0.388405	test-rmse:0.462691
[63]	train-rmse:0.388277	test-rmse:0.463041
[64]	train-rmse:0.387828	test-rmse:0.463243
[65]	train-rmse:0.387614	test-rmse:0.463214
[66]	train-rmse:0.387088	test-rmse:0.463584
[67]	train-rmse:0.386906	test-rmse:0.463627
[68]	train-rmse:0.386444	test-rmse:0.463517
[69]	train-rmse:0.385685	test-rmse:0.463735
[70]	train-rmse:0.385353	test-rmse:0.463113
[71]	train-rmse:0.384828	test-rmse:0.463005
[72]	train-rmse:0.38444	test-rmse:0.462966
[73]	train-rmse:0.383198	test-rmse:0.462825
[74]	train-rmse:0.382841	test-rmse:0.462947
[75]	train-rmse:0.382416	test-rmse:0.463253
[76]	train-rmse:0.381966	test-rmse:0.462963
[77]	train-rmse:0.381655	test-rmse:0.463399
[78]	train-rmse:0.381399	test-rmse:0.463326
[79]	train-rmse:0.380593	test-rmse:0.463278
[80]	train-rmse:0.380329	test-rmse:0.463051
[81]	train-rmse:0.380233	test-rmse:0.46316
[82]	train-rmse:0.379942	test-rmse:0.463234
[83]	train-rmse:0.379686	test-rmse:0.463517
[84]	train-rmse:0.37893	test-rmse:0.463051
[85]	train-rmse:0.37884	test-rmse:0.463287
[86]	train-rmse:0.378756	test-rmse:0.463389
[87]	train-rmse:0.378501	test-rmse:0.463446
[88]	train-rmse:0.378011	test-rmse:0.463085
[89]	train-rmse:0.377178	test-rmse:0.46281
[90]	train-rmse:0.376872	test-rmse:0.462851
[91]	train-rmse:0.376563	test-rmse:0.46331
[92]	train-rmse:0.376317	test-rmse:0.463088
[93]	train-rmse:0.376049	test-rmse:0.463515
[94]	train-rmse:0.375914	test-rmse:0.463486
[95]	train-rmse:0.375643	test-rmse:0.463194
[96]	train-rmse:0.375378	test-rmse:0.463459
[97]	train-rmse:0.375145	test-rmse:0.46375
[98]	train-rmse:0.37453	test-rmse:0.463309
[99]	train-rmse:0.374021	test-rmse:0.463431
[100]	train-rmse:0.373289	test-rmse:0.463593
[101]	train-rmse:0.373032	test-rmse:0.463798
[102]	train-rmse:0.372814	test-rmse:0.464226
[103]	train-rmse:0.372443	test-rmse:0.464454
[104]	train-rmse:0.372217	test-rmse:0.464417
[105]	train-rmse:0.372146	test-rmse:0.464435
[106]	train-rmse:0.371726	test-rmse:0.464241
[107]	train-rmse:0.37158	test-rmse:0.464172
[108]	train-rmse:0.371396	test-rmse:0.464582
[109]	train-rmse:0.371335	test-rmse:0.4646
[110]	train-rmse:0.371127	test-rmse:0.464403
[111]	train-rmse:0.371001	test-rmse:0.464328
[112]	train-rmse:0.370928	test-rmse:0.464546
[113]	train-rmse:0.370688	test-rmse:0.464457
[114]	train-rmse:0.370634	test-rmse:0.464475
[115]	train-rmse:0.370421	test-rmse:0.464819
[116]	train-rmse:0.37007	test-rmse:0.46479
[117]	train-rmse:0.369922	test-rmse:0.464798
Stopping. Best iteration:
[17]	train-rmse:0.417025	test-rmse:0.452558
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#평가</span></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line">pred_probs = xgb_ml.predict(dtest)</span><br><span class="line">y_pred = [<span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> pred_probs]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 예측 라벨과 실제 라벨 사이의 정확도 측정</span></span><br><span class="line">accuracy_score(y_pred,y_test)</span><br></pre></td></tr></table></figure>




<pre><code>0.6977611940298507
</code></pre>
<h3 id="XGBoost-Scikit-Learn-API방식"><a href="#XGBoost-Scikit-Learn-API방식" class="headerlink" title="XGBoost Scikit-Learn API방식"></a>XGBoost Scikit-Learn API방식</h3><ul>
<li>application programming interface</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#xgb를 사용하지 않음(파이썬라이브러리를 가져오지 않고 사이킥런인공지능 사용)</span></span><br><span class="line"><span class="comment">#from sklearn.tree import DecisionTreeClassifier</span></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier <span class="comment"># 사이킥런 API</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#dt = DecisionTreeClassifier()</span></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;max_depth&#x27;</span>:<span class="number">3</span>,<span class="comment">#트리 깊이는 3</span></span><br><span class="line">    <span class="string">&#x27;n_estimator&#x27;</span>:<span class="number">100</span>,<span class="comment">#100번 심기-&gt;결정트리갯수</span></span><br><span class="line">    <span class="string">&#x27;eta&#x27;</span>:<span class="number">0.1</span>,</span><br><span class="line">    <span class="string">&#x27;objectice&#x27;</span> : <span class="string">&#x27;binary:logistic&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">num_rounds = <span class="number">400</span></span><br><span class="line"></span><br><span class="line">xgb_model = XGBClassifier(objective= <span class="string">&#x27;binary:logistic&#x27;</span>,</span><br><span class="line">                          n_estimators=<span class="number">100</span>,</span><br><span class="line">                          max_depth=<span class="number">3</span>,</span><br><span class="line">                          learning_rate =<span class="number">0.1</span>,</span><br><span class="line">                          num_rounds = <span class="number">400</span>,<span class="comment">#이건 엑스지부스터랑 같은내용이지만 양식이 다름</span></span><br><span class="line">                          random_state = <span class="number">42</span>)</span><br><span class="line"></span><br><span class="line">w_list = [(X_train, y_train), (X_test, y_test)]</span><br><span class="line"></span><br><span class="line">xgb_model.fit(X_train, y_train, eval_set = w_list, eval_metric=<span class="string">&#x27;error&#x27;</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y_probas = xgb_model.predict_proba(X_test)</span><br><span class="line">y_pred = [<span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> pred_probs]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 예측 라벨과 실제 라벨 사이의 정확도 측정</span></span><br><span class="line">accuracy_score(y_pred, y_test)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>[0]	validation_0-error:0.260032	validation_1-error:0.302239
[1]	validation_0-error:0.260032	validation_1-error:0.302239
[2]	validation_0-error:0.260032	validation_1-error:0.302239
[3]	validation_0-error:0.260032	validation_1-error:0.302239
[4]	validation_0-error:0.260032	validation_1-error:0.302239
[5]	validation_0-error:0.260032	validation_1-error:0.302239
[6]	validation_0-error:0.260032	validation_1-error:0.302239
[7]	validation_0-error:0.260032	validation_1-error:0.302239
[8]	validation_0-error:0.260032	validation_1-error:0.302239
[9]	validation_0-error:0.260032	validation_1-error:0.302239
[10]	validation_0-error:0.260032	validation_1-error:0.302239
[11]	validation_0-error:0.260032	validation_1-error:0.302239
[12]	validation_0-error:0.260032	validation_1-error:0.302239
[13]	validation_0-error:0.247191	validation_1-error:0.298507
[14]	validation_0-error:0.247191	validation_1-error:0.298507
[15]	validation_0-error:0.248796	validation_1-error:0.302239
[16]	validation_0-error:0.248796	validation_1-error:0.302239
[17]	validation_0-error:0.248796	validation_1-error:0.302239
[18]	validation_0-error:0.248796	validation_1-error:0.302239
[19]	validation_0-error:0.248796	validation_1-error:0.302239
[20]	validation_0-error:0.248796	validation_1-error:0.302239
[21]	validation_0-error:0.248796	validation_1-error:0.302239
[22]	validation_0-error:0.248796	validation_1-error:0.302239
[23]	validation_0-error:0.248796	validation_1-error:0.302239
[24]	validation_0-error:0.248796	validation_1-error:0.302239
[25]	validation_0-error:0.248796	validation_1-error:0.302239
[26]	validation_0-error:0.248796	validation_1-error:0.302239
[27]	validation_0-error:0.248796	validation_1-error:0.302239
[28]	validation_0-error:0.247191	validation_1-error:0.302239
[29]	validation_0-error:0.247191	validation_1-error:0.302239
[30]	validation_0-error:0.247191	validation_1-error:0.302239
[31]	validation_0-error:0.243981	validation_1-error:0.298507
[32]	validation_0-error:0.247191	validation_1-error:0.302239
[33]	validation_0-error:0.243981	validation_1-error:0.298507
[34]	validation_0-error:0.243981	validation_1-error:0.298507
[35]	validation_0-error:0.242376	validation_1-error:0.294776
[36]	validation_0-error:0.24077	validation_1-error:0.294776
[37]	validation_0-error:0.24077	validation_1-error:0.294776
[38]	validation_0-error:0.24077	validation_1-error:0.294776
[39]	validation_0-error:0.24077	validation_1-error:0.294776
[40]	validation_0-error:0.24077	validation_1-error:0.294776
[41]	validation_0-error:0.24077	validation_1-error:0.294776
[42]	validation_0-error:0.24077	validation_1-error:0.294776
[43]	validation_0-error:0.24077	validation_1-error:0.294776
[44]	validation_0-error:0.24077	validation_1-error:0.302239
[45]	validation_0-error:0.24077	validation_1-error:0.302239
[46]	validation_0-error:0.24077	validation_1-error:0.302239
[47]	validation_0-error:0.24077	validation_1-error:0.302239
[48]	validation_0-error:0.24077	validation_1-error:0.302239
[49]	validation_0-error:0.24077	validation_1-error:0.302239
[50]	validation_0-error:0.24077	validation_1-error:0.302239
[51]	validation_0-error:0.24077	validation_1-error:0.302239
[52]	validation_0-error:0.23435	validation_1-error:0.302239
[53]	validation_0-error:0.23435	validation_1-error:0.302239
[54]	validation_0-error:0.232745	validation_1-error:0.298507
[55]	validation_0-error:0.229535	validation_1-error:0.298507
[56]	validation_0-error:0.229535	validation_1-error:0.298507
[57]	validation_0-error:0.229535	validation_1-error:0.298507
[58]	validation_0-error:0.229535	validation_1-error:0.298507
[59]	validation_0-error:0.227929	validation_1-error:0.294776
[60]	validation_0-error:0.227929	validation_1-error:0.298507
[61]	validation_0-error:0.227929	validation_1-error:0.298507
[62]	validation_0-error:0.227929	validation_1-error:0.298507
[63]	validation_0-error:0.227929	validation_1-error:0.298507
[64]	validation_0-error:0.227929	validation_1-error:0.298507
[65]	validation_0-error:0.227929	validation_1-error:0.298507
[66]	validation_0-error:0.227929	validation_1-error:0.298507
[67]	validation_0-error:0.227929	validation_1-error:0.298507
[68]	validation_0-error:0.227929	validation_1-error:0.298507
[69]	validation_0-error:0.227929	validation_1-error:0.298507
[70]	validation_0-error:0.227929	validation_1-error:0.298507
[71]	validation_0-error:0.227929	validation_1-error:0.298507
[72]	validation_0-error:0.227929	validation_1-error:0.302239
[73]	validation_0-error:0.227929	validation_1-error:0.302239
[74]	validation_0-error:0.229535	validation_1-error:0.30597
[75]	validation_0-error:0.229535	validation_1-error:0.30597
[76]	validation_0-error:0.229535	validation_1-error:0.30597
[77]	validation_0-error:0.229535	validation_1-error:0.30597
[78]	validation_0-error:0.229535	validation_1-error:0.30597
[79]	validation_0-error:0.229535	validation_1-error:0.30597
[80]	validation_0-error:0.229535	validation_1-error:0.30597
[81]	validation_0-error:0.229535	validation_1-error:0.30597
[82]	validation_0-error:0.229535	validation_1-error:0.30597
[83]	validation_0-error:0.229535	validation_1-error:0.30597
[84]	validation_0-error:0.229535	validation_1-error:0.30597
[85]	validation_0-error:0.229535	validation_1-error:0.30597
[86]	validation_0-error:0.229535	validation_1-error:0.30597
[87]	validation_0-error:0.229535	validation_1-error:0.30597
[88]	validation_0-error:0.229535	validation_1-error:0.30597
[89]	validation_0-error:0.229535	validation_1-error:0.30597
[90]	validation_0-error:0.229535	validation_1-error:0.30597
[91]	validation_0-error:0.229535	validation_1-error:0.30597
[92]	validation_0-error:0.229535	validation_1-error:0.30597
[93]	validation_0-error:0.229535	validation_1-error:0.30597
[94]	validation_0-error:0.227929	validation_1-error:0.313433
[95]	validation_0-error:0.226324	validation_1-error:0.313433
[96]	validation_0-error:0.223114	validation_1-error:0.317164
[97]	validation_0-error:0.223114	validation_1-error:0.317164
[98]	validation_0-error:0.223114	validation_1-error:0.317164
[99]	validation_0-error:0.223114	validation_1-error:0.317164





0.6977611940298507
</code></pre>
<h3 id="LightGBM-Rython-Wrapper방식"><a href="#LightGBM-Rython-Wrapper방식" class="headerlink" title="LightGBM Rython Wrapper방식"></a>LightGBM Rython Wrapper방식</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> lightgbm <span class="keyword">as</span> lgb </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split </span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns </span><br><span class="line"></span><br><span class="line"><span class="comment"># tips 데이터셋 </span></span><br><span class="line">titanic = sns.load_dataset(<span class="string">&#x27;titanic&#x27;</span>)</span><br><span class="line"></span><br><span class="line">X = titanic[[<span class="string">&#x27;pclass&#x27;</span>, <span class="string">&#x27;parch&#x27;</span>, <span class="string">&#x27;fare&#x27;</span>]]</span><br><span class="line">y = titanic[<span class="string">&#x27;survived&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련데이터, 테스트 데이터 분리</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = <span class="number">0.3</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># XGBoost 코드와 유사하다. </span></span><br><span class="line">dtrain = lgb.Dataset(data = X_train, label = y_train)</span><br><span class="line">dtest = lgb.Dataset(data = X_test, label = y_test)</span><br><span class="line"></span><br><span class="line">params = &#123;<span class="string">&#x27;max_depth&#x27;</span>:<span class="number">3</span>,</span><br><span class="line">          <span class="string">&#x27;n_estimators&#x27;</span>:<span class="number">100</span>,</span><br><span class="line">          <span class="string">&#x27;learning_rate&#x27;</span>: <span class="number">0.1</span>, <span class="comment">#xgbooost eta</span></span><br><span class="line">          <span class="string">&#x27;objective&#x27;</span>:<span class="string">&#x27;binary&#x27;</span>,<span class="comment"># xgboost objectice&#x27; : &#x27;binary:logistic&#x27;</span></span><br><span class="line">          <span class="string">&#x27;metric&#x27;</span> : <span class="string">&#x27;binary_error&#x27;</span>, </span><br><span class="line">          <span class="string">&#x27;num_boost_round&#x27;</span> : <span class="number">400</span>, </span><br><span class="line">          <span class="string">&#x27;verbose&#x27;</span> : <span class="number">1</span>&#125; </span><br><span class="line"></span><br><span class="line">w_list = [dtrain, dtest]</span><br><span class="line">lgb_ml = lgb.train(params=params, train_set = dtrain,\</span><br><span class="line">                  early_stopping_rounds=<span class="number">100</span>, valid_sets= w_list)</span><br><span class="line"></span><br><span class="line">pred_probs = lgb_ml.predict(X_test)</span><br><span class="line">y_pred=[<span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> pred_probs]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 예측 라벨과 실제 라벨 사이의 정확도 측정</span></span><br><span class="line">accuracy_score(y_pred, y_test)</span><br></pre></td></tr></table></figure>

<pre><code>/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument
  warnings.warn(&quot;Found `&#123;&#125;` in params. Will use it instead of argument&quot;.format(alias))


[1]	training&#39;s binary_error: 0.383628	valid_1&#39;s binary_error: 0.384328
Training until validation scores don&#39;t improve for 100 rounds.
[2]	training&#39;s binary_error: 0.383628	valid_1&#39;s binary_error: 0.384328
[3]	training&#39;s binary_error: 0.354735	valid_1&#39;s binary_error: 0.369403
[4]	training&#39;s binary_error: 0.29695	valid_1&#39;s binary_error: 0.354478
[5]	training&#39;s binary_error: 0.272873	valid_1&#39;s binary_error: 0.33209
[6]	training&#39;s binary_error: 0.272873	valid_1&#39;s binary_error: 0.33209
[7]	training&#39;s binary_error: 0.269663	valid_1&#39;s binary_error: 0.317164
[8]	training&#39;s binary_error: 0.269663	valid_1&#39;s binary_error: 0.317164
[9]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[10]	training&#39;s binary_error: 0.269663	valid_1&#39;s binary_error: 0.309701
[11]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[12]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[13]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[14]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[15]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[16]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[17]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[18]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[19]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[20]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[21]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[22]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[23]	training&#39;s binary_error: 0.271268	valid_1&#39;s binary_error: 0.313433
[24]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[25]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[26]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[27]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[28]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[29]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[30]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[31]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[32]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[33]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[34]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[35]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[36]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[37]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[38]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[39]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.309701
[40]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[41]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[42]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[43]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[44]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[45]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[46]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[47]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[48]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[49]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[50]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[51]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[52]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[53]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[54]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[55]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[56]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[57]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[58]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[59]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[60]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[61]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[62]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[63]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[64]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[65]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[66]	training&#39;s binary_error: 0.243981	valid_1&#39;s binary_error: 0.309701
[67]	training&#39;s binary_error: 0.23435	valid_1&#39;s binary_error: 0.309701
[68]	training&#39;s binary_error: 0.23435	valid_1&#39;s binary_error: 0.309701
[69]	training&#39;s binary_error: 0.23435	valid_1&#39;s binary_error: 0.309701
[70]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[71]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[72]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[73]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[74]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[75]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[76]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[77]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[78]	training&#39;s binary_error: 0.232745	valid_1&#39;s binary_error: 0.313433
[79]	training&#39;s binary_error: 0.232745	valid_1&#39;s binary_error: 0.313433
[80]	training&#39;s binary_error: 0.232745	valid_1&#39;s binary_error: 0.313433
[81]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[82]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[83]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[84]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[85]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[86]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[87]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[88]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[89]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[90]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[91]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[92]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[93]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[94]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[95]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[96]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[97]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[98]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[99]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.317164
[100]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[101]	training&#39;s binary_error: 0.23114	valid_1&#39;s binary_error: 0.30597
[102]	training&#39;s binary_error: 0.23114	valid_1&#39;s binary_error: 0.30597
[103]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[104]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.317164
[105]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.317164
[106]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.313433
[107]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[108]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[109]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[110]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[111]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[112]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[113]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[114]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[115]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[116]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[117]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[118]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[119]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[120]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[121]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[122]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[123]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[124]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[125]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[126]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[127]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[128]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[129]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[130]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[131]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[132]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[133]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[134]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[135]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[136]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[137]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.309701
[138]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.309701
[139]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[140]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[141]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[142]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[143]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[144]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.320896
[145]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[146]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[147]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[148]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[149]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[150]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[151]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[152]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[153]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[154]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[155]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[156]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[157]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[158]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[159]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[160]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[161]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[162]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[163]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[164]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[165]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[166]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[167]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[168]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[169]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[170]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[171]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[172]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[173]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[174]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[175]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[176]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[177]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[178]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[179]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[180]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[181]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[182]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[183]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[184]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[185]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[186]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[187]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[188]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[189]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[190]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[191]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[192]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[193]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[194]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[195]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[196]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[197]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[198]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[199]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[200]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[201]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
Early stopping, best iteration is:
[101]	training&#39;s binary_error: 0.23114	valid_1&#39;s binary_error: 0.30597





0.6940298507462687
</code></pre>
<ul>
<li><a target="_blank" rel="noopener" href="https://lightgbm.readthedocs.io/en/latest/Parameters.html">https://lightgbm.readthedocs.io/en/latest/Parameters.html</a></li>
<li>파라메터를 보고 할 것</li>
</ul>
<h3 id="LightGBM-Scikit-Learn-API방식"><a href="#LightGBM-Scikit-Learn-API방식" class="headerlink" title="LightGBM Scikit-Learn API방식"></a>LightGBM Scikit-Learn API방식</h3><ul>
<li>application programming interface</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lightgbm <span class="keyword">import</span> LGBMClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># model </span></span><br><span class="line">w_list = [dtrain, dtest]</span><br><span class="line">model = LGBMClassifier(objective = <span class="string">&#x27;binary&#x27;</span>, </span><br><span class="line">                       metric = <span class="string">&#x27;binary_error&#x27;</span>,</span><br><span class="line">                       n_estimators=<span class="number">100</span>, </span><br><span class="line">                       learning_rate=<span class="number">0.1</span>, </span><br><span class="line">                       max_depth=<span class="number">3</span>, </span><br><span class="line">                       num_boost_round = <span class="number">400</span>,</span><br><span class="line">                       random_state = <span class="number">32</span>)</span><br><span class="line">model.fit(X_train, </span><br><span class="line">          y_train, </span><br><span class="line">          eval_set = [(X_train, y_train), (X_test, y_test)], </span><br><span class="line">          verbose=<span class="number">1</span>,</span><br><span class="line">          early_stopping_rounds = <span class="number">100</span>)</span><br><span class="line">y_probas = model.predict_proba(X_test) </span><br><span class="line">y_pred=[<span class="number">1</span> <span class="keyword">if</span> x &gt; <span class="number">0.5</span> <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> y_probas[:, <span class="number">1</span>]] <span class="comment"># 예측 라벨(0과 1로 예측)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 예측 라벨과 실제 라벨 사이의 정확도 측정</span></span><br><span class="line">accuracy_score(y_pred, y_test)</span><br></pre></td></tr></table></figure>

<pre><code>[1]	training&#39;s binary_error: 0.383628	valid_1&#39;s binary_error: 0.384328
Training until validation scores don&#39;t improve for 100 rounds.
[2]	training&#39;s binary_error: 0.383628	valid_1&#39;s binary_error: 0.384328
[3]	training&#39;s binary_error: 0.354735	valid_1&#39;s binary_error: 0.369403
[4]	training&#39;s binary_error: 0.29695	valid_1&#39;s binary_error: 0.354478
[5]	training&#39;s binary_error: 0.272873	valid_1&#39;s binary_error: 0.33209
[6]	training&#39;s binary_error: 0.272873	valid_1&#39;s binary_error: 0.33209
[7]	training&#39;s binary_error: 0.269663	valid_1&#39;s binary_error: 0.317164
[8]	training&#39;s binary_error: 0.269663	valid_1&#39;s binary_error: 0.317164
[9]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[10]	training&#39;s binary_error: 0.269663	valid_1&#39;s binary_error: 0.309701
[11]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[12]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[13]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[14]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[15]	training&#39;s binary_error: 0.264848	valid_1&#39;s binary_error: 0.309701
[16]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[17]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[18]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[19]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[20]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[21]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[22]	training&#39;s binary_error: 0.266453	valid_1&#39;s binary_error: 0.313433
[23]	training&#39;s binary_error: 0.271268	valid_1&#39;s binary_error: 0.313433
[24]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[25]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[26]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[27]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[28]	training&#39;s binary_error: 0.258427	valid_1&#39;s binary_error: 0.309701
[29]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[30]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[31]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[32]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[33]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[34]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[35]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[36]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.309701
[37]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[38]	training&#39;s binary_error: 0.255217	valid_1&#39;s binary_error: 0.317164
[39]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.309701
[40]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[41]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[42]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[43]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[44]	training&#39;s binary_error: 0.248796	valid_1&#39;s binary_error: 0.313433
[45]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[46]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[47]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[48]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[49]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[50]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[51]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[52]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[53]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[54]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[55]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[56]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[57]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[58]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[59]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[60]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[61]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[62]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[63]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[64]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[65]	training&#39;s binary_error: 0.247191	valid_1&#39;s binary_error: 0.313433
[66]	training&#39;s binary_error: 0.243981	valid_1&#39;s binary_error: 0.309701
[67]	training&#39;s binary_error: 0.23435	valid_1&#39;s binary_error: 0.309701
[68]	training&#39;s binary_error: 0.23435	valid_1&#39;s binary_error: 0.309701
[69]	training&#39;s binary_error: 0.23435	valid_1&#39;s binary_error: 0.309701
[70]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[71]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[72]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[73]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[74]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[75]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[76]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[77]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[78]	training&#39;s binary_error: 0.232745	valid_1&#39;s binary_error: 0.313433
[79]	training&#39;s binary_error: 0.232745	valid_1&#39;s binary_error: 0.313433
[80]	training&#39;s binary_error: 0.232745	valid_1&#39;s binary_error: 0.313433
[81]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[82]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[83]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[84]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[85]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[86]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[87]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[88]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[89]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[90]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[91]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[92]	training&#39;s binary_error: 0.229535	valid_1&#39;s binary_error: 0.309701
[93]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[94]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[95]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[96]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[97]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[98]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[99]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.317164
[100]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[101]	training&#39;s binary_error: 0.23114	valid_1&#39;s binary_error: 0.30597
[102]	training&#39;s binary_error: 0.23114	valid_1&#39;s binary_error: 0.30597
[103]	training&#39;s binary_error: 0.227929	valid_1&#39;s binary_error: 0.309701
[104]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.317164
[105]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.317164
[106]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.313433
[107]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[108]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[109]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[110]	training&#39;s binary_error: 0.224719	valid_1&#39;s binary_error: 0.317164
[111]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[112]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[113]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[114]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[115]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[116]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[117]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[118]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[119]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[120]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[121]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[122]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[123]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[124]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[125]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[126]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[127]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[128]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[129]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[130]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[131]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[132]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[133]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[134]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[135]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[136]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[137]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.309701
[138]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.309701
[139]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[140]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[141]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[142]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[143]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.309701
[144]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.320896
[145]	training&#39;s binary_error: 0.223114	valid_1&#39;s binary_error: 0.313433
[146]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[147]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[148]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[149]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[150]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[151]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[152]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.313433
[153]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[154]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[155]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[156]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[157]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[158]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[159]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[160]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[161]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[162]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[163]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[164]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[165]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[166]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[167]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[168]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[169]	training&#39;s binary_error: 0.219904	valid_1&#39;s binary_error: 0.324627
[170]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[171]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[172]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[173]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[174]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[175]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[176]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[177]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[178]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[179]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[180]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[181]	training&#39;s binary_error: 0.221509	valid_1&#39;s binary_error: 0.328358
[182]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[183]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[184]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[185]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[186]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[187]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[188]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[189]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[190]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[191]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[192]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[193]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[194]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[195]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[196]	training&#39;s binary_error: 0.216693	valid_1&#39;s binary_error: 0.320896
[197]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[198]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[199]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[200]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
[201]	training&#39;s binary_error: 0.215088	valid_1&#39;s binary_error: 0.317164
Early stopping, best iteration is:
[101]	training&#39;s binary_error: 0.23114	valid_1&#39;s binary_error: 0.30597


/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_boost_round` in params. Will use it instead of argument
  warnings.warn(&quot;Found `&#123;&#125;` in params. Will use it instead of argument&quot;.format(alias))





0.6940298507462687
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-05T07:00:28.539Z" title="2022. 7. 5. 오후 4:00:28">2022-07-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-05T06:59:43.316Z" title="2022. 7. 5. 오후 3:59:43">2022-07-05</time></span><span class="level-item">4 minutes read (About 563 words)</span></div></div><div class="content"><hr>
<h1 id="title-‘머신러닝5-트리의-앙상블’"><a href="#title-‘머신러닝5-트리의-앙상블’" class="headerlink" title="title: ‘머신러닝5 트리의 앙상블’"></a><strong>title: ‘머신러닝5 트리의 앙상블’</strong></h1><h1 id="date-‘2022-07-05-09-00’"><a href="#date-‘2022-07-05-09-00’" class="headerlink" title="date: ‘2022-07-05 09:00’"></a><strong>date: ‘2022-07-05 09:00’</strong></h1><hr>
<h2 id="랜덤-포레스트"><a href="#랜덤-포레스트" class="headerlink" title="랜덤 포레스트"></a>랜덤 포레스트</h2><ul>
<li>Decision Tree(나무 1개)에서 출발<ul>
<li>여러개 심음</li>
<li>샘플링</li>
<li>Feature Importances</li>
</ul>
</li>
<li>예측해야 할 행의 갯수,100만개</li>
<li>컬럼의 갯수 200개 &#x3D;&#x3D;&gt;100개 축소<ul>
<li>나무 100개를 심고 평균을 내자</li>
<li>나무 1개당 컬럼을 10개로 다양한 값 찾기<ul>
<li>T1 mae :20, T2 mae :30, T3 mae 10…..-&gt;T1~T100 mae :20(평균값)</li>
<li>Feature Importances</li>
</ul>
</li>
<li>샘플링 : 부트스트랩 샘플(복원추출)</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 라이브러리 불러오기 </span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split, cross_validate</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># 데이터 불러오기</span></span><br><span class="line">wine = pd.read_csv(<span class="string">&#x27;https://bit.ly/wine_csv_data&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># input, target 분리 </span></span><br><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>, <span class="string">&#x27;sugar&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련데이터, 테스트 데이터 분리</span></span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    data, target, test_size = <span class="number">0.2</span>, random_state = <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델링</span></span><br><span class="line">rf = RandomForestClassifier(n_jobs=-<span class="number">1</span>, random_state = <span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모형 평가</span></span><br><span class="line">scores = cross_validate(rf, train_input, train_target, return_train_score = <span class="literal">True</span>, n_jobs =-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]), np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]),<span class="string">&quot;과대적합&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 특성 중요도</span></span><br><span class="line">rf.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(rf.feature_importances_,<span class="string">&quot;역시 당도가 중요&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># OOB </span></span><br><span class="line">rf = RandomForestClassifier(oob_score = <span class="literal">True</span>, n_jobs = -<span class="number">1</span>, random_state = <span class="number">42</span>)</span><br><span class="line">rf.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(rf.oob_score_,<span class="string">&quot;OOB검증세트와 비슷&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>0.9973541965122431 0.8905151032797809 과대적합
[0.23167441 0.50039841 0.26792718] 역시 당도가 중요
0.8934000384837406 OOB검증세트와 비슷
</code></pre>
<h2 id="그레이디언트-부스팅"><a href="#그레이디언트-부스팅" class="headerlink" title="그레이디언트 부스팅"></a>그레이디언트 부스팅</h2><ul>
<li>기존알고리즘에 가중치(보정치)를 주어 학습을 시킴</li>
<li>경사하강법의 원리를 이용함</li>
<li>T1~Tn 증가하면서 오차를 보정해주며 정확성을 높임</li>
<li>랜덤포레스트와의 차이점<ul>
<li>랜덤포레스트는 각 나무간의 상호 연관성이 없음(부트스트랩샘플)</li>
<li>그레이디언트 부스팅은 각 나무간 상호 연관성이 있음<br> -&gt;그러나 너무 느린 속도</li>
<li>XGBoost,LightGBM이 대안</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line">gb = GradientBoostingClassifier(random_state=<span class="number">42</span>)</span><br><span class="line">scores = cross_validate(gb,train_input,train_target, return_train_score=<span class="literal">True</span>,n_jobs=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]),np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.8881086892152563 0.8720430147331015
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#결정트리 갯수를 기본100-&gt;500개로 늘리고 학습율 기본0.1-&gt;0.2로 늘려 봄</span></span><br><span class="line">gb = GradientBoostingClassifier(n_estimators=<span class="number">500</span>,learning_rate=<span class="number">0.2</span>,random_state=<span class="number">42</span>)</span><br><span class="line">scores = cross_validate(gb,train_input,train_target, return_train_score=<span class="literal">True</span>,n_jobs=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(np.mean(scores[<span class="string">&#x27;train_score&#x27;</span>]),np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.9464595437171814 0.8780082549788999
</code></pre>
<ul>
<li>특성 중요도</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gb.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(gb.feature_importances_)</span><br></pre></td></tr></table></figure>

<pre><code>[0.15872278 0.68010884 0.16116839]
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-05T07:00:04.000Z" title="2022. 7. 5. 오후 4:00:04">2022-07-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-05T07:05:51.495Z" title="2022. 7. 5. 오후 4:05:51">2022-07-05</time></span><span class="level-item">5 minutes read (About 810 words)</span></div></div><div class="content"><hr>
<h1 id="title-‘머신러닝6-비지도학습’"><a href="#title-‘머신러닝6-비지도학습’" class="headerlink" title="title: ‘머신러닝6 비지도학습’"></a><strong>title: ‘머신러닝6 비지도학습’</strong></h1><h1 id="date-‘2022-07-05-13-00’"><a href="#date-‘2022-07-05-13-00’" class="headerlink" title="date: ‘2022-07-05 13:00’"></a><strong>date: ‘2022-07-05 13:00’</strong></h1><hr>
<h2 id="주성분-분석-PCA-principal-component-analysis"><a href="#주성분-분석-PCA-principal-component-analysis" class="headerlink" title="주성분 분석(PCA principal component analysis)"></a>주성분 분석(PCA principal component analysis)</h2><ul>
<li>이론적으로 어려움</li>
<li>좌표계 공간개념(직교와 회전)</li>
<li>공분산(통계롼련 내용)</li>
<li>Feature Engineerin기법</li>
<li>StandardScaler()</li>
<li>현 머신러닝의 문제점: 컬럼의 갯수가 매우 많음(요소의 다양성)</li>
</ul>
<ul>
<li>우리의 판단으로 컬럼갯수를 줄였으나 이제는 통계적으로 줄이자-&gt;차원축소</li>
</ul>
<h3 id="차원축소"><a href="#차원축소" class="headerlink" title="차원축소"></a>차원축소</h3><ul>
<li>특성이 많으면 훈련데이터가 쉽게 과대적합이 된다.</li>
<li>특성을 줄요서 학습모델의 성능을 향상시키다.</li>
<li>모델의 학습시간을 감소시켜줌</li>
<li>대표적인 방법론:PCA,EFA</li>
</ul>
<h3 id="PCA-vs-EFA"><a href="#PCA-vs-EFA" class="headerlink" title="PCA vs EFA"></a>PCA vs EFA</h3><ul>
<li><p>EFA(탐색적요인분석), Factor Analysis</p>
<ul>
<li>예)국어 40, 수학 100, 과학 100, 영어 30</li>
</ul>
<ul>
<li>평가: 귀학생은 언어영역은 수준이 낮은 편이나 수리영역은 수준이 높습니다.</li>
<li>범주형&amp;수치데이터셋</li>
</ul>
</li>
<li><p>PCA(주성분분석)</p>
<ul>
<li>장비1, 장비2, 장비3…..</li>
<li>PC1, PC2, PC3,….PCN(ex.장비1과 장비2의 무게, 장비3과 장비4의 길이….)</li>
<li>원래 가지고 있던 정보를 알 수 없음 (정보손실)</li>
<li>범주형 데이터셋에는 사용 안됨-&gt;무조건 수치형 데이터셋에서만 사용!!</li>
<li>pca 실행전 ,반드시 표준화 처리(스케일링 실행)</li>
</ul>
</li>
<li><p>p320</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!wget https://bit.ly/fruits_300_data -O fruits_300.npy</span><br></pre></td></tr></table></figure>

<pre><code>--2022-07-05 04:55:12--  https://bit.ly/fruits_300_data
Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11
Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.
HTTP request sent, awaiting response... 301 Moved Permanently
Location: https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy [following]
--2022-07-05 04:55:12--  https://github.com/rickiepark/hg-mldl/raw/master/fruits_300.npy
Resolving github.com (github.com)... 140.82.112.3
Connecting to github.com (github.com)|140.82.112.3|:443... connected.
HTTP request sent, awaiting response... 302 Found
Location: https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy [following]
--2022-07-05 04:55:13--  https://raw.githubusercontent.com/rickiepark/hg-mldl/master/fruits_300.npy
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 3000128 (2.9M) [application/octet-stream]
Saving to: ‘fruits_300.npy’

fruits_300.npy      100%[===================&gt;]   2.86M  --.-KB/s    in 0.02s   

2022-07-05 04:55:13 (179 MB/s) - ‘fruits_300.npy’ saved [3000128/3000128]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">fruits = np.load(<span class="string">&#x27;/content/fruits_300.npy&#x27;</span>)</span><br><span class="line">fruits_2d = fruits.reshape(-<span class="number">1</span>,<span class="number">100</span>*<span class="number">100</span>)</span><br><span class="line"><span class="comment">#300개의 행 10000개의 열</span></span><br><span class="line">fruits_2d.shape</span><br></pre></td></tr></table></figure>




<pre><code>(300, 10000)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components=<span class="number">50</span>)<span class="comment">#행을 50개로 압축</span></span><br><span class="line">pca.fit(fruits_2d)</span><br></pre></td></tr></table></figure>




<pre><code>PCA(n_components=50)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(pca.components_.shape)<span class="comment"># 행을 300-&gt;50개로 줄임</span></span><br></pre></td></tr></table></figure>

<pre><code>(50, 10000)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_fruits</span>(<span class="params">arr, ratio=<span class="number">1</span></span>):</span><br><span class="line">    n = <span class="built_in">len</span>(arr)    <span class="comment"># n은 샘플 개수입니다</span></span><br><span class="line">    <span class="comment"># 한 줄에 10개씩 이미지를 그립니다. 샘플 개수를 10으로 나누어 전체 행 개수를 계산합니다. </span></span><br><span class="line">    rows = <span class="built_in">int</span>(np.ceil(n/<span class="number">10</span>))</span><br><span class="line">    <span class="comment"># 행이 1개 이면 열 개수는 샘플 개수입니다. 그렇지 않으면 10개입니다.</span></span><br><span class="line">    cols = n <span class="keyword">if</span> rows &lt; <span class="number">2</span> <span class="keyword">else</span> <span class="number">10</span></span><br><span class="line">    fig, axs = plt.subplots(rows, cols, </span><br><span class="line">                            figsize=(cols*ratio, rows*ratio), squeeze=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(rows):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(cols):</span><br><span class="line">            <span class="keyword">if</span> i*<span class="number">10</span> + j &lt; n:    <span class="comment"># n 개까지만 그립니다.</span></span><br><span class="line">                axs[i, j].imshow(arr[i*<span class="number">10</span> + j], cmap=<span class="string">&#x27;gray_r&#x27;</span>)</span><br><span class="line">            axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">draw_fruits(pca.components_.reshape(-<span class="number">1</span>,<span class="number">100</span>,<span class="number">100</span>))</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0705_2/output_7_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 머신러닝에서 컬럼의 갯수를 10000개에서 50개로 줄임</span></span><br><span class="line">fruits_pca = pca.transform(fruits_2d)</span><br><span class="line"><span class="built_in">print</span>(fruits_pca.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(300, 50)
</code></pre>
<ul>
<li>훈련데이터, 테스트 데이터로 분리</li>
</ul>
<h2 id="설명된-분산"><a href="#설명된-분산" class="headerlink" title="설명된 분산"></a>설명된 분산</h2><ul>
<li>주성분이 원본 데이터의 분산을 얼마나 잘 나타내는지 기록한 값</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 원본 이미지 압축-&gt; 결과값은 92%</span></span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(pca.explained_variance_ratio_))</span><br></pre></td></tr></table></figure>

<pre><code>0.9215343906846957
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(pca.explained_variance_ratio_)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0705_2/output_12_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(np.<span class="built_in">sum</span>(pca.explained_variance_ratio_[:<span class="number">20</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>0.8416602343085364
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-04T08:11:36.000Z" title="2022. 7. 4. 오후 5:11:36">2022-07-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-04T08:15:45.311Z" title="2022. 7. 4. 오후 5:15:45">2022-07-04</time></span><span class="level-item">10 minutes read (About 1514 words)</span></div></div><div class="content"><hr>
<h1 id="title-‘머신러닝5-결정트리’"><a href="#title-‘머신러닝5-결정트리’" class="headerlink" title="title: ‘머신러닝5 결정트리’"></a><strong>title: ‘머신러닝5 결정트리’</strong></h1><h1 id="date-‘2022-07-04-11-00’"><a href="#date-‘2022-07-04-11-00’" class="headerlink" title="date: ‘2022-07-04 11:00’"></a><strong>date: ‘2022-07-04 11:00’</strong></h1><hr>
<h2 id="결정트리-아주-중요"><a href="#결정트리-아주-중요" class="headerlink" title="결정트리(아주 중요)"></a>결정트리(아주 중요)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">wine = pd.read_csv(<span class="string">&#x27;https://bit.ly/wine_csv_data&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(wine.head())</span><br></pre></td></tr></table></figure>

<pre><code>   alcohol  sugar    pH  class
0      9.4    1.9  3.51    0.0
1      9.8    2.6  3.20    0.0
2      9.8    2.3  3.26    0.0
3      9.8    1.9  3.16    0.0
4      9.4    1.9  3.51    0.0
</code></pre>
<ul>
<li>데이터 가공하기.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br></pre></td></tr></table></figure>

<ul>
<li>훈련데이터 분리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target =train_test_split(</span><br><span class="line">    data, target, test_size = <span class="number">0.2</span>, random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((5197, 3), (1300, 3), (5197,), (1300,))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line"></span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_scaled,train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_scaled,test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.7808350971714451
0.7776923076923077
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_,lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[[ 0.51270274  1.6733911  -0.68767781]] [1.81777902]
</code></pre>
<ul>
<li>모델만들기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"></span><br><span class="line">dt = DecisionTreeClassifier(max_depth= <span class="number">6</span>,random_state=<span class="number">42</span>)<span class="comment">#깊이를 줄여보자</span></span><br><span class="line">dt.fit(train_scaled,train_target)</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_scaled,train_target)) <span class="comment">#훈련 셋트</span></span><br><span class="line"><span class="built_in">print</span>(dt.score(test_scaled,test_target)) <span class="comment">#테스트 셋트</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plot_tree(dt)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>0.8766596113142198
0.8523076923076923
</code></pre>
<p><img src="/images/day0704_2/output_11_1.png" alt="png"></p>
<ul>
<li>훈련정확도는 99.6%</li>
<li>테스트 정확도는 85.9%<br>+-&gt;과대적합이 일어남<br>-max_depth&#x3D; 7값을 조정하여 비슷하게 만듬</li>
</ul>
<h3 id="노드란-무엇인가"><a href="#노드란-무엇인가" class="headerlink" title="노드란 무엇인가?"></a>노드란 무엇인가?</h3><ul>
<li>0이면 레드 와인(1599)</li>
<li>1이면 화이트 와인(4898)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wine[<span class="string">&#x27;class&#x27;</span>].value_counts()</span><br></pre></td></tr></table></figure>




<pre><code>1.0    4898
0.0    1599
Name: class, dtype: int64
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plot_tree(dt,</span><br><span class="line">          max_depth=<span class="number">1</span>, </span><br><span class="line">          filled=<span class="literal">True</span>, </span><br><span class="line">          feature_names=[<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0704_2/output_15_0.png" alt="png"></p>
<ul>
<li>불순도(Gini impurity)</li>
</ul>
<ul>
<li>비율(0~0.5)</li>
<li>레드와인:화이트 와인 이 5:5 일때 불순도가 가장 높은 상태(0.5)</li>
<li>한범주안에서 서로 다른 데이터가 얼마나 섞여 있는지를 나타냄.</li>
<li>흰색과 검은색이 각각 반반이면 불순도 최대 0.5</li>
<li>흰색과 검은색이 완전 분리가 되면 <ul>
<li>흰색 노드 불순도 최소 0</li>
<li>검은색 노드 불순도 최소 0</li>
</ul>
</li>
</ul>
<ul>
<li>엔트로피(Entropy)</li>
</ul>
<ul>
<li>불확실한 정도를 의미(0~1)</li>
<li>흰색과 검은색이 각각 반이면 엔트로피 최대 1</li>
<li>흰색과 검은색이 완전 분리가 되면<ul>
<li>흰색 노드 엔트로피도 0</li>
<li>검은색 노드 엔트로피도 0</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> plot_tree</span><br><span class="line"></span><br><span class="line">dt = DecisionTreeClassifier(criterion = <span class="string">&#x27;entropy&#x27;</span>, max_depth = <span class="number">42</span>, random_state=<span class="number">42</span>)</span><br><span class="line">dt.fit(train_scaled,train_target)</span><br><span class="line">dt.score(train_scaled,train_target) <span class="comment">#훈련 셋트</span></span><br><span class="line">dt.score(test_scaled,test_target) <span class="comment">#테스트 셋트</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">7</span>))</span><br><span class="line">plot_tree(dt,</span><br><span class="line">          max_depth=<span class="number">1</span>, </span><br><span class="line">          filled=<span class="literal">True</span>, </span><br><span class="line">          feature_names=[<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0704_2/output_18_0.png" alt="png"></p>
<h3 id="특성-중요도"><a href="#특성-중요도" class="headerlink" title="특성 중요도"></a>특성 중요도</h3><ul>
<li>어떤 특성이 결정 트리 모델에 영향을 주었는가?</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(dt.feature_importances_)</span><br></pre></td></tr></table></figure>

<pre><code>[0.23739824 0.5051808  0.25742097]
</code></pre>
<h2 id="현업에서의-적용"><a href="#현업에서의-적용" class="headerlink" title="현업에서의 적용"></a>현업에서의 적용</h2><ul>
<li>현업에서 DecisionTreeClassifier을 사용하기에는 오래되었다.(1970년대)</li>
<li>렘덤포르세트, XGBoost 하이퍼 파라미터가 매우 많음</li>
</ul>
<h2 id="검증-세트"><a href="#검증-세트" class="headerlink" title="검증 세트"></a>검증 세트</h2><ul>
<li>훈련세트와 테스트세트</li>
<li>훈련 : 교과서로 공부하는 것 </li>
<li>훈련세트 : 모의평가</li>
<li>검증 : 강남대성 모의고사</li>
<li>테스트 : 중간고사, 기말고사</li>
<li>실전 :수능</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">wine = pd.read_csv(<span class="string">&#x27;https://bit.ly/wine_csv_data&#x27;</span>)</span><br><span class="line">data = wine[[<span class="string">&#x27;alcohol&#x27;</span>,<span class="string">&#x27;sugar&#x27;</span>,<span class="string">&#x27;pH&#x27;</span>]].to_numpy()</span><br><span class="line">target = wine[<span class="string">&#x27;class&#x27;</span>].to_numpy()</span><br><span class="line"><span class="comment">#훈련 80%, 테스트 20%</span></span><br><span class="line">train_input, test_input, train_target, test_target =train_test_split(</span><br><span class="line">    data, target, test_size = <span class="number">0.2</span>, random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((5197, 3), (1300, 3), (5197,), (1300,))
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#훈련80%, 검증20%</span></span><br><span class="line">sub_input, val_input,sub_target,val_target = train_test_split(</span><br><span class="line">    train_input, train_target, test_size =<span class="number">0.2</span>, random_state=<span class="number">42</span></span><br><span class="line">)</span><br><span class="line">sub_input.shape,val_input.shape,sub_target.shape,val_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((4157, 3), (1040, 3), (4157,), (1040,))
</code></pre>
<ul>
<li>훈련데이터: sub_input, sub_target</li>
<li>검증데이터: val_input, val_target</li>
<li>테스트데이터: test_input, test_target</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line">dt =DecisionTreeClassifier(random_state =<span class="number">42</span>)</span><br><span class="line">dt.fit(sub_input,sub_target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;훈련성과:&quot;</span>,dt.score(sub_input,sub_target))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;검증성과:&quot;</span>,dt.score(val_input,val_target))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;최종:&quot;</span>,dt.score(test_input,test_target))</span><br></pre></td></tr></table></figure>

<pre><code>훈련성과: 0.9971133028626413
검증성과: 0.864423076923077
최종: 0.8569230769230769
</code></pre>
<ul>
<li>훈련 : 87%</li>
<li>검증 : 86%-&gt;과대적합</li>
</ul>
<hr>
<ul>
<li>최종 : 85%</li>
</ul>
<h3 id="교차-검증"><a href="#교차-검증" class="headerlink" title="교차 검증"></a>교차 검증</h3><ul>
<li>데이터 셋을 반복분할</li>
<li>For loop</li>
<li>샘플링의 편향성을 방지</li>
<li>교차검증을 한다고 해서 정확도가 무조건 올라가는 것은 아님.</li>
<li>모형을 안정적으로 만들어줌(과대적합 방지)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">df = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#데이터를 K폴드로 나눈다.</span></span><br><span class="line">folds = KFold(n_splits=<span class="number">5</span>, shuffle = <span class="literal">True</span>)</span><br><span class="line"><span class="keyword">for</span> train_idx,valid_idx <span class="keyword">in</span> folds.split(df):</span><br><span class="line">  <span class="built_in">print</span>(<span class="string">f&#x27;훈련데이터:<span class="subst">&#123;df[train_idx]&#125;</span>,검증데이터:<span class="subst">&#123;df[valid_idx]&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>훈련데이터:[1 2 3 4 5 6 8 9],검증데이터:[ 7 10]
훈련데이터:[ 1  2  3  4  6  7  8 10],검증데이터:[5 9]
훈련데이터:[ 1  2  4  5  7  8  9 10],검증데이터:[3 6]
훈련데이터:[ 1  3  4  5  6  7  9 10],검증데이터:[2 8]
훈련데이터:[ 2  3  5  6  7  8  9 10],검증데이터:[1 4]
</code></pre>
<ul>
<li>교차 검증 함수</li>
</ul>
<ul>
<li>cross_validate()</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_validate</span><br><span class="line">scores =cross_validate(dt,train_input,train_target)</span><br><span class="line"><span class="built_in">print</span>(scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;평균:&quot;</span>,np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;fit_time&#39;: array([0.01610422, 0.00758529, 0.00780439, 0.00830793, 0.00751185]), &#39;score_time&#39;: array([0.00120473, 0.00096321, 0.00094819, 0.00098753, 0.00134945]), &#39;test_score&#39;: array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])&#125;
평균: 0.855300214703487
</code></pre>
<ul>
<li>StratifiedKFold 사용</li>
</ul>
<ul>
<li>타깃클래스를 골고루 나누기 위함</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold </span><br><span class="line">scores = cross_validate(dt, train_input, train_target, cv = StratifiedKFold())</span><br><span class="line"><span class="built_in">print</span>(scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;평균 : &quot;</span>, np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;fit_time&#39;: array([0.01418257, 0.00769162, 0.00846624, 0.00809741, 0.00809479]), &#39;score_time&#39;: array([0.00103283, 0.00094843, 0.00096679, 0.00104737, 0.00102282]), &#39;test_score&#39;: array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])&#125;
평균 :  0.855300214703487
</code></pre>
<ul>
<li>10-폴드 교차 검증</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> StratifiedKFold</span><br><span class="line">splitter =StratifiedKFold(n_splits = <span class="number">10</span>,shuffle =<span class="literal">True</span>, random_state = <span class="number">42</span>)<span class="comment">#10번 더 교차 검증을 수행</span></span><br><span class="line">scores =cross_validate(dt,train_input,train_target,cv =splitter)</span><br><span class="line"><span class="built_in">print</span>(scores)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;평균:&quot;</span>,np.mean(scores[<span class="string">&#x27;test_score&#x27;</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>&#123;&#39;fit_time&#39;: array([0.01752782, 0.00863743, 0.00879025, 0.0088315 , 0.00837684,
       0.00851107, 0.00831246, 0.00826931, 0.00829077, 0.00844049]), &#39;score_time&#39;: array([0.00099802, 0.00086832, 0.00085974, 0.00183129, 0.00091791,
       0.0008316 , 0.00078368, 0.00092673, 0.00080705, 0.00082994]), &#39;test_score&#39;: array([0.83461538, 0.87884615, 0.85384615, 0.85384615, 0.84615385,
       0.87307692, 0.85961538, 0.85549133, 0.85163776, 0.86705202])&#125;
평균: 0.8574181117533719
</code></pre>
<h2 id="하이퍼-파라미터-튜닝"><a href="#하이퍼-파라미터-튜닝" class="headerlink" title="하이퍼 파라미터 튜닝"></a>하이퍼 파라미터 튜닝</h2><ul>
<li>그리드 서치(사람이 수동입력)</li>
</ul>
<ul>
<li>max_depth: [1.3.5…]</li>
</ul>
<ul>
<li>랜덤 서치(사람이 범위만 지정)</li>
</ul>
<ul>
<li>max_depth: 1~10&#x2F;by random</li>
</ul>
<ul>
<li>베이지안 옵티마이제이션</li>
<li>사람의 개입없이 하이퍼파라미터 튜닝을 자동적으로 수행하는 기술을 AutoML이라고 함</li>
</ul>
<ul>
<li>예)PyCaret</li>
</ul>
<ul>
<li>각 모델마다 적게는 1-2개에서 많게는 5-6개의 매개 변수를 제공한다</li>
<li>하이퍼파라미터와 동시에 교차검증을 수행(불가능하다)</li>
</ul>
<ul>
<li>교차검증 5번</li>
</ul>
<ul>
<li>교차검증 1번 돌때, Max Depth3번 적용 총 결과값 3x5x2나옴</li>
<li>Max Death &#x3D;1,3,7</li>
<li>criterion&#x3D; gini.entropy</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;min_impurity_decrease&#x27;</span> : [<span class="number">0.0001</span>,<span class="number">0.0002</span>,<span class="number">0.0003</span>,<span class="number">0.0004</span>,<span class="number">0.0005</span>]</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state =<span class="number">42</span>),params, n_jobs= -<span class="number">1</span>)</span><br><span class="line">gs.fit(train_input,train_target)</span><br></pre></td></tr></table></figure>




<pre><code>GridSearchCV(estimator=DecisionTreeClassifier(random_state=42), n_jobs=-1,
             param_grid=&#123;&#39;min_impurity_decrease&#39;: [0.0001, 0.0002, 0.0003,
                                                   0.0004, 0.0005]&#125;)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;best:&quot;</span>,gs.best_estimator_)</span><br><span class="line">dt = gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_input, train_target))</span><br></pre></td></tr></table></figure>

<pre><code>best: DecisionTreeClassifier(min_impurity_decrease=0.0001, random_state=42)
0.9615162593804117
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;criterion&#x27;</span> : [<span class="string">&#x27;gini&#x27;</span>, <span class="string">&#x27;entropy&#x27;</span>],</span><br><span class="line">    <span class="string">&#x27;max_depth &#x27;</span>: [<span class="number">1</span>,<span class="number">3</span>,<span class="number">7</span>],</span><br><span class="line">    <span class="string">&#x27;min_impurity_decrease&#x27;</span> : [<span class="number">0.0001</span>,<span class="number">0.0002</span>,<span class="number">0.0003</span>,<span class="number">0.0004</span>,<span class="number">0.0005</span>]</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line">gs = GridSearchCV(DecisionTreeClassifier(random_state =<span class="number">42</span>),params, n_jobs= -<span class="number">1</span>)</span><br><span class="line">gs.fit(train_input,train_target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;best:&quot;</span>,gs.best_estimator_)</span><br><span class="line">dt = gs.best_estimator_</span><br><span class="line"><span class="built_in">print</span>(dt.score(train_input, train_target))</span><br></pre></td></tr></table></figure>

<pre><code>best: DecisionTreeClassifier(max_depth=7, min_impurity_decrease=0.0005,
                       random_state=42)
0.8830094285164518
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-04T08:11:10.000Z" title="2022. 7. 4. 오후 5:11:10">2022-07-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-04T08:15:45.327Z" title="2022. 7. 4. 오후 5:15:45">2022-07-04</time></span><span class="level-item">5 minutes read (About 686 words)</span></div></div><div class="content"><hr>
<h1 id="title-‘머신러닝4-확률적-경사-하강법’"><a href="#title-‘머신러닝4-확률적-경사-하강법’" class="headerlink" title="title: ‘머신러닝4 확률적 경사 하강법’"></a><strong>title: ‘머신러닝4 확률적 경사 하강법’</strong></h1><h1 id="date-‘2022-07-04-09-00’"><a href="#date-‘2022-07-04-09-00’" class="headerlink" title="date: ‘2022-07-04 09:00’"></a><strong>date: ‘2022-07-04 09:00’</strong></h1><hr>
<h2 id="확률적-경사-하강법"><a href="#확률적-경사-하강법" class="headerlink" title="확률적 경사 하강법"></a>확률적 경사 하강법</h2><ul>
<li>점진적 학습 (step, 보폭)</li>
<li>학습률</li>
<li>XGBoost, Light GBM, 딥러닝(이미지 분류, 자연어처리, 옵티마이져)</li>
</ul>
<h3 id="샘플"><a href="#샘플" class="headerlink" title="샘플"></a>샘플</h3><ul>
<li>신경망 이미지 데이터, 자연어</li>
<li>자율주행 하루 데이터 1TB –&gt;학습량이 너무 큼</li>
<li>한꺼번에 모델을 학습하기 어려움</li>
</ul>
<ul>
<li>샘플링, 배치, 에포크, 오차(&#x3D;손실&#x3D;loss)가 가장 작은 지점을 찾아야 함.</li>
</ul>
<ul>
<li>이러한 방법이 확률적 경사 하강법 </li>
<li>빠른 시간내에 손실을 줄일 수 있는 방법을 찾는것&#x3D; 손실함수를 이용.</li>
</ul>
<ul>
<li>10시간 걸려 정확도95% 1시간 걸려 정확도 80% 어느 것이 좋은가? 최적화.</li>
</ul>
<h3 id="손실함수"><a href="#손실함수" class="headerlink" title="손실함수"></a>손실함수</h3><ul>
<li>로지스틱 손실 함수</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">fish = pd.read_csv(<span class="string">&quot;http://bit.ly/fish_csv_data&quot;</span>)</span><br><span class="line">fish.info()</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 159 entries, 0 to 158
Data columns (total 6 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Species   159 non-null    object 
 1   Weight    159 non-null    float64
 2   Length    159 non-null    float64
 3   Diagonal  159 non-null    float64
 4   Height    159 non-null    float64
 5   Width     159 non-null    float64
dtypes: float64(5), object(1)
memory usage: 7.6+ KB
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fish_input =fish[[<span class="string">&#x27;Weight&#x27;</span>,<span class="string">&#x27;Length&#x27;</span>,<span class="string">&#x27;Diagonal&#x27;</span>,<span class="string">&#x27;Height&#x27;</span>,<span class="string">&#x27;Width&#x27;</span>]].to_numpy()</span><br><span class="line">fish_target =fish[<span class="string">&#x27;Species&#x27;</span>].to_numpy()</span><br><span class="line"></span><br><span class="line">fish_input.shape,fish_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((159, 5), (159,))
</code></pre>
<ul>
<li>훈련세트와 테스트 데이터 분리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input,test_input, train_target, test_target =train_test_split(</span><br><span class="line">    fish_input, fish_target, random_state =<span class="number">42</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<ul>
<li>훈련세트와 테스트 세트의 특성 표준화<ul>
<li>무게, 길이, 대각선 길이, 높이, 너비<br>-표준화 처리진행</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br><span class="line"></span><br><span class="line">train_scaled[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([[ 0.91965782,  0.60943175,  0.81041221,  1.85194896,  1.00075672],
       [ 0.30041219,  1.54653445,  1.45316551, -0.46981663,  0.27291745],
       [-1.0858536 , -1.68646987, -1.70848587, -1.70159849, -2.0044758 ],
       [-0.79734143, -0.60880176, -0.67486907, -0.82480589, -0.27631471],
       [-0.71289885, -0.73062511, -0.70092664, -0.0802298 , -0.7033869 ]])
</code></pre>
<h2 id="모델링"><a href="#모델링" class="headerlink" title="모델링"></a>모델링</h2><ul>
<li>확률적 경사 하강법</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</span><br><span class="line">sc = SGDClassifier(loss = <span class="string">&#x27;log&#x27;</span>,max_iter =<span class="number">10</span>, random_state =<span class="number">42</span>)<span class="comment">#에포크 10회는 좀 적으니 더 숫자를 넣어라~</span></span><br><span class="line"></span><br><span class="line">sc.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled,train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.773109243697479
0.775


/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.
  ConvergenceWarning,
</code></pre>
<ul>
<li>partial_fit()메서드 사용하면 추가학습 가능</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sc.partial_fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(sc.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(sc.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8151260504201681
0.85
</code></pre>
<h2 id="에포크와-과대-x2F-과소적합"><a href="#에포크와-과대-x2F-과소적합" class="headerlink" title="에포크와 과대&#x2F;과소적합"></a>에포크와 과대&#x2F;과소적합</h2><ul>
<li>에포크 숫자가 적으면 덜학습 됨</li>
<li>early_stopping</li>
</ul>
<ul>
<li>에포크 숫자를 1000회로 주어졌을 때 손실 10,9,8…..3,3,3</li>
<li>3에 도달한 시점에서 학습을 몇번하고 그만 둠</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">sc = SGDClassifier(loss=<span class="string">&#x27;log&#x27;</span>,random_state=<span class="number">42</span>)</span><br><span class="line">train_score =[]</span><br><span class="line">test_score= []</span><br><span class="line">classes = np.unique(train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment">#300번 에포크 훈련을 반복</span></span><br><span class="line"><span class="comment">#훈련할 때마다, train_score, test_score추가를 한다.</span></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">300</span>):</span><br><span class="line">  sc.partial_fit(train_scaled,train_target, classes= classes)</span><br><span class="line">  train_score.append(sc.score(train_scaled,train_target))</span><br><span class="line">  test_score.append(sc.score(test_scaled,test_target))</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line">fig,ax = plt.subplots()</span><br><span class="line">ax.plot(train_score)</span><br><span class="line">ax.plot(test_score)</span><br><span class="line">ax.legend([<span class="string">&quot;train&quot;</span>, <span class="string">&quot;test&quot;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0704_1/output_16_0.png" alt="png"></p>
<h2 id="XGBoost-LightGBM코드"><a href="#XGBoost-LightGBM코드" class="headerlink" title="XGBoost, LightGBM코드"></a>XGBoost, LightGBM코드</h2><ul>
<li>train-loss, train-accuaray,test-loss,test-accurary</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-01T07:59:07.520Z" title="2022. 7. 1. 오후 4:59:07">2022-07-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-01T07:59:07.521Z" title="2022. 7. 1. 오후 4:59:07">2022-07-01</time></span><span class="level-item">14 minutes read (About 2110 words)</span></div></div><div class="content"><hr>
<h1 id="title-‘머신러닝4-로지스틱-회귀’"><a href="#title-‘머신러닝4-로지스틱-회귀’" class="headerlink" title="title: ‘머신러닝4 로지스틱 회귀’"></a><strong>title: ‘머신러닝4 로지스틱 회귀’</strong></h1><h1 id="date-‘2022-07-01-11-00’"><a href="#date-‘2022-07-01-11-00’" class="headerlink" title="date: ‘2022-07-01 11:00’"></a><strong>date: ‘2022-07-01 11:00’</strong></h1><hr>
<h2 id="로지스틱-회귀"><a href="#로지스틱-회귀" class="headerlink" title="로지스틱 회귀"></a>로지스틱 회귀</h2><ul>
<li><p>선형회귀에서 출발</p>
</li>
<li><p>이진 분류 문제 해결</p>
</li>
<li><p>클래스 확률 예측</p>
</li>
<li><p>딥러닝에서도 사용됨 </p>
</li>
<li><p>P177</p>
</li>
</ul>
<ul>
<li>X가 사격형일 확율 30%</li>
<li>X가 삼각형일 확률 50%</li>
<li>X가 원일 확률 20%</li>
</ul>
<h2 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h2><ul>
<li>Species(종속변수 &#x3D; Y)</li>
<li>Weight,Length, Diagonal,Height,Width(독립변수들)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">fish = pd.read_csv(<span class="string">&#x27;https://bit.ly/fish_csv_data&#x27;</span>)</span><br><span class="line">fish.head()</span><br></pre></td></tr></table></figure>





  <div id="df-1e28b899-1483-4eec-b037-95410a050afe">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Species</th>
      <th>Weight</th>
      <th>Length</th>
      <th>Diagonal</th>
      <th>Height</th>
      <th>Width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bream</td>
      <td>242.0</td>
      <td>25.4</td>
      <td>30.0</td>
      <td>11.5200</td>
      <td>4.0200</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Bream</td>
      <td>290.0</td>
      <td>26.3</td>
      <td>31.2</td>
      <td>12.4800</td>
      <td>4.3056</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Bream</td>
      <td>340.0</td>
      <td>26.5</td>
      <td>31.1</td>
      <td>12.3778</td>
      <td>4.6961</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Bream</td>
      <td>363.0</td>
      <td>29.0</td>
      <td>33.5</td>
      <td>12.7300</td>
      <td>4.4555</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Bream</td>
      <td>430.0</td>
      <td>29.0</td>
      <td>34.0</td>
      <td>12.4440</td>
      <td>5.1340</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-1e28b899-1483-4eec-b037-95410a050afe')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

<p>  &lt;svg xmlns&#x3D;”<a target="_blank" rel="noopener" href="http://www.w3.org/2000/svg&quot;">http://www.w3.org/2000/svg&quot;</a> height&#x3D;”24px”viewBox&#x3D;”0 0 24 24”<br>       width&#x3D;”24px”&gt;<br>    <path d="M0 0h24v24H0V0z" fill="none"/><br>    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/><br>  </svg><br>      </button></p>
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

<pre><code>  &lt;script&gt;
    const buttonEl =
      document.querySelector(&#39;#df-1e28b899-1483-4eec-b037-95410a050afe button.colab-df-convert&#39;);
    buttonEl.style.display =
      google.colab.kernel.accessAllowed ? &#39;block&#39; : &#39;none&#39;;

    async function convertToInteractive(key) &#123;
      const element = document.querySelector(&#39;#df-1e28b899-1483-4eec-b037-95410a050afe&#39;);
      const dataTable =
        await google.colab.kernel.invokeFunction(&#39;convertToInteractive&#39;,
                                                 [key], &#123;&#125;);
      if (!dataTable) return;

      const docLinkHtml = &#39;Like what you see? Visit the &#39; +
        &#39;&lt;a target=&quot;_blank&quot; href=https://colab.research.google.com/notebooks/data_table.ipynb&gt;data table notebook&lt;/a&gt;&#39;
        + &#39; to learn more about interactive tables.&#39;;
      element.innerHTML = &#39;&#39;;
      dataTable[&#39;output_type&#39;] = &#39;display_data&#39;;
      await google.colab.output.renderOutput(dataTable, element);
      const docLink = document.createElement(&#39;div&#39;);
      docLink.innerHTML = docLinkHtml;
      element.appendChild(docLink);
    &#125;
  &lt;/script&gt;
&lt;/div&gt;
</code></pre>
  </div>




<h2 id="데이터-탐색"><a href="#데이터-탐색" class="headerlink" title="데이터 탐색"></a>데이터 탐색</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 종속변수</span></span><br><span class="line"><span class="built_in">print</span>(pd.unique(fish[<span class="string">&#x27;Species&#x27;</span>]))<span class="comment">#유니크함수로 스피시스열의 고유값 추출</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(fish[<span class="string">&#x27;Species&#x27;</span>].value_counts())</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Roach&#39; &#39;Whitefish&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Smelt&#39;]

Perch        56
Bream        35
Roach        20
Pike         17
Smelt        14
Parkki       11
Whitefish     6
Name: Species, dtype: int64
</code></pre>
<h2 id="데이터-가공"><a href="#데이터-가공" class="headerlink" title="데이터 가공"></a>데이터 가공</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 판다스 데이터 프레임에서 넘파이 배열로 변환</span></span><br><span class="line">fish_input = fish[[<span class="string">&#x27;Weight&#x27;</span>,<span class="string">&#x27;Length&#x27;</span>,<span class="string">&#x27;Diagonal&#x27;</span>,<span class="string">&#x27;Height&#x27;</span>,<span class="string">&#x27;Width&#x27;</span>]].to_numpy() </span><br><span class="line"><span class="comment">#  fish 데이터 프레임에서 여러열을 선택해 새로운 데이터 프레임을 넘파이 배열로 바꾸어 저장</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(fish_input.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(159, 5)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(fish_input[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>[[242.      25.4     30.      11.52     4.02  ]
 [290.      26.3     31.2     12.48     4.3056]
 [340.      26.5     31.1     12.3778   4.6961]
 [363.      29.      33.5     12.73     4.4555]
 [430.      29.      34.      12.444    5.134 ]]
</code></pre>
<ul>
<li>타킷데이터, 종속변수, Y</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fish_target = fish[<span class="string">&#x27;Species&#x27;</span>].to_numpy()</span><br><span class="line"><span class="built_in">print</span>(fish_target.shape)</span><br><span class="line"><span class="built_in">print</span>(fish_target[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>(159,)
[&#39;Bream&#39; &#39;Bream&#39; &#39;Bream&#39; &#39;Bream&#39; &#39;Bream&#39;]
</code></pre>
<h2 id="데이터-분리"><a href="#데이터-분리" class="headerlink" title="데이터 분리"></a>데이터 분리</h2><ul>
<li>훈련 데이터 테스트 데이터 분리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="comment">#임의 샘플링</span></span><br><span class="line"></span><br><span class="line">train_input, test_input,train_target,test_target = train_test_split(</span><br><span class="line">    fish_input, fish_target, random_state= <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(train_input.shape) <span class="comment"># 훈련데이터 값</span></span><br><span class="line"><span class="comment">#층화 샘플링</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>(119, 5)
</code></pre>
<h2 id="표준화-전처리"><a href="#표준화-전처리" class="headerlink" title="표준화 전처리"></a>표준화 전처리</h2><ul>
<li>여기에서도 훈련 세트의 통계 값으로 테스트 세트를 변환해야 한다는 점을 잊지 마세요!!(중요)</li>
<li>훈련 세트의 평균값과 테스트 세트의 평균값는 다르다. 따라서 테스트 세트의 평균값(통계값)을 훈련세트의 평균값(통계값)으로 대체해줘야 한다.</li>
<li>데이터 가공</li>
</ul>
<ul>
<li>숫자 결측치가 존재, 평균값으로 대체</li>
<li>원본 데이터 평균으로 대치하면 안됨</li>
<li>훈련 데이터와 테스트 데이터 분리</li>
</ul>
<ul>
<li>데이터 누수(Data Leakage)</li>
</ul>
<ul>
<li>훈련데이터 평균값 70을 대치(기준)</li>
<li>테스트 데이터 평균값(75)과 모든 데이터 평균값(72.5)은 기준이 안됨 </li>
<li>참조: <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/common_pitfalls.html">https://scikit-learn.org/stable/common_pitfalls.html</a></li>
</ul>
<p>cf) 기준을 맞춰라 –&gt;데이터 표준화(표준점수)</p>
<ul>
<li>p97~100는 수동으로 mean,std 을<br>  -‘# train_scaled &#x3D; (train_input - mean)&#x2F; std<br>   라는 수식을 만들어 사용했으나 </li>
<li>StandardScaler 라는 매소드가 있으니 이를 이용하면 된다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">ss.fit(train_input)</span><br><span class="line"><span class="comment">#ss.fit(test_input)을 하면 안됨!!-&gt; 훈련테스트 통계값으로 통일</span></span><br><span class="line">train_scaled = ss.transform(train_input)</span><br><span class="line">test_scaled = ss.transform(test_input)</span><br></pre></td></tr></table></figure>

<h2 id="모형-만들기"><a href="#모형-만들기" class="headerlink" title="모형 만들기"></a>모형 만들기</h2><ul>
<li>K-최근접 이웃</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">kn = KNeighborsClassifier(n_neighbors = <span class="number">3</span>)</span><br><span class="line">kn.fit(train_scaled, train_target)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(kn.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(kn.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.8907563025210085
0.85
</code></pre>
<ul>
<li>타깃값 확인</li>
<li>알파벳 순으로 정렬</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(kn.classes_)</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Smelt&#39; &#39;Whitefish&#39;]
</code></pre>
<ul>
<li><p>다중분율</p>
</li>
<li><p>5개 샘플에 대한 예측은 어떤 확률이냐?</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">proba = kn.predict_proba(test_scaled[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(kn.classes_)</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(proba,decimals= <span class="number">4</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Smelt&#39; &#39;Whitefish&#39;]
[[0.     0.     1.     0.     0.     0.     0.    ]
 [0.     0.     0.     0.     0.     1.     0.    ]
 [0.     0.     0.     1.     0.     0.     0.    ]
 [0.     0.     0.6667 0.     0.3333 0.     0.    ]
 [0.     0.     0.6667 0.     0.3333 0.     0.    ]]
</code></pre>
<ul>
<li>첫번째 클래스는 Perch</li>
</ul>
<ul>
<li>100% 확률로 Perch로 예측</li>
</ul>
<ul>
<li>네번째 클래스는 Perch</li>
</ul>
<ul>
<li>66.7%확률로 Perch로 예측</li>
<li>33.3%확률로 Roach로 예측</li>
</ul>
<h2 id="회귀식"><a href="#회귀식" class="headerlink" title="회귀식"></a>회귀식</h2><ul>
<li>y&#x3D; ax + b</li>
<li>양변에 로그를 취함</li>
<li>원래 값으로 돌리기 위해 양변을 다시 지수로 변환-&gt;로지스틱 회귀</li>
</ul>
<h2 id="로지스틱-회귀로-이진분류-수행"><a href="#로지스틱-회귀로-이진분류-수행" class="headerlink" title="로지스틱 회귀로 이진분류 수행"></a>로지스틱 회귀로 이진분류 수행</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">char_arr = np.array([<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;C&#x27;</span>,<span class="string">&#x27;D&#x27;</span>,<span class="string">&#x27;E&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(char_arr[[<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">True</span>,<span class="literal">False</span>,<span class="literal">False</span>]])</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;A&#39; &#39;C&#39;]
</code></pre>
<ul>
<li>도미와 빙어의 행만 골라냄 (bream,smelt)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bream_smelt_indexes =(train_target == <span class="string">&#x27;Bream&#x27;</span>) | (train_target == <span class="string">&#x27;Smelt&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(bream_smelt_indexes)</span><br><span class="line">train_bream_smelt = train_scaled[bream_smelt_indexes]</span><br><span class="line">target_bream_smelt = train_target[bream_smelt_indexes]</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_scaled.shape, train_bream_smelt.shape)</span><br></pre></td></tr></table></figure>

<pre><code>[ True False  True False False False False  True False False False  True
 False False False  True  True False False  True False  True False False
 False  True False False  True False False False False  True False False
  True  True False False False False False  True False False False False
 False  True False  True False False  True False False False  True False
 False False False False False  True False  True False False False False
 False False False False False  True False  True False False  True  True
 False False False  True False False False False False  True False False
 False  True False  True False False  True  True False False False False
 False False False False  True  True False False  True False False]
(119, 5) (33, 5)
</code></pre>
<ul>
<li>총 119마리에서 참인 값은 33마리만 추출</li>
</ul>
<h2 id="모델-만들기"><a href="#모델-만들기" class="headerlink" title="모델 만들기"></a>모델 만들기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">lr = LogisticRegression()</span><br><span class="line">lr.fit(train_bream_smelt,target_bream_smelt)</span><br></pre></td></tr></table></figure>




<pre><code>LogisticRegression()
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.predict(train_bream_smelt[:<span class="number">5</span>]))<span class="comment">#훈련한 모델로 5개 샘플 예측</span></span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Smelt&#39; &#39;Bream&#39; &#39;Bream&#39; &#39;Bream&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.predict_proba(train_bream_smelt[:<span class="number">5</span>]))<span class="comment"># 예측 확율을 출력 두번째만 도미가 아님</span></span><br></pre></td></tr></table></figure>

<pre><code>[[0.99759855 0.00240145]
 [0.02735183 0.97264817]
 [0.99486072 0.00513928]
 [0.98584202 0.01415798]
 [0.99767269 0.00232731]]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.classes_) <span class="comment"># 음성클라스 도미(0): 양성크라스 빙어(1)</span></span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Bream&#39; &#39;Smelt&#39;]
</code></pre>
<ul>
<li>cf. 분류기준 : threshold 임계값 설정(경계선 설정)</li>
</ul>
<ul>
<li>도미 Vs 빙어 <ul>
<li>[0.51,0.49]-&gt; 이런값은 도미인가 빙어인가?</li>
<li>[0.90,0.10]</li>
</ul>
</li>
</ul>
<ul>
<li>계수와 절편</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)<span class="comment">#로지스틱 회귀는 선형회귀와 비슷</span></span><br></pre></td></tr></table></figure>

<pre><code>[[-0.4037798  -0.57620209 -0.66280298 -1.01290277 -0.73168947]] [-2.16155132]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">decisions = lr.decision_function(train_bream_smelt[:<span class="number">5</span>])<span class="comment">#decision_function()메서드로 Z값 출력</span></span><br><span class="line"><span class="built_in">print</span>(decisions)</span><br></pre></td></tr></table></figure>

<pre><code>[[ 13.07724442   5.67940163  -3.35341274  -3.31343798   2.17367082
  -20.94258142   6.67911528]
 [-11.87101288   2.30253045   5.38260123  -3.16152122   3.19003127
    8.30344773  -4.14607657]
 [ 12.33862012   5.65079591  -4.66939988  -2.1462105    1.70362799
  -17.38222731   4.50479367]
 [ 10.54150945   6.10969846  -4.81186721  -2.96238906   2.29032761
  -14.96402558   3.79674632]
 [ 13.67852112   5.73152066  -4.25491239  -2.55085968   1.73528849
  -20.24827704   5.90871883]]
</code></pre>
<ul>
<li>z값을 확율값으로 변환시켜야 함. 지수변환(p188)시켜야 함</li>
<li>expit()</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> expit</span><br><span class="line"><span class="built_in">print</span>(expit(decisions))</span><br></pre></td></tr></table></figure>

<pre><code>[0.00240145 0.97264817 0.00513928 0.01415798 0.00232731]
</code></pre>
<h2 id="다중-분류-수행하기"><a href="#다중-분류-수행하기" class="headerlink" title="다중 분류 수행하기"></a>다중 분류 수행하기</h2><ul>
<li>2진분류의 확장판</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 하이퍼 파라메터 세팅</span></span><br><span class="line"><span class="comment"># 모형을 튜닝(잘모르면 건들지 않는게 좋음, defult값 사용)</span></span><br><span class="line"><span class="comment"># 모형 결과의 과대적합 또는 과소적합을 방지하기 위한 것</span></span><br><span class="line">lr = LogisticRegression(C =<span class="number">20</span> , max_iter = <span class="number">1000</span>)</span><br><span class="line">lr.fit(train_scaled, train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.score(train_scaled, train_target))</span><br><span class="line"><span class="built_in">print</span>(lr.score(test_scaled, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9327731092436975
0.925
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.predict(test_scaled[:<span class="number">5</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;Perch&#39; &#39;Smelt&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Perch&#39;]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">proba = lr.predict_proba(test_scaled[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(np.<span class="built_in">round</span>(proba, decimals = <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(lr.classes_)</span><br></pre></td></tr></table></figure>

<pre><code>[[0.    0.014 0.841 0.    0.136 0.007 0.003]
 [0.    0.003 0.044 0.    0.007 0.946 0.   ]
 [0.    0.    0.034 0.935 0.015 0.016 0.   ]
 [0.011 0.034 0.306 0.007 0.567 0.    0.076]
 [0.    0.    0.904 0.002 0.089 0.002 0.001]]
[&#39;Bream&#39; &#39;Parkki&#39; &#39;Perch&#39; &#39;Pike&#39; &#39;Roach&#39; &#39;Smelt&#39; &#39;Whitefish&#39;]
</code></pre>
<ul>
<li>다중 분류일 경우 선형 방정식은 어떤 모습일까?</li>
<li>분류 7개 컬럼 값 5개</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_,lr.intercept_)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(lr.coef_.shape, lr.intercept_.shape)</span><br></pre></td></tr></table></figure>

<pre><code>[[-1.49002087 -1.02912886  2.59345551  7.70357682 -1.2007011 ]
 [ 0.19618235 -2.01068181 -3.77976834  6.50491489 -1.99482722]
 [ 3.56279745  6.34357182 -8.48971143 -5.75757348  3.79307308]
 [-0.10458098  3.60319431  3.93067812 -3.61736674 -1.75069691]
 [-1.40061442 -6.07503434  5.25969314 -0.87220069  1.86043659]
 [-1.38526214  1.49214574  1.39226167 -5.67734118 -4.40097523]
 [ 0.62149861 -2.32406685 -0.90660867  1.71599038  3.6936908 ]] [-0.09205179 -0.26290885  3.25101327 -0.14742956  2.65498283 -6.78782948
  1.38422358]

(7, 5) (7,)
</code></pre>
<h2 id="평가지표"><a href="#평가지표" class="headerlink" title="평가지표"></a>평가지표</h2><ul>
<li><p>회귀 평가지표<br>-&gt; 결정계수($R^2$)P.121</p>
<ul>
<li>$1-[(타깃-예측)^2의 합&#x2F;(타깃-평균)^2합]$</li>
</ul>
</li>
<li><p>MAE, MSE, RMSE</p>
<ul>
<li>(실제 - 예측) &#x3D;오차</li>
<li>MAE(mean absolute errer): 오차의 절댓값의 평균</li>
<li>MSE(m Squared e): 오차의 제곱의 평균</li>
<li>RMSE(Root MSE): MSE에 제곱근을 취한값</li>
</ul>
</li>
<li><p>좋은 모델이란</p>
</li>
</ul>
<ul>
<li>결정계수 :1에 수렴하면 좋은 모델</li>
<li>MAE외 :0에 수렴하면 좋은 모델</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error, mean_squared_error, r2_score</span><br><span class="line"></span><br><span class="line">true = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">4</span>,<span class="number">6</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">8</span>]) <span class="comment">#실제값</span></span><br><span class="line">preds = np.array([<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">7</span>,<span class="number">6</span>,<span class="number">8</span>])<span class="comment">#예측값</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#절대값 오차의 평균</span></span><br><span class="line">mae = mean_absolute_error(true, preds)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;mae=&quot;</span>,mae)</span><br><span class="line"><span class="comment">#제곱 오차의 평균</span></span><br><span class="line">mse = mean_absolute_error(true, preds)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;mse=&quot;</span>,mse)</span><br><span class="line"><span class="comment">#mse제곱근</span></span><br><span class="line">rmse =np.sqrt(mse)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;rmse=&quot;</span>,rmse)</span><br><span class="line"><span class="comment">#결정계수</span></span><br><span class="line">r2 = r2_score(true, preds)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;r2=&quot;</span>,r2)</span><br></pre></td></tr></table></figure>

<pre><code>mae= 0.5384615384615384
mse= 0.5384615384615384
rmse= 0.7337993857053428
r2= 0.8617021276595744
</code></pre>
<h2 id="분류-오차-행렬"><a href="#분류-오차-행렬" class="headerlink" title="분류 오차 행렬"></a>분류 오차 행렬</h2><ul>
<li>오차 행렬</li>
<li>실제 값</li>
</ul>
<ul>
<li>[빙어, 도미, 도미, 빙어, 도미]</li>
</ul>
<ul>
<li>예측 값</li>
</ul>
<ul>
<li><p>[빙어, 빙어, 도미, 빙어, 빙어]</p>
<ul>
<li>TP(빙어를 빙어로 예측):2</li>
<li>TN(도미를 도미로 예측):1</li>
<li>FP(실제도미,예측 빙어):2</li>
<li>FN(실제빙어,예측 도미):0</li>
</ul>
</li>
</ul>
<ul>
<li>모형의 정확도 3&#x2F;5 &#x3D;60% </li>
<li>사이킷런에 분류오차행렬 함수가 있다.</li>
<li>TP,TN,FP,FN(5,4,3,7)</li>
</ul>
<ul>
<li>정확도(5+4&#x2F;5+5+3+7)</li>
<li>정밀도(precision:5&#x2F;5+3):양성이라 예측(TP+FP)중 실제 양성값(TP)의 비율(스팸메일)-&gt;실수를 옳다고 생각하면 안되는 값</li>
<li>재현율(5&#x2F;5+7):실제 양성(TP+FN) 값 중 양성으로 예측한 값(TP)의 비율 (암진단)-&gt;사실을 거짓으로 판단하면 큰일나는 값</li>
<li>로그손실</li>
<li>ROC Curve(&#x3D;AUC)</li>
</ul>
<ul>
<li>코로나 검사</li>
</ul>
<ul>
<li>양성(1) : 음성(99)</li>
<li>머신러닝 모형 :98%&#x2F; 정밀도 99</li>
<li>인간 음성진단 :99%&#x2F; 정밀도 95</li>
<li>검사자가 실제는 양성이나 진단은 음성으로 내릴 가능성이 높음(의료사고)-재현율로 파악하는 것이 옳다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"></span><br><span class="line">true = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">preds = [<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">confusion_matrix(true, preds)</span><br></pre></td></tr></table></figure>




<pre><code>array([[2, 1],
       [2, 0]])
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-07-01T07:47:32.000Z" title="2022. 7. 1. 오후 4:47:32">2022-07-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-07-01T07:50:43.160Z" title="2022. 7. 1. 오후 4:50:43">2022-07-01</time></span><span class="level-item">5 minutes read (About 703 words)</span></div></div><div class="content"><hr>
<h1 id="title-‘머신러닝3-회귀알고리즘’"><a href="#title-‘머신러닝3-회귀알고리즘’" class="headerlink" title="title: ‘머신러닝3 회귀알고리즘’"></a><strong>title: ‘머신러닝3 회귀알고리즘’</strong></h1><h1 id="date-‘2022-07-01-09-00’"><a href="#date-‘2022-07-01-09-00’" class="headerlink" title="date: ‘2022-07-01 09:00’"></a><strong>date: ‘2022-07-01 09:00’</strong></h1><hr>
<h2 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="built_in">print</span>(np.__version__)</span><br></pre></td></tr></table></figure>

<pre><code>1.21.6
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">perch_length = np.array(</span><br><span class="line">    [<span class="number">8.4</span>, <span class="number">13.7</span>, <span class="number">15.0</span>, <span class="number">16.2</span>, <span class="number">17.4</span>, <span class="number">18.0</span>, <span class="number">18.7</span>, <span class="number">19.0</span>, <span class="number">19.6</span>, <span class="number">20.0</span>, </span><br><span class="line">     <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.3</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.5</span>, </span><br><span class="line">     <span class="number">22.5</span>, <span class="number">22.7</span>, <span class="number">23.0</span>, <span class="number">23.5</span>, <span class="number">24.0</span>, <span class="number">24.0</span>, <span class="number">24.6</span>, <span class="number">25.0</span>, <span class="number">25.6</span>, <span class="number">26.5</span>, </span><br><span class="line">     <span class="number">27.3</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">28.0</span>, <span class="number">28.7</span>, <span class="number">30.0</span>, <span class="number">32.8</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">     <span class="number">36.5</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">37.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, </span><br><span class="line">     <span class="number">40.0</span>, <span class="number">42.0</span>, <span class="number">43.0</span>, <span class="number">43.0</span>, <span class="number">43.5</span>, <span class="number">44.0</span>]</span><br><span class="line">     )</span><br><span class="line">perch_weight = np.array(</span><br><span class="line">    [<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, </span><br><span class="line">     <span class="number">110.0</span>, <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, </span><br><span class="line">     <span class="number">130.0</span>, <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, </span><br><span class="line">     <span class="number">197.0</span>, <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, </span><br><span class="line">     <span class="number">514.0</span>, <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, </span><br><span class="line">     <span class="number">820.0</span>, <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, </span><br><span class="line">     <span class="number">1000.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">     )</span><br><span class="line"><span class="built_in">print</span>(perch_length.shape,perch_weight.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(56,) (56,)
</code></pre>
<h2 id="데이터-가공"><a href="#데이터-가공" class="headerlink" title="데이터 가공"></a>데이터 가공</h2><ul>
<li>1차원 데이터를 가공</li>
<li>train_test_split로 훈련 세트와 테스트 세트로 나눈 후 1-&gt;2차원배열로 변환</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    <span class="comment"># 독립변수, 종속변수</span></span><br><span class="line">    perch_length, perch_weight, random_state = <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape, train_target.shape, test_target.shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>(42,) (14,) (42,) (14,)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1차원 -&gt;2차원:넘파이배열은 크기를 바꾸는 reshape()메서드가 있다.자동으로 바꾸는 식 (-1,1)을 이용한다</span></span><br><span class="line">train_input = train_input.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">test_input = test_input.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h2 id="데이터-시각화-gt-데이터-재가공"><a href="#데이터-시각화-gt-데이터-재가공" class="headerlink" title="데이터 시각화-&gt;데이터 재가공"></a>데이터 시각화-&gt;데이터 재가공</h2><h2 id="모델링"><a href="#모델링" class="headerlink" title="모델링"></a>모델링</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line">knr = KNeighborsRegressor(n_neighbors=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#모형훈련</span></span><br><span class="line">knr.fit(train_input, train_target)</span><br></pre></td></tr></table></figure>




<pre><code>KNeighborsRegressor(n_neighbors=3)
</code></pre>
<h2 id="모델평가"><a href="#모델평가" class="headerlink" title="모델평가"></a>모델평가</h2><h2 id="모델-예측"><a href="#모델-예측" class="headerlink" title="모델 예측"></a>모델 예측</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 농어의 50cm --&gt; 농어의 무게</span></span><br><span class="line"><span class="built_in">print</span>(knr.predict([[<span class="number">50</span>]]))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>[1033.33333333]
</code></pre>
<h2 id="모형-평가를-위한-시각화"><a href="#모형-평가를-위한-시각화" class="headerlink" title="모형 평가를 위한 시각화"></a>모형 평가를 위한 시각화</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scipy.spatial <span class="keyword">import</span> distance</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 50cm 농어의 이웃을 3개</span></span><br><span class="line">distances, indexes = knr.kneighbors([[<span class="number">50</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련세트의 산점도를 그립니다.</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input, train_target)</span><br><span class="line"><span class="comment"># 훈련세트 중에서 이웃 샘플만 다시 그립니다</span></span><br><span class="line">ax.scatter(train_input[indexes], train_target[indexes],marker=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line"><span class="comment"># 농어의 길이 #농어의 무게</span></span><br><span class="line">ax.scatter(<span class="number">50</span>, <span class="number">1033</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0701_1/output_14_0.png" alt="png"></p>
<ul>
<li>맞는 것처럼 보이지만 길이를 100cm으로 해도 똑같은 결과(1033)가 나온다. 멀리있는 데이터를 가지고 왔다. 잘못된 알고리즘이다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 100cm 농어의 이웃을 3개</span></span><br><span class="line">distances, indexes = knr.kneighbors([[<span class="number">100</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(distances, indexes)</span><br><span class="line"><span class="comment"># 훈련세트의 산점도를 그립니다.</span></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input, train_target)</span><br><span class="line"><span class="comment"># 훈련세트 중에서 이웃 샘플만 다시 그립니다</span></span><br><span class="line">ax.scatter(train_input[indexes], train_target[indexes],marker=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line"><span class="comment"># 농어의 길이 #농어의 무게</span></span><br><span class="line">ax.scatter(<span class="number">100</span>, <span class="number">1033</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(knr.predict([[<span class="number">100</span>]]))<span class="comment"># 100cm도 똑같이 1033g 나온다</span></span><br></pre></td></tr></table></figure>

<pre><code>[[56. 57. 57.]] [[34  8 14]]
</code></pre>
<p><img src="/images/day0701_1/output_16_1.png" alt="png"></p>
<pre><code>[1033.33333333]
</code></pre>
<h2 id="선형-회귀-p-136"><a href="#선형-회귀-p-136" class="headerlink" title="선형 회귀(p.136)"></a>선형 회귀(p.136)</h2><ul>
<li>사이킷에서 선형회귀 알고리즘을 사용해보자.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 파이썬</span></span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">lr= LinearRegression()</span><br><span class="line"><span class="comment"># 선형회귀 모델을 훈련</span></span><br><span class="line"></span><br><span class="line">lr.fit(train_input, train_target)</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<pre><code>LinearRegression()
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">50</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[1241.83860323]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">1000</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[38308.12631868]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_,lr.intercept_) <span class="comment"># lr.coef_는 기울기(계수, 가중치) 값,lr.intercept_(절편)</span></span><br></pre></td></tr></table></figure>

<pre><code>[39.01714496] -709.0186449535477
</code></pre>
<h3 id="선형회귀에서-다항회귀로-바꾸자"><a href="#선형회귀에서-다항회귀로-바꾸자" class="headerlink" title="선형회귀에서 다항회귀로 바꾸자"></a>선형회귀에서 다항회귀로 바꾸자</h3><ul>
<li>농어 1cm가 -650g은 이상하다.</li>
<li>직선의 기울기 대신 곡선의 기울기를 쓰자.</li>
<li>직선은 1차방정식, 곡선은 2차방정식</li>
<li>$ 무게 &#x3D;a \times\ 길이^2 + b \times\ 길이 + 절편 $</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#p.140</span></span><br><span class="line">train_poly = np.column_stack((train_input **<span class="number">2</span>, train_input))</span><br><span class="line">test_poly = np.column_stack((test_input **<span class="number">2</span>, test_input))</span><br><span class="line"><span class="built_in">print</span>(train_poly.shape, test_poly.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 2) (14, 2)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lr = LinearRegression()</span><br><span class="line">lr.fit(train_poly,train_target)</span><br><span class="line"><span class="built_in">print</span>(lr.predict([[<span class="number">50</span> ** <span class="number">2</span>, <span class="number">50</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[1573.98423528]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(lr.coef_, lr.intercept_)</span><br></pre></td></tr></table></figure>

<pre><code>[  1.01433211 -21.55792498] 116.0502107827827
</code></pre>
<ul>
<li>$무게 &#x3D; 1.01 \times\ 길이^2 - 21.6 \times\ 길이 +116.05$</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-06-30T08:12:48.000Z" title="2022. 6. 30. 오후 5:12:48">2022-06-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-06-30T08:19:52.380Z" title="2022. 6. 30. 오후 5:19:52">2022-06-30</time></span><span class="level-item">4 minutes read (About 619 words)</span></div></div><div class="content"><p>title: ‘머신러닝3 회귀알고리즘’</p>
<p>date: ‘2022-06-30 14:00’</p>
<h2 id="K-최근접-이웃-회귀"><a href="#K-최근접-이웃-회귀" class="headerlink" title="K- 최근접 이웃 회귀"></a>K- 최근접 이웃 회귀</h2><ul>
<li>지도학습 알고리즘은 크게 분류와 회귀</li>
<li>지도 학습 : 종속변수 존재</li>
</ul>
<ul>
<li>분류 : 도미와 빙어 분류 문제 해결</li>
<li>회귀 : 통계 회귀분석 y &#x3D; ax + b</li>
</ul>
<h2 id="데이터-불러오기"><a href="#데이터-불러오기" class="headerlink" title="데이터 불러오기"></a>데이터 불러오기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="built_in">print</span>(np.__version__)</span><br></pre></td></tr></table></figure>

<pre><code>1.21.6
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">perch_length = np.array(</span><br><span class="line">    [<span class="number">8.4</span>, <span class="number">13.7</span>, <span class="number">15.0</span>, <span class="number">16.2</span>, <span class="number">17.4</span>, <span class="number">18.0</span>, <span class="number">18.7</span>, <span class="number">19.0</span>, <span class="number">19.6</span>, <span class="number">20.0</span>, </span><br><span class="line">     <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.0</span>, <span class="number">21.3</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.0</span>, <span class="number">22.5</span>, </span><br><span class="line">     <span class="number">22.5</span>, <span class="number">22.7</span>, <span class="number">23.0</span>, <span class="number">23.5</span>, <span class="number">24.0</span>, <span class="number">24.0</span>, <span class="number">24.6</span>, <span class="number">25.0</span>, <span class="number">25.6</span>, <span class="number">26.5</span>, </span><br><span class="line">     <span class="number">27.3</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">27.5</span>, <span class="number">28.0</span>, <span class="number">28.7</span>, <span class="number">30.0</span>, <span class="number">32.8</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">     <span class="number">36.5</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">37.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">39.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, <span class="number">40.0</span>, </span><br><span class="line">     <span class="number">40.0</span>, <span class="number">42.0</span>, <span class="number">43.0</span>, <span class="number">43.0</span>, <span class="number">43.5</span>, <span class="number">44.0</span>]</span><br><span class="line">     )</span><br><span class="line">perch_weight = np.array(</span><br><span class="line">    [<span class="number">5.9</span>, <span class="number">32.0</span>, <span class="number">40.0</span>, <span class="number">51.5</span>, <span class="number">70.0</span>, <span class="number">100.0</span>, <span class="number">78.0</span>, <span class="number">80.0</span>, <span class="number">85.0</span>, <span class="number">85.0</span>, </span><br><span class="line">     <span class="number">110.0</span>, <span class="number">115.0</span>, <span class="number">125.0</span>, <span class="number">130.0</span>, <span class="number">120.0</span>, <span class="number">120.0</span>, <span class="number">130.0</span>, <span class="number">135.0</span>, <span class="number">110.0</span>, </span><br><span class="line">     <span class="number">130.0</span>, <span class="number">150.0</span>, <span class="number">145.0</span>, <span class="number">150.0</span>, <span class="number">170.0</span>, <span class="number">225.0</span>, <span class="number">145.0</span>, <span class="number">188.0</span>, <span class="number">180.0</span>, </span><br><span class="line">     <span class="number">197.0</span>, <span class="number">218.0</span>, <span class="number">300.0</span>, <span class="number">260.0</span>, <span class="number">265.0</span>, <span class="number">250.0</span>, <span class="number">250.0</span>, <span class="number">300.0</span>, <span class="number">320.0</span>, </span><br><span class="line">     <span class="number">514.0</span>, <span class="number">556.0</span>, <span class="number">840.0</span>, <span class="number">685.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">690.0</span>, <span class="number">900.0</span>, <span class="number">650.0</span>, </span><br><span class="line">     <span class="number">820.0</span>, <span class="number">850.0</span>, <span class="number">900.0</span>, <span class="number">1015.0</span>, <span class="number">820.0</span>, <span class="number">1100.0</span>, <span class="number">1000.0</span>, <span class="number">1100.0</span>, </span><br><span class="line">     <span class="number">1000.0</span>, <span class="number">1000.0</span>]</span><br><span class="line">     )</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">fig, ax= plt.subplots() <span class="comment"># 객체지향의 시작</span></span><br><span class="line">ax.scatter(perch_length,perch_weight)</span><br><span class="line">ax.set_xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show</span><br><span class="line"></span><br></pre></td></tr></table></figure>




<pre><code>&lt;function matplotlib.pyplot.show&gt;
</code></pre>
<p><img src="/images/day0630_ch3/output_5_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    perch_length, perch_weight, random_state = <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br><span class="line"><span class="built_in">print</span>(train_input.ndim)</span><br></pre></td></tr></table></figure>

<pre><code>1
</code></pre>
<ul>
<li>1차원 배열-&gt; 2차원 배열</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_input = train_input. reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">test_input = test_input.reshape(-<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(train_input.shape, test_input.shape)</span><br><span class="line"><span class="built_in">print</span>(train_input.ndim)</span><br></pre></td></tr></table></figure>

<pre><code>(42, 1) (14, 1)
2
</code></pre>
<h2 id="결정계수"><a href="#결정계수" class="headerlink" title="결정계수"></a>결정계수</h2><ul>
<li>Adjusted -R Squared</li>
<li>정확한 지표(0~1)</li>
<li>1에 가까울수록 예측 모형이 예측을 잘한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor</span><br><span class="line"></span><br><span class="line">knr = KNeighborsRegressor()</span><br><span class="line"></span><br><span class="line"><span class="comment">#모형학습</span></span><br><span class="line">knr.fit(train_input,train_target)</span><br><span class="line"></span><br><span class="line"><span class="comment">#테스트 세트의 점수를 확인한다</span></span><br><span class="line"><span class="built_in">print</span>(knr.score(test_input,test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.992809406101064
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line"></span><br><span class="line"><span class="comment">#예측 데이터</span></span><br><span class="line">test_prediction = knr.predict(test_input)</span><br><span class="line"></span><br><span class="line"><span class="comment">#테스트 세트에 대한 평균 절댓값 오차를 계산</span></span><br><span class="line">mae = mean_absolute_error(test_target,test_prediction)</span><br><span class="line"><span class="built_in">print</span>(mae)</span><br></pre></td></tr></table></figure>

<pre><code>19.157142857142862
</code></pre>
<ul>
<li>예측이 평균적으로 19g정도 다르다.</li>
</ul>
<ul>
<li>확실한 것은 오차가 존재하는데 19g이 의미하는 것은 무엇인가?<ul>
<li>오차를 줄일 필요가 있음(더 많은 데이터를 모으거나 알고리즘을 바꿔야 함)</li>
</ul>
</li>
<li>개선을 지속적으로 하여 0g이 될때까지</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(knr.score(train_input, train_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.9698823289099254
</code></pre>
<h2 id="과대적합-vs-과소적합"><a href="#과대적합-vs-과소적합" class="headerlink" title="과대적합 vs 과소적합"></a>과대적합 vs 과소적합</h2><ul>
<li>매우 힘듬. 도망가고 싶음(모형 설계가 잘못됨)</li>
<li>과대적합 : 훈련세트는 점수 좋으나 테스트 점수가 매우 안좋음</li>
<li>과소적합 : 테스트세트의 점수가 매우 좋음</li>
<li>결론 : 제대로 모형이 훈련이 안된 것이기에 모형 서비스에 탑재 불가.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;훈련평가:&quot;</span>,knr.score(train_input,train_target))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;테스트평가:&quot;</span>,knr.score(test_input,test_target))<span class="comment"># 테스트세트 점수가 좋기에 과소적합</span></span><br></pre></td></tr></table></figure>

<pre><code>훈련평가: 0.9698823289099254
테스트평가: 0.992809406101064
</code></pre>
<ul>
<li>모형개선</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 이웃의 갯수를 3으로 재 지정</span></span><br><span class="line">knr.n_neighbors = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 모형 다시 훈련</span></span><br><span class="line">knr.fit(train_input, train_target)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;훈련 평가:&quot;</span>,knr.score(train_input,train_target))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;테스트 평가:&quot;</span>,knr.score(test_input, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>훈련 평가: 0.9804899950518966
테스트 평가: 0.9746459963987609
</code></pre>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-06-30T08:11:18.000Z" title="2022. 6. 30. 오후 5:11:18">2022-06-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-06-30T08:22:40.092Z" title="2022. 6. 30. 오후 5:22:40">2022-06-30</time></span><span class="level-item">11 minutes read (About 1715 words)</span></div></div><div class="content"><p>title: ‘머신러닝2 데이터다루기’</p>
<p>date: ‘2022-06-30 09:00’</p>
<h2 id="인공지능"><a href="#인공지능" class="headerlink" title="인공지능"></a>인공지능</h2><p>인공지능&gt;머신러닝&gt;딥러닝</p>
<ul>
<li><p>딥러닝 알고리즘→인공신경망 알고리즘</p>
<ul>
<li><p>이미지,자연어(&#x3D;음성인식)</p>
</li>
<li><p>판별하는 성능이 중요</p>
</li>
</ul>
</li>
<li><p>머신러닝 알고리즘→선형회귀, 결정트리</p>
<ul>
<li><p>결과에 대한 해석 요구</p>
</li>
<li><p>통계적 분석이 중요</p>
</li>
<li><p>정형데이터(&#x3D;엑셀 데이터, 테이블)</p>
</li>
</ul>
</li>
</ul>
<h2 id="분석의-흐름"><a href="#분석의-흐름" class="headerlink" title="분석의 흐름"></a>분석의 흐름</h2><p> 1.데이터 수집</p>
<p> 2.데이터 가공</p>
<p> 3.데이터 시각화</p>
<p> 4.데이터(예측)모델링 </p>
<ul>
<li>예측평가지표</li>
<li>cf)R:,데이터(통계)모델링</li>
<li>변수(&#x3D;컬럼&#x3D;피쳐)간의 관계</li>
<li>가설 검정이 중요</li>
<li>공통점 : 결과를 해석</li>
</ul>
<p>5.보고서를 작성</p>
<h3 id="모형학습"><a href="#모형학습" class="headerlink" title="모형학습"></a>모형학습</h3><ul>
<li>fish_data-&gt; 독립변수, fish_target-&gt;종속변수</li>
<li>kn.fit(fish_data, fish_target)</li>
</ul>
<h2 id="새로운-모델-제안의-위험성"><a href="#새로운-모델-제안의-위험성" class="headerlink" title="새로운 모델 제안의 위험성"></a>새로운 모델 제안의 위험성</h2><ul>
<li>어제 머신 러닝 공부에 이어서</li>
<li>Default(내정값) : 정확도 1(100%)</li>
<li>하이퍼 파라미터 세팅</li>
</ul>
<ul>
<li>n_neighbprs &#x3D; 49 로 했을 시 정확도 0.7(70%)</li>
<li>튜닝을 하면 이상해질 수 있다. 따라서 완벽하게 파악하지 못한 내용을 변동시키지 말것.</li>
</ul>
<h2 id="머신러닝-알고리즘의-흐름"><a href="#머신러닝-알고리즘의-흐름" class="headerlink" title="머신러닝 알고리즘의 흐름"></a>머신러닝 알고리즘의 흐름</h2><ul>
<li>선형모델 : <strong>선형회귀</strong>,<strong>로지스틱 회귀</strong>,서포트벡터 머신</li>
<li>의사결정트리 모델 : 1975년 의사결정트리모델, KNN</li>
</ul>
<ul>
<li><strong>랜덤포레스트</strong></li>
<li>부스팅계열 : <strong>LightGBM(2017), XGBoost(2016)</strong></li>
<li>추천: LightGBM</li>
</ul>
<h2 id="훈련-세트와-테스트-세트-P68"><a href="#훈련-세트와-테스트-세트-P68" class="headerlink" title="훈련 세트와 테스트 세트(P68)"></a>훈련 세트와 테스트 세트(P68)</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fish_length = [<span class="number">25.4</span>, <span class="number">26.3</span>, <span class="number">26.5</span>, <span class="number">29.0</span>, <span class="number">29.0</span>, <span class="number">29.7</span>, <span class="number">29.7</span>, <span class="number">30.0</span>, <span class="number">30.0</span>, <span class="number">30.7</span>, <span class="number">31.0</span>, <span class="number">31.0</span>, </span><br><span class="line">                <span class="number">31.5</span>, <span class="number">32.0</span>, <span class="number">32.0</span>, <span class="number">32.0</span>, <span class="number">33.0</span>, <span class="number">33.0</span>, <span class="number">33.5</span>, <span class="number">33.5</span>, <span class="number">34.0</span>, <span class="number">34.0</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">                <span class="number">35.0</span>, <span class="number">35.0</span>, <span class="number">35.0</span>, <span class="number">36.0</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">38.5</span>, <span class="number">38.5</span>, <span class="number">39.5</span>, <span class="number">41.0</span>, <span class="number">41.0</span>, <span class="number">9.8</span>, </span><br><span class="line">                <span class="number">10.5</span>, <span class="number">10.6</span>, <span class="number">11.0</span>, <span class="number">11.2</span>, <span class="number">11.3</span>, <span class="number">11.8</span>, <span class="number">11.8</span>, <span class="number">12.0</span>, <span class="number">12.2</span>, <span class="number">12.4</span>, <span class="number">13.0</span>, <span class="number">14.3</span>, <span class="number">15.0</span>]</span><br><span class="line">fish_weight = [<span class="number">242.0</span>, <span class="number">290.0</span>, <span class="number">340.0</span>, <span class="number">363.0</span>, <span class="number">430.0</span>, <span class="number">450.0</span>, <span class="number">500.0</span>, <span class="number">390.0</span>, <span class="number">450.0</span>, <span class="number">500.0</span>, <span class="number">475.0</span>, <span class="number">500.0</span>, </span><br><span class="line">                <span class="number">500.0</span>, <span class="number">340.0</span>, <span class="number">600.0</span>, <span class="number">600.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">610.0</span>, <span class="number">650.0</span>, <span class="number">575.0</span>, <span class="number">685.0</span>, <span class="number">620.0</span>, <span class="number">680.0</span>, </span><br><span class="line">                <span class="number">700.0</span>, <span class="number">725.0</span>, <span class="number">720.0</span>, <span class="number">714.0</span>, <span class="number">850.0</span>, <span class="number">1000.0</span>, <span class="number">920.0</span>, <span class="number">955.0</span>, <span class="number">925.0</span>, <span class="number">975.0</span>, <span class="number">950.0</span>, <span class="number">6.7</span>, </span><br><span class="line">                <span class="number">7.5</span>, <span class="number">7.0</span>, <span class="number">9.7</span>, <span class="number">9.8</span>, <span class="number">8.7</span>, <span class="number">10.0</span>, <span class="number">9.9</span>, <span class="number">9.8</span>, <span class="number">12.2</span>, <span class="number">13.4</span>, <span class="number">12.2</span>, <span class="number">19.7</span>, <span class="number">19.9</span>]</span><br></pre></td></tr></table></figure>

<ul>
<li>2차원 리스트를 만들고 라벨링을 한다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fish_data = [[l, w] <span class="keyword">for</span> l, w <span class="keyword">in</span> <span class="built_in">zip</span>(fish_length, fish_weight)]</span><br><span class="line">fish_target = [<span class="number">1</span>] * <span class="number">35</span> + [<span class="number">0</span>] * <span class="number">14</span></span><br><span class="line"><span class="built_in">print</span>(fish_target[<span class="number">0</span>:<span class="number">40</span>:<span class="number">5</span>])<span class="comment">#1-40까지의 데이터에서 5간격으로 표시</span></span><br><span class="line"><span class="built_in">print</span>(fish_data[<span class="number">0</span>:<span class="number">40</span>:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(fish_target)</span><br></pre></td></tr></table></figure>

<pre><code>[1, 1, 1, 1, 1, 1, 1, 0]
[[25.4, 242.0], [29.7, 450.0], [31.0, 475.0], [32.0, 600.0], [34.0, 575.0], [35.0, 725.0], [38.5, 920.0], [9.8, 6.7]]
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
</code></pre>
<ul>
<li>전체 데이터에서 일부분 샘플을 추출했다.</li>
<li>도미35마리 빙어 14마리</li>
<li>처음 35개를 훈련&#x2F; 나머지 14개를 테스트 해본다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"><span class="comment"># 클래스 인스턴스화</span></span><br><span class="line">kn = KNeighborsClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 훈련세트로 0:34를 인덱스로 활용</span></span><br><span class="line">train_input = fish_data[:<span class="number">35</span>]</span><br><span class="line">train_target =fish_target[:<span class="number">35</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 테스트 세트로 35:마지막까지를 인덱스로 활용</span></span><br><span class="line">test_input = fish_data[<span class="number">35</span>:]</span><br><span class="line">test_target =fish_target[<span class="number">35</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모형학습</span></span><br><span class="line">kn = kn.fit(train_input,train_target)</span><br><span class="line"><span class="built_in">print</span>(kn.score(test_input, test_target))</span><br></pre></td></tr></table></figure>

<pre><code>0.0
</code></pre>
<p>-&gt; 훈련된 데이터는 도미인데 테스트한 데이터는 빙어이기에 이상한 결과가 나옴</p>
<ul>
<li>샘플링 편향</li>
<li>훈련세트와 테스트 세트가 골고루 섞이지 않음</li>
</ul>
<h2 id="샘플링-작업"><a href="#샘플링-작업" class="headerlink" title="샘플링 작업"></a>샘플링 작업</h2><ul>
<li>넘파이를 사용하여 골고루 섞어 준다.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">input_arr = np.array(fish_data)</span><br><span class="line">target_arr = np.array(fish_target)</span><br><span class="line"><span class="built_in">print</span>(input_arr[<span class="number">0</span>:<span class="number">49</span>:<span class="number">7</span>])</span><br><span class="line"><span class="built_in">print</span>(input_arr.shape, target_arr.shape)<span class="comment">#입력한 것의 (샘플수,특성수) 타겟은 특성수가 없음</span></span><br></pre></td></tr></table></figure>

<pre><code>[[ 25.4 242. ]
 [ 30.  390. ]
 [ 32.  600. ]
 [ 34.  685. ]
 [ 36.  850. ]
 [  9.8   6.7]
 [ 11.8   9.9]]
(49, 2) (49,)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(target_arr.shape)</span><br><span class="line"><span class="built_in">print</span>(target_arr.ndim)<span class="comment">#차원을 확인-&gt;1차원</span></span><br><span class="line"><span class="built_in">print</span>(target_arr)</span><br></pre></td></tr></table></figure>

<pre><code>(49,)
1
[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#random으로 무작위 배열을 만드는 설정</span></span><br><span class="line">np.random.seed(<span class="number">42</span>)</span><br><span class="line">index = np.arange(<span class="number">49</span>)</span><br><span class="line">np.random.shuffle(index)</span><br><span class="line"><span class="built_in">print</span>(index)</span><br></pre></td></tr></table></figure>

<pre><code>[13 45 47 44 17 27 26 25 31 19 12  4 34  8  3  6 40 41 46 15  9 16 24 33
 30  0 43 32  5 29 11 36  1 21  2 37 35 23 39 10 22 18 48 20  7 42 14 28
 38]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_input = input_arr[index[:<span class="number">35</span>]]</span><br><span class="line">train_target= target_arr[index[:<span class="number">35</span>]]</span><br><span class="line"></span><br><span class="line">test_input = input_arr[index[<span class="number">35</span>:]]</span><br><span class="line">test_target= target_arr[index[<span class="number">35</span>:]]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(train_input[:<span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(train_input[:,<span class="number">0</span>])<span class="comment">#전체길이</span></span><br></pre></td></tr></table></figure>

<pre><code>[[ 32. 340.]]
[32.  12.4 14.3 12.2 33.  36.  35.  35.  38.5 33.5 31.5 29.  41.  30.
 29.  29.7 11.3 11.8 13.  32.  30.7 33.  35.  41.  38.5 25.4 12.  39.5
 29.7 37.  31.  10.5 26.3 34.  26.5]
</code></pre>
<h2 id="시각화"><a href="#시각화" class="headerlink" title="시각화"></a>시각화</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt  </span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input[:, <span class="number">0</span>], train_input[:, <span class="number">1</span>])</span><br><span class="line">ax.scatter(test_input[:, <span class="number">0</span>], test_input[:, <span class="number">1</span>])</span><br><span class="line">ax.set_xlabel(<span class="string">&quot;length&quot;</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">&quot;weight&quot;</span>)</span><br><span class="line">fig.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src="/images/day0630_ml/output_20_0.png" alt="png"></p>
<h2 id="두번째-머신러닝-프로그램"><a href="#두번째-머신러닝-프로그램" class="headerlink" title="두번째 머신러닝 프로그램"></a>두번째 머신러닝 프로그램</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kn.fit(train_input, train_target)</span><br><span class="line">kn.score(test_input, test_target)</span><br></pre></td></tr></table></figure>




<pre><code>1.0
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kn.predict(test_input) <span class="comment"># 예측데이터</span></span><br></pre></td></tr></table></figure>




<pre><code>array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_target <span class="comment">#실제 데이터</span></span><br></pre></td></tr></table></figure>




<pre><code>array([0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0])
</code></pre>
<h2 id="데이터-전처리"><a href="#데이터-전처리" class="headerlink" title="데이터 전처리"></a>데이터 전처리</h2><ul>
<li>머신러닝 시 데이터 전처리</li>
<li>결측치 처리, 이상치 처리</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fish_length = [<span class="number">25.4</span>, <span class="number">26.3</span>, <span class="number">26.5</span>, <span class="number">29.0</span>, <span class="number">29.0</span>, <span class="number">29.7</span>, <span class="number">29.7</span>, <span class="number">30.0</span>, <span class="number">30.0</span>, <span class="number">30.7</span>, <span class="number">31.0</span>, <span class="number">31.0</span>, </span><br><span class="line">                <span class="number">31.5</span>, <span class="number">32.0</span>, <span class="number">32.0</span>, <span class="number">32.0</span>, <span class="number">33.0</span>, <span class="number">33.0</span>, <span class="number">33.5</span>, <span class="number">33.5</span>, <span class="number">34.0</span>, <span class="number">34.0</span>, <span class="number">34.5</span>, <span class="number">35.0</span>, </span><br><span class="line">                <span class="number">35.0</span>, <span class="number">35.0</span>, <span class="number">35.0</span>, <span class="number">36.0</span>, <span class="number">36.0</span>, <span class="number">37.0</span>, <span class="number">38.5</span>, <span class="number">38.5</span>, <span class="number">39.5</span>, <span class="number">41.0</span>, <span class="number">41.0</span>, <span class="number">9.8</span>, </span><br><span class="line">                <span class="number">10.5</span>, <span class="number">10.6</span>, <span class="number">11.0</span>, <span class="number">11.2</span>, <span class="number">11.3</span>, <span class="number">11.8</span>, <span class="number">11.8</span>, <span class="number">12.0</span>, <span class="number">12.2</span>, <span class="number">12.4</span>, <span class="number">13.0</span>, <span class="number">14.3</span>, <span class="number">15.0</span>]</span><br><span class="line">fish_weight = [<span class="number">242.0</span>, <span class="number">290.0</span>, <span class="number">340.0</span>, <span class="number">363.0</span>, <span class="number">430.0</span>, <span class="number">450.0</span>, <span class="number">500.0</span>, <span class="number">390.0</span>, <span class="number">450.0</span>, <span class="number">500.0</span>, <span class="number">475.0</span>, <span class="number">500.0</span>, </span><br><span class="line">                <span class="number">500.0</span>, <span class="number">340.0</span>, <span class="number">600.0</span>, <span class="number">600.0</span>, <span class="number">700.0</span>, <span class="number">700.0</span>, <span class="number">610.0</span>, <span class="number">650.0</span>, <span class="number">575.0</span>, <span class="number">685.0</span>, <span class="number">620.0</span>, <span class="number">680.0</span>, </span><br><span class="line">                <span class="number">700.0</span>, <span class="number">725.0</span>, <span class="number">720.0</span>, <span class="number">714.0</span>, <span class="number">850.0</span>, <span class="number">1000.0</span>, <span class="number">920.0</span>, <span class="number">955.0</span>, <span class="number">925.0</span>, <span class="number">975.0</span>, <span class="number">950.0</span>, <span class="number">6.7</span>, </span><br><span class="line">                <span class="number">7.5</span>, <span class="number">7.0</span>, <span class="number">9.7</span>, <span class="number">9.8</span>, <span class="number">8.7</span>, <span class="number">10.0</span>, <span class="number">9.9</span>, <span class="number">9.8</span>, <span class="number">12.2</span>, <span class="number">13.4</span>, <span class="number">12.2</span>, <span class="number">19.7</span>, <span class="number">19.9</span>]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## column_stack()활용</span></span><br><span class="line">np.column_stack(([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]))</span><br></pre></td></tr></table></figure>




<pre><code>array([[1, 4],
       [2, 5],
       [3, 6]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fish_data = np.column_stack((fish_length, fish_weight))</span><br><span class="line"><span class="built_in">print</span>(fish_data[:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">fish_data.shape</span><br></pre></td></tr></table></figure>

<pre><code>[[ 25.4 242. ]
 [ 26.3 290. ]
 [ 26.5 340. ]
 [ 29.  363. ]
 [ 29.  430. ]]





(49, 2)
</code></pre>
<ul>
<li>종속변수 &#x3D; Y &#x3D; 타깃데이터 &#x3D; Target &lt;-&gt;독립변수(X)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fish_target = np.concatenate((np.ones(<span class="number">35</span>),np.zeros(<span class="number">14</span>)))</span><br><span class="line"><span class="built_in">print</span>(fish_target.shape)</span><br></pre></td></tr></table></figure>

<pre><code>(49,)
</code></pre>
<h2 id="scikit-learn-훈련세트와-테스트-세트-나누기"><a href="#scikit-learn-훈련세트와-테스트-세트-나누기" class="headerlink" title="scikit-learn 훈련세트와 테스트 세트 나누기"></a>scikit-learn 훈련세트와 테스트 세트 나누기</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    <span class="comment">#독립변수, 종속변수</span></span><br><span class="line">    fish_data, fish_target, random_state =<span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((36, 2), (13, 2), (36,), (13,))
</code></pre>
<ul>
<li>P92 도미와 빙어가 잘 섞여 있나?</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(test_target)</span><br></pre></td></tr></table></figure>

<pre><code>[1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
</code></pre>
<ul>
<li>35(도미) :14(빙어)</li>
</ul>
<ul>
<li>2.5:1</li>
</ul>
<ul>
<li>테스트 셋(비율)</li>
</ul>
<ul>
<li>3.3:1</li>
</ul>
<h2 id="층화샘플링"><a href="#층화샘플링" class="headerlink" title="층화샘플링"></a>층화샘플링</h2><ul>
<li>기초 통계, 설문조사</li>
<li>비율이 중요</li>
<li>예)남성 속옷을 구매하는 비율은 남자9: 여자1이지만 조사는 남자5: 여자 5로 조사됨으로 비율이 맞지 않음</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">train_input, test_input, train_target, test_target = train_test_split(</span><br><span class="line">    <span class="comment"># 독립변수, 종속변수</span></span><br><span class="line">    fish_data, fish_target, stratify=fish_target, random_state = <span class="number">42</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_input.shape, test_input.shape, train_target.shape, test_target.shape</span><br></pre></td></tr></table></figure>




<pre><code>((36, 2), (13, 2), (36,), (13,))
</code></pre>
<ul>
<li>stratify &#x3D; fish_target를 넣어주어</li>
<li>빙어가 한마리 더 늘도록 해서 테스트 세트 비율이 2.55:1 로 근접하게 됨</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(test_target)</span><br></pre></td></tr></table></figure>

<pre><code>[0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.]
</code></pre>
<h2 id="수상한-도미-한마리"><a href="#수상한-도미-한마리" class="headerlink" title="수상한 도미 한마리"></a>수상한 도미 한마리</h2><ul>
<li></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">kn = KNeighborsClassifier()</span><br><span class="line">kn.fit(train_input, train_target)</span><br><span class="line">kn.score(test_input, test_target)</span><br></pre></td></tr></table></figure>




<pre><code>1.0
</code></pre>
<ul>
<li>도미사이즈 20cm 이상 &#x3D; 1</li>
<li>빙어사이즈 10cm 이하 &#x3D; 0 인 문제가 발생</li>
<li>알고리즘에 문제가 있음</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(kn.predict([[<span class="number">25</span>,<span class="number">150</span>]]))</span><br></pre></td></tr></table></figure>

<pre><code>[0.]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt </span><br><span class="line"></span><br><span class="line">fig, ax = plt.subplots()</span><br><span class="line">ax.scatter(train_input[:, <span class="number">0</span>], train_input[:, <span class="number">1</span>])</span><br><span class="line">ax.scatter(<span class="number">25</span>, <span class="number">150</span>, marker = <span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0630_ml/output_44_0.png" alt="png"></p>
<ul>
<li>이웃 샘플이 누구인지 확인해보니 알고리즘이 맞지 않음</li>
</ul>
<ul>
<li>빙어에 4개의 이웃 샘플이 있어 빙어로 인식</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">distances, indexes = kn.kneighbors([[<span class="number">25</span>, <span class="number">150</span>]])</span><br><span class="line">plt.scatter(train_input[:,<span class="number">0</span>], train_input[:,<span class="number">1</span>])</span><br><span class="line">plt.scatter(<span class="number">25</span>, <span class="number">150</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.scatter(train_input[indexes,<span class="number">0</span>], train_input[indexes,<span class="number">1</span>], marker=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0630_ml/output_46_0.png" alt="png"></p>
<ul>
<li>떨어진 거리 비율을 맞추기 위해 스케일의 크기를 동일하게 함.즉 무게와 길이의 길이를 1000으로 맞춤</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(train_input[:,<span class="number">0</span>], train_input[:,<span class="number">1</span>])</span><br><span class="line">plt.scatter(<span class="number">25</span>, <span class="number">150</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.scatter(train_input[indexes,<span class="number">0</span>], train_input[indexes,<span class="number">1</span>], marker=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line">plt.xlim((<span class="number">0</span>, <span class="number">1000</span>))</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0630_ml/output_48_0.png" alt="png"></p>
<p>-p98</p>
<ul>
<li>그러나 두 특성(길이와 무게)의 값이 놓인 범위가 매우 다름</li>
<li>두 특성의 스케일이 다름</li>
</ul>
<ul>
<li>스케일이 같도록 통계처리 필요</li>
<li>Feature Engineering(피처 엔지니어링)</li>
</ul>
<ul>
<li>머신 러닝</li>
</ul>
<ul>
<li>전체 데이터 전처리(결측지 처리, 이상치 처리)</li>
<li>데이터 분리</li>
<li>Feature Engineering(피처 엔지니어링)</li>
</ul>
<h3 id="표준점수"><a href="#표준점수" class="headerlink" title="표준점수"></a>표준점수</h3><ul>
<li>z 점수</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mean = np.mean(train_input, axis =<span class="number">0</span>)</span><br><span class="line">std = np.std(train_input,axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(mean, std)</span><br></pre></td></tr></table></figure>

<pre><code>[ 27.29722222 454.09722222] [  9.98244253 323.29893931]
</code></pre>
<ul>
<li>표준 점수 구하기</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 브로드 캐스팅- 서로 다른 배열을 계산할 때</span></span><br><span class="line"><span class="built_in">print</span>(train_input.shape, mean.shape, std.shape)</span><br><span class="line">train_scaled = (train_input - mean)/std</span><br></pre></td></tr></table></figure>

<pre><code>(36, 2) (2,) (2,)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_input[<span class="number">0</span>:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([[ 29.7, 500. ],
       [ 12.2,  12.2],
       [ 33. , 700. ],
       [ 11.3,   8.7],
       [ 39.5, 925. ]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_scaled[<span class="number">0</span>:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>array([[ 0.24070039,  0.14198246],
       [-1.51237757, -1.36683783],
       [ 0.5712808 ,  0.76060496],
       [-1.60253587, -1.37766373],
       [ 1.22242404,  1.45655528]])
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.scatter(train_scaled[:,<span class="number">0</span>], train_scaled[:,<span class="number">1</span>])</span><br><span class="line">plt.scatter(<span class="number">25</span>, <span class="number">150</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0630_ml/output_56_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">new = ([<span class="number">25</span>, <span class="number">150</span>] - mean) / std</span><br><span class="line">plt.scatter(train_scaled[:,<span class="number">0</span>], train_scaled[:,<span class="number">1</span>])</span><br><span class="line">plt.scatter(new[<span class="number">0</span>], new[<span class="number">1</span>], marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0630_ml/output_57_0.png" alt="png"></p>
<p>통계처리 전 : KNN –&gt; 예측이 틀림<br>통계처리 후 : KNN –&gt; 예측이 정확하게 맞음<br>– 통계처리 –&gt; Feature Engineering</p>
<ul>
<li>모형학습</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kn.fit(train_scaled, train_target)</span><br></pre></td></tr></table></figure>




<pre><code>KNeighborsClassifier()
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#kn.score(test_input, test_target)</span></span><br><span class="line">test_scaled = (test_input - mean)/ std</span><br><span class="line">kn.score(test_scaled, test_target)</span><br></pre></td></tr></table></figure>




<pre><code>1.0
</code></pre>
<ul>
<li>예측</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(kn.predict([new]))</span><br></pre></td></tr></table></figure>

<pre><code>[1.]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">distances, indexes = kn.kneighbors([new])</span><br><span class="line">plt.scatter(train_scaled[:,<span class="number">0</span>], train_scaled[:,<span class="number">1</span>])</span><br><span class="line">plt.scatter(new[<span class="number">0</span>], new[<span class="number">1</span>], marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.scatter(train_scaled[indexes,<span class="number">0</span>], train_scaled[indexes,<span class="number">1</span>], marker=<span class="string">&#x27;D&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;length&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;weight&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="/images/day0630_ml/output_64_0.png" alt="png"></p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/page/0/">Previous</a></div><div class="pagination-next"><a href="/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="CHAI JE HYUNG"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">CHAI JE HYUNG</p><p class="is-size-6 is-block">GOD IS GOOD ALL THE TIME</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>SEOUL.KOREA</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">21</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/westar99" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/westar99"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://www.facebook.com/jehyung.chai"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-07-07T08:05:34.000Z">2022-07-07</time></p><p class="title"><a href="/2022/07/07/lecture_in_humanedu/"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-07-06T07:38:20.000Z">2022-07-06</time></p><p class="title"><a href="/2022/07/06/day0706/"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-07-05T07:00:28.539Z">2022-07-05</time></p><p class="title"><a href="/2022/07/05/day0705_1/"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-07-05T07:00:04.000Z">2022-07-05</time></p><p class="title"><a href="/2022/07/05/day0705_2/"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-07-04T08:11:36.000Z">2022-07-04</time></p><p class="title"><a href="/2022/07/04/day0704_2/"> </a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">June 2022</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="CHAI JEHYUNG" height="28"></a><p class="is-size-7"><span>&copy; 2022 John Doe</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>